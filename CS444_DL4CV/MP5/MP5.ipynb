{"cells":[{"cell_type":"markdown","metadata":{"id":"CV6C6iXT8RQI"},"source":["# Deep Q-Learning "]},{"cell_type":"markdown","metadata":{"id":"OERQ9Gr38RQL"},"source":["Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21750,"status":"ok","timestamp":1683407462268,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"},"user_tz":300},"id":"ca9r_g7T8RQL","outputId":"7456d4ce-d180-4b4e-a755-f07efff8e9a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n","Installing collected packages: pyvirtualdisplay\n","Successfully installed pyvirtualdisplay-3.0\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n","The following additional packages will be installed:\n","  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python2\n","  python2-minimal x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common\n","Suggested packages:\n","  python-tk python-numpy libgle3 python2-doc\n","The following NEW packages will be installed:\n","  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python-opengl\n","  python2 python2-minimal x11-xkb-utils xfonts-base xfonts-encodings\n","  xfonts-utils xserver-common xvfb\n","0 upgraded, 14 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 8,318 kB of archives.\n","After this operation, 18.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n","Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n","Fetched 8,318 kB in 1s (5,605 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 14.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python2-minimal.\n","(Reading database ... 122518 files and directories currently installed.)\n","Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n","Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n","Selecting previously unselected package libpython2-stdlib:amd64.\n","Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n","Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n","Setting up python2-minimal (2.7.17-2ubuntu4) ...\n","Selecting previously unselected package python2.\n","(Reading database ... 122547 files and directories currently installed.)\n","Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n","Unpacking python2 (2.7.17-2ubuntu4) ...\n","Selecting previously unselected package freeglut3:amd64.\n","Preparing to unpack .../01-freeglut3_2.8.1-3_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-3) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../02-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../03-libxfont2_1%3a2.0.3-1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../04-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n","Selecting previously unselected package python-opengl.\n","Preparing to unpack .../05-python-opengl_3.1.0+dfsg-2build1_all.deb ...\n","Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../06-x11-xkb-utils_7.7+5_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../07-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../08-xfonts-utils_1%3a7.7+6_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../09-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../10-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n","Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../11-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n","Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n","Setting up freeglut3:amd64 (2.8.1-3) ...\n","Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n","Setting up python2 (2.7.17-2ubuntu4) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n","Setting up libxfont2:amd64 (1:2.0.3-1) ...\n","Setting up python-opengl (3.1.0+dfsg-2build1) ...\n","Setting up x11-xkb-utils (7.7+5) ...\n","Setting up xfonts-utils (1:7.7+6) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n","Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n","Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"]}],"source":["!pip3 install gym pyvirtualdisplay\n","!sudo apt-get install -y xvfb python-opengl ffmpeg"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27427,"status":"ok","timestamp":1683407489692,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"},"user_tz":300},"id":"67EG7jzI8RQM","outputId":"d96f09e0-7fe5-428c-8437-f7bc9de75dfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ez_setup\n","  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ez_setup\n","  Building wheel for ez_setup (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ez_setup: filename=ez_setup-0.9-py3-none-any.whl size=11012 sha256=e473650dc28ddca8093343a72153d0dd1ef15178bbc89ee10258510b6cd8e02b\n","  Stored in directory: /root/.cache/pip/wheels/7a/d6/77/8f495e85fb7df23d41c328b9ea3cf0d9e83631b20bba479293\n","Successfully built ez_setup\n","Installing collected packages: ez_setup\n","Successfully installed ez_setup-0.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (2.2.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (1.22.4)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (0.0.8)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[atari]) (5.12.0)\n","Installing collected packages: ale-py\n","Successfully installed ale-py-0.7.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (0.0.8)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (1.22.4)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.27.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (8.1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (4.65.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (1.26.15)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446676 sha256=ac68689378b9cf9e73cfbeb6b0dc8823590d1220252efe8e3bee48c593753a40\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom\n","Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n"]}],"source":["!pip3 install --upgrade setuptools --user\n","!pip3 install ez_setup \n","!pip3 install gym[atari] \n","!pip3 install gym[accept-rom-license] "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26685,"status":"ok","timestamp":1683407516369,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"},"user_tz":300},"id":"B2n95GQN8ex_","outputId":"276061d5-08cd-4cc2-9957-e265047409dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683407516369,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"},"user_tz":300},"id":"q8zaNb9b8Vzz","outputId":"e307e79b-9da7-4222-8d47-12454b849303"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/assignment5_materials\n"]}],"source":["import os\n","datadir = \"/content/drive/MyDrive/assignment5_materials/\"\n","if not os.path.exists(datadir):\n","  !ln -s \"/content/drive/MyDrive/assignment5_materials/\" $datadir # TODO: Fill your A5 path\n","os.chdir(datadir)\n","!pwd"]},{"cell_type":"markdown","metadata":{"id":"D-KaDVLC8RQM"},"source":["For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"P_sDG78C8RQN","executionInfo":{"status":"ok","timestamp":1683407523611,"user_tz":300,"elapsed":7244,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"}}},"outputs":[],"source":["%matplotlib inline\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from utils import find_max_lives, check_live, get_frame, get_init_state\n","from model import DQN\n","#, DQN_LSTM\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","# %load_ext autoreload\n","# %autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"_QeiMBlj8RQN"},"source":["## Understanding the environment"]},{"cell_type":"markdown","metadata":{"id":"zzJ7QsJu8RQN"},"source":["In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://www.gymlibrary.dev/environments/atari/breakout/. \n","\n","In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683297335867,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"},"user_tz":300},"id":"wJFViHv78RQO","outputId":"fd5da8b0-e5b3-44ea-973b-1124d70a39ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["env = gym.make('BreakoutDeterministic-v4')\n","state = env.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683297335868,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"},"user_tz":300},"id":"p3U-q7C-8RQO","outputId":"cb4f25cf-f580-46db-bad3-605383755fb9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  logger.deprecation(\n"]}],"source":["number_lives = find_max_lives(env)\n","state_size = env.observation_space.shape\n","action_size = 3 #fire, left, and right"]},{"cell_type":"markdown","metadata":{"id":"Mj5_JKdY8RQO"},"source":["## Creating a DQN Agent"]},{"cell_type":"markdown","metadata":{"id":"RSgk6yev8RQP"},"source":["Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n","\n","__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n","\n","__Frame__ : Number of frames processed in total.\n","\n","__Memory Size__ : The current size of the replay memory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3J_z1XJB8RQP"},"outputs":[],"source":["double_dqn = False # set to True if using double DQN agent\n","\n","if double_dqn:\n","    from agent_double import Agent\n","else:\n","    from agent import Agent\n","\n","agent = Agent(action_size)\n","evaluation_reward = deque(maxlen=evaluation_reward_length)\n","frame = 0\n","memory_size = 0"]},{"cell_type":"markdown","metadata":{"id":"ZVJUj4oJ8RQP"},"source":["### Main Training Loop"]},{"cell_type":"markdown","metadata":{"id":"OR2wHgfN8RQP"},"source":["In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wwUz3byh8RQP","scrolled":true,"outputId":"878b70a1-3ab4-4901-a98b-8fc2e99ef63e","executionInfo":{"status":"ok","timestamp":1683312529354,"user_tz":300,"elapsed":15188397,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["episode: 0   score: 0.0   memory length: 123   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 0.0\n","episode: 1   score: 2.0   memory length: 322   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.0\n","episode: 2   score: 4.0   memory length: 621   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 2.0\n","episode: 3   score: 0.0   memory length: 745   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n","episode: 4   score: 1.0   memory length: 897   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 5   score: 0.0   memory length: 1021   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1666666666666667\n","episode: 6   score: 1.0   memory length: 1192   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.1428571428571428\n","episode: 7   score: 1.0   memory length: 1363   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.125\n","episode: 8   score: 3.0   memory length: 1612   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.3333333333333333\n","episode: 9   score: 0.0   memory length: 1736   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2\n","episode: 10   score: 1.0   memory length: 1907   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.1818181818181819\n","episode: 11   score: 0.0   memory length: 2030   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.0833333333333333\n","episode: 12   score: 2.0   memory length: 2228   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.1538461538461537\n","episode: 13   score: 0.0   memory length: 2352   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0714285714285714\n","episode: 14   score: 0.0   memory length: 2476   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0\n","episode: 15   score: 0.0   memory length: 2600   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.9375\n","episode: 16   score: 0.0   memory length: 2723   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 0.8823529411764706\n","episode: 17   score: 2.0   memory length: 2942   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 0.9444444444444444\n","episode: 18   score: 4.0   memory length: 3219   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.105263157894737\n","episode: 19   score: 2.0   memory length: 3418   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.15\n","episode: 20   score: 1.0   memory length: 3588   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.1428571428571428\n","episode: 21   score: 0.0   memory length: 3712   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0909090909090908\n","episode: 22   score: 2.0   memory length: 3931   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.1304347826086956\n","episode: 23   score: 3.0   memory length: 4178   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.2083333333333333\n","episode: 24   score: 4.0   memory length: 4436   epsilon: 1.0    steps: 258    lr: 0.0001     evaluation reward: 1.32\n","episode: 25   score: 1.0   memory length: 4608   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.3076923076923077\n","episode: 26   score: 0.0   memory length: 4732   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2592592592592593\n","episode: 27   score: 2.0   memory length: 4950   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.2857142857142858\n","episode: 28   score: 2.0   memory length: 5148   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3103448275862069\n","episode: 29   score: 0.0   memory length: 5272   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2666666666666666\n","episode: 30   score: 0.0   memory length: 5396   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2258064516129032\n","episode: 31   score: 1.0   memory length: 5565   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.21875\n","episode: 32   score: 3.0   memory length: 5833   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.2727272727272727\n","episode: 33   score: 3.0   memory length: 6098   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.3235294117647058\n","episode: 34   score: 5.0   memory length: 6427   epsilon: 1.0    steps: 329    lr: 0.0001     evaluation reward: 1.4285714285714286\n","episode: 35   score: 0.0   memory length: 6550   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3888888888888888\n","episode: 36   score: 0.0   memory length: 6673   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3513513513513513\n","episode: 37   score: 4.0   memory length: 6988   epsilon: 1.0    steps: 315    lr: 0.0001     evaluation reward: 1.4210526315789473\n","episode: 38   score: 3.0   memory length: 7220   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.4615384615384615\n","episode: 39   score: 4.0   memory length: 7534   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.525\n","episode: 40   score: 1.0   memory length: 7686   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.5121951219512195\n","episode: 41   score: 0.0   memory length: 7810   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4761904761904763\n","episode: 42   score: 4.0   memory length: 8112   epsilon: 1.0    steps: 302    lr: 0.0001     evaluation reward: 1.5348837209302326\n","episode: 43   score: 3.0   memory length: 8358   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5681818181818181\n","episode: 44   score: 3.0   memory length: 8608   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.6\n","episode: 45   score: 3.0   memory length: 8855   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.6304347826086956\n","episode: 46   score: 0.0   memory length: 8979   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5957446808510638\n","episode: 47   score: 4.0   memory length: 9255   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.6458333333333333\n","episode: 48   score: 4.0   memory length: 9554   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.6938775510204083\n","episode: 49   score: 2.0   memory length: 9776   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.7\n","episode: 50   score: 1.0   memory length: 9928   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6862745098039216\n","episode: 51   score: 2.0   memory length: 10147   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.6923076923076923\n","episode: 52   score: 0.0   memory length: 10270   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6603773584905661\n","episode: 53   score: 3.0   memory length: 10502   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.6851851851851851\n","episode: 54   score: 2.0   memory length: 10700   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.690909090909091\n","episode: 55   score: 2.0   memory length: 10900   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6964285714285714\n","episode: 56   score: 0.0   memory length: 11024   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6666666666666667\n","episode: 57   score: 3.0   memory length: 11256   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.6896551724137931\n","episode: 58   score: 1.0   memory length: 11427   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6779661016949152\n","episode: 59   score: 2.0   memory length: 11646   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.6833333333333333\n","episode: 60   score: 1.0   memory length: 11816   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6721311475409837\n","episode: 61   score: 3.0   memory length: 12048   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.6935483870967742\n","episode: 62   score: 0.0   memory length: 12172   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6666666666666667\n","episode: 63   score: 6.0   memory length: 12532   epsilon: 1.0    steps: 360    lr: 0.0001     evaluation reward: 1.734375\n","episode: 64   score: 1.0   memory length: 12702   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.7230769230769232\n","episode: 65   score: 1.0   memory length: 12854   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.7121212121212122\n","episode: 66   score: 2.0   memory length: 13074   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.7164179104477613\n","episode: 67   score: 1.0   memory length: 13228   epsilon: 1.0    steps: 154    lr: 0.0001     evaluation reward: 1.7058823529411764\n","episode: 68   score: 2.0   memory length: 13426   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.710144927536232\n","episode: 69   score: 2.0   memory length: 13645   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.7142857142857142\n","episode: 70   score: 1.0   memory length: 13815   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.704225352112676\n","episode: 71   score: 1.0   memory length: 13985   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6944444444444444\n","episode: 72   score: 4.0   memory length: 14282   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.726027397260274\n","episode: 73   score: 3.0   memory length: 14509   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.7432432432432432\n","episode: 74   score: 0.0   memory length: 14633   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.72\n","episode: 75   score: 0.0   memory length: 14757   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6973684210526316\n","episode: 76   score: 2.0   memory length: 14975   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.7012987012987013\n","episode: 77   score: 1.0   memory length: 15146   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6923076923076923\n","episode: 78   score: 0.0   memory length: 15270   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6708860759493671\n","episode: 79   score: 3.0   memory length: 15518   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.6875\n","episode: 80   score: 0.0   memory length: 15642   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6666666666666667\n","episode: 81   score: 2.0   memory length: 15864   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.670731707317073\n","episode: 82   score: 1.0   memory length: 16017   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.6626506024096386\n","episode: 83   score: 0.0   memory length: 16141   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6428571428571428\n","episode: 84   score: 0.0   memory length: 16265   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6235294117647059\n","episode: 85   score: 0.0   memory length: 16389   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6046511627906976\n","episode: 86   score: 1.0   memory length: 16541   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.5977011494252873\n","episode: 87   score: 0.0   memory length: 16665   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5795454545454546\n","episode: 88   score: 1.0   memory length: 16837   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.5730337078651686\n","episode: 89   score: 9.0   memory length: 17235   epsilon: 1.0    steps: 398    lr: 0.0001     evaluation reward: 1.6555555555555554\n","episode: 90   score: 0.0   memory length: 17359   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6373626373626373\n","episode: 91   score: 1.0   memory length: 17511   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6304347826086956\n","episode: 92   score: 0.0   memory length: 17635   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6129032258064515\n","episode: 93   score: 3.0   memory length: 17850   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.627659574468085\n","episode: 94   score: 2.0   memory length: 18049   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.631578947368421\n","episode: 95   score: 2.0   memory length: 18248   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.6354166666666667\n","episode: 96   score: 2.0   memory length: 18431   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.6391752577319587\n","episode: 97   score: 3.0   memory length: 18681   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.653061224489796\n","episode: 98   score: 2.0   memory length: 18880   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.6565656565656566\n","episode: 99   score: 2.0   memory length: 19098   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.66\n","episode: 100   score: 5.0   memory length: 19415   epsilon: 1.0    steps: 317    lr: 0.0001     evaluation reward: 1.71\n","episode: 101   score: 2.0   memory length: 19614   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.71\n","episode: 102   score: 1.0   memory length: 19765   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.68\n","episode: 103   score: 1.0   memory length: 19917   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.69\n","episode: 104   score: 1.0   memory length: 20090   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.69\n","episode: 105   score: 4.0   memory length: 20368   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.73\n","episode: 106   score: 1.0   memory length: 20539   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.73\n","episode: 107   score: 0.0   memory length: 20663   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.72\n","episode: 108   score: 0.0   memory length: 20787   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.69\n","episode: 109   score: 1.0   memory length: 20956   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.7\n","episode: 110   score: 4.0   memory length: 21252   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.73\n","episode: 111   score: 2.0   memory length: 21435   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.75\n","episode: 112   score: 0.0   memory length: 21559   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.73\n","episode: 113   score: 3.0   memory length: 21828   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.76\n","episode: 114   score: 3.0   memory length: 22055   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.79\n","episode: 115   score: 3.0   memory length: 22304   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.82\n","episode: 116   score: 0.0   memory length: 22428   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.82\n","episode: 117   score: 5.0   memory length: 22752   epsilon: 1.0    steps: 324    lr: 0.0001     evaluation reward: 1.85\n","episode: 118   score: 2.0   memory length: 22950   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.83\n","episode: 119   score: 3.0   memory length: 23176   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.84\n","episode: 120   score: 2.0   memory length: 23358   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.85\n","episode: 121   score: 1.0   memory length: 23510   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.86\n","episode: 122   score: 2.0   memory length: 23709   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.86\n","episode: 123   score: 3.0   memory length: 23938   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.86\n","episode: 124   score: 3.0   memory length: 24188   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.85\n","episode: 125   score: 0.0   memory length: 24311   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.84\n","episode: 126   score: 0.0   memory length: 24435   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.84\n","episode: 127   score: 2.0   memory length: 24653   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.84\n","episode: 128   score: 1.0   memory length: 24805   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.83\n","episode: 129   score: 1.0   memory length: 24975   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.84\n","episode: 130   score: 4.0   memory length: 25269   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.88\n","episode: 131   score: 3.0   memory length: 25516   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.9\n","episode: 132   score: 1.0   memory length: 25668   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.88\n","episode: 133   score: 1.0   memory length: 25820   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.86\n","episode: 134   score: 2.0   memory length: 26022   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.83\n","episode: 135   score: 1.0   memory length: 26173   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.84\n","episode: 136   score: 3.0   memory length: 26420   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.87\n","episode: 137   score: 2.0   memory length: 26602   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.85\n","episode: 138   score: 0.0   memory length: 26726   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.82\n","episode: 139   score: 1.0   memory length: 26878   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.79\n","episode: 140   score: 1.0   memory length: 27049   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.79\n","episode: 141   score: 2.0   memory length: 27234   epsilon: 1.0    steps: 185    lr: 0.0001     evaluation reward: 1.81\n","episode: 142   score: 2.0   memory length: 27433   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.79\n","episode: 143   score: 1.0   memory length: 27604   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.77\n","episode: 144   score: 0.0   memory length: 27727   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.74\n","episode: 145   score: 3.0   memory length: 27974   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.74\n","episode: 146   score: 3.0   memory length: 28241   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.77\n","episode: 147   score: 3.0   memory length: 28468   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.76\n","episode: 148   score: 2.0   memory length: 28666   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.74\n","episode: 149   score: 5.0   memory length: 28985   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.77\n","episode: 150   score: 0.0   memory length: 29109   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.76\n","episode: 151   score: 1.0   memory length: 29282   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.75\n","episode: 152   score: 2.0   memory length: 29483   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.77\n","episode: 153   score: 2.0   memory length: 29682   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 154   score: 1.0   memory length: 29852   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.75\n","episode: 155   score: 0.0   memory length: 29976   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.73\n","episode: 156   score: 2.0   memory length: 30195   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.75\n","episode: 157   score: 0.0   memory length: 30319   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.72\n","episode: 158   score: 8.0   memory length: 30790   epsilon: 1.0    steps: 471    lr: 0.0001     evaluation reward: 1.79\n","episode: 159   score: 1.0   memory length: 30962   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.78\n","episode: 160   score: 0.0   memory length: 31086   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.77\n","episode: 161   score: 2.0   memory length: 31285   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 162   score: 2.0   memory length: 31484   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.78\n","episode: 163   score: 3.0   memory length: 31731   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.75\n","episode: 164   score: 2.0   memory length: 31930   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 165   score: 2.0   memory length: 32129   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.77\n","episode: 166   score: 2.0   memory length: 32347   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.77\n","episode: 167   score: 0.0   memory length: 32471   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.76\n","episode: 168   score: 0.0   memory length: 32594   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.74\n","episode: 169   score: 0.0   memory length: 32718   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.72\n","episode: 170   score: 0.0   memory length: 32841   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.71\n","episode: 171   score: 1.0   memory length: 33010   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.71\n","episode: 172   score: 2.0   memory length: 33193   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.69\n","episode: 173   score: 3.0   memory length: 33460   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.69\n","episode: 174   score: 2.0   memory length: 33680   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.71\n","episode: 175   score: 3.0   memory length: 33906   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.74\n","episode: 176   score: 3.0   memory length: 34133   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.75\n","episode: 177   score: 2.0   memory length: 34332   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 178   score: 1.0   memory length: 34501   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.77\n","episode: 179   score: 1.0   memory length: 34652   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.75\n","episode: 180   score: 0.0   memory length: 34776   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.75\n","episode: 181   score: 2.0   memory length: 34994   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.75\n","episode: 182   score: 0.0   memory length: 35118   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.74\n","episode: 183   score: 2.0   memory length: 35317   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 184   score: 2.0   memory length: 35536   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.78\n","episode: 185   score: 2.0   memory length: 35735   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.8\n","episode: 186   score: 3.0   memory length: 35984   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.82\n","episode: 187   score: 3.0   memory length: 36211   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.85\n","episode: 188   score: 0.0   memory length: 36335   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.84\n","episode: 189   score: 0.0   memory length: 36459   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.75\n","episode: 190   score: 2.0   memory length: 36640   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.77\n","episode: 191   score: 2.0   memory length: 36839   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.78\n","episode: 192   score: 2.0   memory length: 37024   epsilon: 1.0    steps: 185    lr: 0.0001     evaluation reward: 1.8\n","episode: 193   score: 2.0   memory length: 37244   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.79\n","episode: 194   score: 1.0   memory length: 37396   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.78\n","episode: 195   score: 1.0   memory length: 37548   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.77\n","episode: 196   score: 3.0   memory length: 37775   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.78\n","episode: 197   score: 0.0   memory length: 37899   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.75\n","episode: 198   score: 6.0   memory length: 38265   epsilon: 1.0    steps: 366    lr: 0.0001     evaluation reward: 1.79\n","episode: 199   score: 1.0   memory length: 38438   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.78\n","episode: 200   score: 2.0   memory length: 38637   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.75\n","episode: 201   score: 0.0   memory length: 38760   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.73\n","episode: 202   score: 3.0   memory length: 38989   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.75\n","episode: 203   score: 3.0   memory length: 39238   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.77\n","episode: 204   score: 9.0   memory length: 39629   epsilon: 1.0    steps: 391    lr: 0.0001     evaluation reward: 1.85\n","episode: 205   score: 2.0   memory length: 39828   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.83\n","episode: 206   score: 1.0   memory length: 39998   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.83\n","episode: 207   score: 2.0   memory length: 40217   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.85\n","episode: 208   score: 0.0   memory length: 40341   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.85\n","episode: 209   score: 1.0   memory length: 40493   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.85\n","episode: 210   score: 2.0   memory length: 40712   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.83\n","episode: 211   score: 3.0   memory length: 40975   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.84\n","episode: 212   score: 3.0   memory length: 41205   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.87\n","episode: 213   score: 2.0   memory length: 41404   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.86\n","episode: 214   score: 1.0   memory length: 41555   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.84\n","episode: 215   score: 2.0   memory length: 41753   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.83\n","episode: 216   score: 1.0   memory length: 41924   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.84\n","episode: 217   score: 1.0   memory length: 42097   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.8\n","episode: 218   score: 3.0   memory length: 42343   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.81\n","episode: 219   score: 3.0   memory length: 42589   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.81\n","episode: 220   score: 0.0   memory length: 42713   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.79\n","episode: 221   score: 0.0   memory length: 42837   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.78\n","episode: 222   score: 0.0   memory length: 42961   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.76\n","episode: 223   score: 0.0   memory length: 43085   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.73\n","episode: 224   score: 1.0   memory length: 43254   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.71\n","episode: 225   score: 0.0   memory length: 43378   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 226   score: 0.0   memory length: 43502   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 227   score: 3.0   memory length: 43734   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.72\n","episode: 228   score: 3.0   memory length: 43980   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.74\n","episode: 229   score: 2.0   memory length: 44199   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.75\n","episode: 230   score: 0.0   memory length: 44323   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 231   score: 1.0   memory length: 44493   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.69\n","episode: 232   score: 0.0   memory length: 44617   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 233   score: 3.0   memory length: 44865   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.7\n","episode: 234   score: 1.0   memory length: 45034   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.69\n","episode: 235   score: 3.0   memory length: 45280   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.71\n","episode: 236   score: 0.0   memory length: 45404   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 237   score: 0.0   memory length: 45528   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 238   score: 2.0   memory length: 45727   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.68\n","episode: 239   score: 0.0   memory length: 45851   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.67\n","episode: 240   score: 4.0   memory length: 46128   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.7\n","episode: 241   score: 2.0   memory length: 46347   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.7\n","episode: 242   score: 3.0   memory length: 46559   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.71\n","episode: 243   score: 1.0   memory length: 46729   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.71\n","episode: 244   score: 2.0   memory length: 46928   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.73\n","episode: 245   score: 0.0   memory length: 47052   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.7\n","episode: 246   score: 0.0   memory length: 47175   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n","episode: 247   score: 1.0   memory length: 47345   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.65\n","episode: 248   score: 2.0   memory length: 47545   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.65\n","episode: 249   score: 1.0   memory length: 47715   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\n","episode: 250   score: 0.0   memory length: 47839   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n","episode: 251   score: 0.0   memory length: 47963   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 252   score: 2.0   memory length: 48163   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6\n","episode: 253   score: 2.0   memory length: 48382   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.6\n","episode: 254   score: 3.0   memory length: 48632   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.62\n","episode: 255   score: 2.0   memory length: 48831   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.64\n","episode: 256   score: 1.0   memory length: 49000   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n","episode: 257   score: 1.0   memory length: 49170   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.64\n","episode: 258   score: 0.0   memory length: 49294   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n","episode: 259   score: 3.0   memory length: 49542   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.58\n","episode: 260   score: 1.0   memory length: 49694   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.59\n","episode: 261   score: 2.0   memory length: 49895   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.59\n","episode: 262   score: 0.0   memory length: 50018   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 263   score: 3.0   memory length: 50286   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.57\n","episode: 264   score: 3.0   memory length: 50555   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.58\n","episode: 265   score: 2.0   memory length: 50753   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n","episode: 266   score: 1.0   memory length: 50923   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.57\n","episode: 267   score: 1.0   memory length: 51094   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.58\n","episode: 268   score: 2.0   memory length: 51292   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6\n","episode: 269   score: 0.0   memory length: 51416   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 270   score: 1.0   memory length: 51568   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.61\n","episode: 271   score: 2.0   memory length: 51767   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.62\n","episode: 272   score: 0.0   memory length: 51891   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 273   score: 1.0   memory length: 52061   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.58\n","episode: 274   score: 0.0   memory length: 52185   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n","episode: 275   score: 2.0   memory length: 52365   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.55\n","episode: 276   score: 1.0   memory length: 52537   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.53\n","episode: 277   score: 2.0   memory length: 52756   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.53\n","episode: 278   score: 1.0   memory length: 52928   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.53\n","episode: 279   score: 1.0   memory length: 53079   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.53\n","episode: 280   score: 0.0   memory length: 53203   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 281   score: 0.0   memory length: 53327   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 282   score: 1.0   memory length: 53479   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.52\n","episode: 283   score: 2.0   memory length: 53678   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 284   score: 2.0   memory length: 53877   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 285   score: 1.0   memory length: 54047   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.51\n","episode: 286   score: 1.0   memory length: 54198   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\n","episode: 287   score: 2.0   memory length: 54397   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.48\n","episode: 288   score: 3.0   memory length: 54666   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.51\n","episode: 289   score: 2.0   memory length: 54864   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n","episode: 290   score: 3.0   memory length: 55135   epsilon: 1.0    steps: 271    lr: 0.0001     evaluation reward: 1.54\n","episode: 291   score: 1.0   memory length: 55287   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.53\n","episode: 292   score: 1.0   memory length: 55439   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.52\n","episode: 293   score: 2.0   memory length: 55638   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 294   score: 2.0   memory length: 55819   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.53\n","episode: 295   score: 3.0   memory length: 56046   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.55\n","episode: 296   score: 0.0   memory length: 56170   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.52\n","episode: 297   score: 0.0   memory length: 56294   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.52\n","episode: 298   score: 1.0   memory length: 56446   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.47\n","episode: 299   score: 3.0   memory length: 56694   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.49\n","episode: 300   score: 2.0   memory length: 56877   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.49\n","episode: 301   score: 2.0   memory length: 57080   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.51\n","episode: 302   score: 1.0   memory length: 57231   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\n","episode: 303   score: 2.0   memory length: 57430   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.48\n","episode: 304   score: 1.0   memory length: 57600   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.4\n","episode: 305   score: 2.0   memory length: 57799   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n","episode: 306   score: 0.0   memory length: 57923   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 307   score: 1.0   memory length: 58093   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n","episode: 308   score: 1.0   memory length: 58245   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.39\n","episode: 309   score: 1.0   memory length: 58414   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\n","episode: 310   score: 2.0   memory length: 58612   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.39\n","episode: 311   score: 1.0   memory length: 58782   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.37\n","episode: 312   score: 5.0   memory length: 59101   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.39\n","episode: 313   score: 0.0   memory length: 59225   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.37\n","episode: 314   score: 0.0   memory length: 59349   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 315   score: 2.0   memory length: 59530   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.36\n","episode: 316   score: 0.0   memory length: 59654   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 317   score: 0.0   memory length: 59778   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 318   score: 2.0   memory length: 59977   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.33\n","episode: 319   score: 2.0   memory length: 60177   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.32\n","episode: 320   score: 0.0   memory length: 60300   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 321   score: 2.0   memory length: 60485   epsilon: 1.0    steps: 185    lr: 0.0001     evaluation reward: 1.34\n","episode: 322   score: 0.0   memory length: 60609   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 323   score: 2.0   memory length: 60826   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.36\n","episode: 324   score: 2.0   memory length: 61046   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.37\n","episode: 325   score: 1.0   memory length: 61219   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.38\n","episode: 326   score: 3.0   memory length: 61470   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.41\n","episode: 327   score: 0.0   memory length: 61594   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 328   score: 2.0   memory length: 61793   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.37\n","episode: 329   score: 4.0   memory length: 62089   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.39\n","episode: 330   score: 0.0   memory length: 62213   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 331   score: 3.0   memory length: 62443   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.41\n","episode: 332   score: 3.0   memory length: 62714   epsilon: 1.0    steps: 271    lr: 0.0001     evaluation reward: 1.44\n","episode: 333   score: 0.0   memory length: 62838   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 334   score: 1.0   memory length: 63008   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\n","episode: 335   score: 4.0   memory length: 63307   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.42\n","episode: 336   score: 0.0   memory length: 63430   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 337   score: 2.0   memory length: 63647   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.44\n","episode: 338   score: 0.0   memory length: 63771   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 339   score: 2.0   memory length: 63991   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.44\n","episode: 340   score: 1.0   memory length: 64163   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.41\n","episode: 341   score: 1.0   memory length: 64316   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.4\n","episode: 342   score: 0.0   memory length: 64440   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.37\n","episode: 343   score: 2.0   memory length: 64638   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n","episode: 344   score: 1.0   memory length: 64790   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.37\n","episode: 345   score: 3.0   memory length: 65037   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.4\n","episode: 346   score: 0.0   memory length: 65161   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4\n","episode: 347   score: 2.0   memory length: 65359   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\n","episode: 348   score: 3.0   memory length: 65604   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.42\n","episode: 349   score: 1.0   memory length: 65774   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.42\n","episode: 350   score: 0.0   memory length: 65897   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 351   score: 2.0   memory length: 66097   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.44\n","episode: 352   score: 0.0   memory length: 66221   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 353   score: 1.0   memory length: 66391   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\n","episode: 354   score: 0.0   memory length: 66514   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 355   score: 0.0   memory length: 66638   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 356   score: 2.0   memory length: 66859   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.37\n","episode: 357   score: 2.0   memory length: 67058   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.38\n","episode: 358   score: 2.0   memory length: 67257   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n","episode: 359   score: 3.0   memory length: 67471   epsilon: 1.0    steps: 214    lr: 0.0001     evaluation reward: 1.4\n","episode: 360   score: 0.0   memory length: 67595   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 361   score: 0.0   memory length: 67718   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 362   score: 1.0   memory length: 67888   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n","episode: 363   score: 1.0   memory length: 68039   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n","episode: 364   score: 1.0   memory length: 68209   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n","episode: 365   score: 2.0   memory length: 68427   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.34\n","episode: 366   score: 2.0   memory length: 68625   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\n","episode: 367   score: 0.0   memory length: 68749   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 368   score: 2.0   memory length: 68948   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.34\n","episode: 369   score: 2.0   memory length: 69130   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.36\n","episode: 370   score: 3.0   memory length: 69357   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.38\n","episode: 371   score: 0.0   memory length: 69481   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 372   score: 0.0   memory length: 69605   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 373   score: 2.0   memory length: 69803   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\n","episode: 374   score: 3.0   memory length: 70032   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.4\n","episode: 375   score: 0.0   memory length: 70156   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 376   score: 0.0   memory length: 70280   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.37\n","episode: 377   score: 1.0   memory length: 70449   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.36\n","episode: 378   score: 1.0   memory length: 70620   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.36\n","episode: 379   score: 2.0   memory length: 70836   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.37\n","episode: 380   score: 1.0   memory length: 70989   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.38\n","episode: 381   score: 1.0   memory length: 71158   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\n","episode: 382   score: 3.0   memory length: 71423   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.41\n","episode: 383   score: 1.0   memory length: 71575   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 384   score: 2.0   memory length: 71792   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\n","episode: 385   score: 1.0   memory length: 71963   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n","episode: 386   score: 1.0   memory length: 72132   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n","episode: 387   score: 1.0   memory length: 72302   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\n","episode: 388   score: 0.0   memory length: 72425   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 389   score: 0.0   memory length: 72548   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 390   score: 4.0   memory length: 72827   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.35\n","episode: 391   score: 0.0   memory length: 72951   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 392   score: 2.0   memory length: 73168   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.35\n","episode: 393   score: 1.0   memory length: 73319   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.34\n","episode: 394   score: 3.0   memory length: 73567   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.35\n","episode: 395   score: 0.0   memory length: 73691   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 396   score: 2.0   memory length: 73890   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.34\n","episode: 397   score: 1.0   memory length: 74059   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n","episode: 398   score: 1.0   memory length: 74210   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.35\n","episode: 399   score: 1.0   memory length: 74361   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.33\n","episode: 400   score: 2.0   memory length: 74562   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.33\n","episode: 401   score: 1.0   memory length: 74714   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.32\n","episode: 402   score: 4.0   memory length: 75030   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.35\n","episode: 403   score: 1.0   memory length: 75200   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n","episode: 404   score: 1.0   memory length: 75371   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.34\n","episode: 405   score: 1.0   memory length: 75523   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.33\n","episode: 406   score: 3.0   memory length: 75771   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.36\n","episode: 407   score: 1.0   memory length: 75943   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.36\n","episode: 408   score: 2.0   memory length: 76142   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.37\n","episode: 409   score: 2.0   memory length: 76342   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.38\n","episode: 410   score: 3.0   memory length: 76609   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.39\n","episode: 411   score: 3.0   memory length: 76856   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.41\n","episode: 412   score: 2.0   memory length: 77054   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n","episode: 413   score: 0.0   memory length: 77178   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 414   score: 3.0   memory length: 77446   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.41\n","episode: 415   score: 2.0   memory length: 77665   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.41\n","episode: 416   score: 2.0   memory length: 77882   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.43\n","episode: 417   score: 4.0   memory length: 78144   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.47\n","episode: 418   score: 0.0   memory length: 78267   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 419   score: 1.0   memory length: 78437   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.44\n","episode: 420   score: 2.0   memory length: 78636   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\n","episode: 421   score: 0.0   memory length: 78759   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n","episode: 422   score: 1.0   memory length: 78929   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n","episode: 423   score: 2.0   memory length: 79131   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.45\n","episode: 424   score: 2.0   memory length: 79330   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.45\n","episode: 425   score: 3.0   memory length: 79560   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.47\n","episode: 426   score: 1.0   memory length: 79731   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.45\n","episode: 427   score: 0.0   memory length: 79854   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 428   score: 3.0   memory length: 80101   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.46\n","episode: 429   score: 1.0   memory length: 80271   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.43\n","episode: 430   score: 1.0   memory length: 80423   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.44\n","episode: 431   score: 1.0   memory length: 80595   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.42\n","episode: 432   score: 0.0   memory length: 80719   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 433   score: 1.0   memory length: 80871   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 434   score: 0.0   memory length: 80994   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 435   score: 3.0   memory length: 81242   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.38\n","episode: 436   score: 0.0   memory length: 81366   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 437   score: 2.0   memory length: 81585   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.38\n","episode: 438   score: 0.0   memory length: 81709   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 439   score: 2.0   memory length: 81928   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.38\n","episode: 440   score: 1.0   memory length: 82099   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.38\n","episode: 441   score: 0.0   memory length: 82222   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 442   score: 3.0   memory length: 82449   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.4\n","episode: 443   score: 5.0   memory length: 82735   epsilon: 1.0    steps: 286    lr: 0.0001     evaluation reward: 1.43\n","episode: 444   score: 2.0   memory length: 82933   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n","episode: 445   score: 1.0   memory length: 83105   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.42\n","episode: 446   score: 2.0   memory length: 83323   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.44\n","episode: 447   score: 0.0   memory length: 83446   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 448   score: 1.0   memory length: 83616   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.4\n","episode: 449   score: 0.0   memory length: 83740   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 450   score: 0.0   memory length: 83864   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 451   score: 0.0   memory length: 83988   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.37\n","episode: 452   score: 2.0   memory length: 84171   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.39\n","episode: 453   score: 2.0   memory length: 84370   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n","episode: 454   score: 1.0   memory length: 84521   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\n","episode: 455   score: 5.0   memory length: 84889   epsilon: 1.0    steps: 368    lr: 0.0001     evaluation reward: 1.46\n","episode: 456   score: 1.0   memory length: 85041   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.45\n","episode: 457   score: 2.0   memory length: 85258   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.45\n","episode: 458   score: 0.0   memory length: 85381   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 459   score: 1.0   memory length: 85533   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.41\n","episode: 460   score: 0.0   memory length: 85656   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 461   score: 3.0   memory length: 85903   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.44\n","episode: 462   score: 4.0   memory length: 86201   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.47\n","episode: 463   score: 3.0   memory length: 86467   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.49\n","episode: 464   score: 0.0   memory length: 86591   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n","episode: 465   score: 0.0   memory length: 86715   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n","episode: 466   score: 1.0   memory length: 86886   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.45\n","episode: 467   score: 1.0   memory length: 87039   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.46\n","episode: 468   score: 0.0   memory length: 87163   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 469   score: 3.0   memory length: 87392   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.45\n","episode: 470   score: 1.0   memory length: 87564   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.43\n","episode: 471   score: 0.0   memory length: 87688   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 472   score: 0.0   memory length: 87812   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 473   score: 2.0   memory length: 88034   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.43\n","episode: 474   score: 1.0   memory length: 88186   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.41\n","episode: 475   score: 3.0   memory length: 88455   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.44\n","episode: 476   score: 0.0   memory length: 88579   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 477   score: 0.0   memory length: 88702   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 478   score: 2.0   memory length: 88921   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.44\n","episode: 479   score: 1.0   memory length: 89090   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n","episode: 480   score: 0.0   memory length: 89213   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 481   score: 1.0   memory length: 89386   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.42\n","episode: 482   score: 2.0   memory length: 89607   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.41\n","episode: 483   score: 0.0   memory length: 89731   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4\n","episode: 484   score: 2.0   memory length: 89950   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n","episode: 485   score: 1.0   memory length: 90121   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n","episode: 486   score: 3.0   memory length: 90369   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.42\n","episode: 487   score: 0.0   memory length: 90493   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 488   score: 5.0   memory length: 90859   epsilon: 1.0    steps: 366    lr: 0.0001     evaluation reward: 1.46\n","episode: 489   score: 0.0   memory length: 90983   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n","episode: 490   score: 2.0   memory length: 91169   epsilon: 1.0    steps: 186    lr: 0.0001     evaluation reward: 1.44\n","episode: 491   score: 2.0   memory length: 91370   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.46\n","episode: 492   score: 2.0   memory length: 91592   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.46\n","episode: 493   score: 1.0   memory length: 91743   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n","episode: 494   score: 0.0   memory length: 91867   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 495   score: 2.0   memory length: 92065   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\n","episode: 496   score: 1.0   memory length: 92234   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n","episode: 497   score: 7.0   memory length: 92657   epsilon: 1.0    steps: 423    lr: 0.0001     evaluation reward: 1.5\n","episode: 498   score: 0.0   memory length: 92780   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 499   score: 0.0   memory length: 92904   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n","episode: 500   score: 4.0   memory length: 93199   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.5\n","episode: 501   score: 3.0   memory length: 93466   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.52\n","episode: 502   score: 3.0   memory length: 93714   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.51\n","episode: 503   score: 3.0   memory length: 93961   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.53\n","episode: 504   score: 3.0   memory length: 94190   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.55\n","episode: 505   score: 0.0   memory length: 94314   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 506   score: 0.0   memory length: 94438   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 507   score: 3.0   memory length: 94683   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.53\n","episode: 508   score: 1.0   memory length: 94836   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.52\n","episode: 509   score: 1.0   memory length: 95005   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\n","episode: 510   score: 2.0   memory length: 95203   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n","episode: 511   score: 2.0   memory length: 95423   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.49\n","episode: 512   score: 3.0   memory length: 95668   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.5\n","episode: 513   score: 1.0   memory length: 95840   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\n","episode: 514   score: 5.0   memory length: 96162   epsilon: 1.0    steps: 322    lr: 0.0001     evaluation reward: 1.53\n","episode: 515   score: 3.0   memory length: 96410   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.54\n","episode: 516   score: 1.0   memory length: 96562   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.53\n","episode: 517   score: 1.0   memory length: 96732   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5\n","episode: 518   score: 1.0   memory length: 96904   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\n","episode: 519   score: 0.0   memory length: 97027   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 520   score: 1.0   memory length: 97199   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.49\n","episode: 521   score: 0.0   memory length: 97323   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.49\n","episode: 522   score: 1.0   memory length: 97474   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\n","episode: 523   score: 1.0   memory length: 97647   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.48\n","episode: 524   score: 1.0   memory length: 97799   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.47\n","episode: 525   score: 2.0   memory length: 97998   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\n","episode: 526   score: 0.0   memory length: 98121   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 527   score: 0.0   memory length: 98245   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 528   score: 0.0   memory length: 98369   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 529   score: 1.0   memory length: 98539   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.42\n","episode: 530   score: 1.0   memory length: 98711   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.42\n","episode: 531   score: 0.0   memory length: 98835   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 532   score: 0.0   memory length: 98959   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 533   score: 2.0   memory length: 99177   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.42\n","episode: 534   score: 1.0   memory length: 99347   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.43\n","episode: 535   score: 3.0   memory length: 99577   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.43\n","episode: 536   score: 1.0   memory length: 99747   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.44\n","episode: 537   score: 1.0   memory length: 99917   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.43\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/assignment5_materials/memory.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  sample = np.array(sample)\n","/content/drive/MyDrive/assignment5_materials/agent.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  mini_batch = np.array(mini_batch).transpose()\n"]},{"output_type":"stream","name":"stdout","text":["episode: 538   score: 3.0   memory length: 100189   epsilon: 0.9996238000000082    steps: 272    lr: 0.0001     evaluation reward: 1.46\n","episode: 539   score: 0.0   memory length: 100312   epsilon: 0.9993802600000135    steps: 123    lr: 0.0001     evaluation reward: 1.44\n","episode: 540   score: 3.0   memory length: 100539   epsilon: 0.9989308000000232    steps: 227    lr: 0.0001     evaluation reward: 1.46\n","episode: 541   score: 0.0   memory length: 100663   epsilon: 0.9986852800000285    steps: 124    lr: 0.0001     evaluation reward: 1.46\n","episode: 542   score: 1.0   memory length: 100833   epsilon: 0.9983486800000358    steps: 170    lr: 0.0001     evaluation reward: 1.44\n","episode: 543   score: 2.0   memory length: 101052   epsilon: 0.9979150600000453    steps: 219    lr: 0.0001     evaluation reward: 1.41\n","episode: 544   score: 1.0   memory length: 101204   epsilon: 0.9976141000000518    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 545   score: 0.0   memory length: 101327   epsilon: 0.9973705600000571    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 546   score: 2.0   memory length: 101525   epsilon: 0.9969785200000656    steps: 198    lr: 0.0001     evaluation reward: 1.39\n","episode: 547   score: 2.0   memory length: 101724   epsilon: 0.9965845000000741    steps: 199    lr: 0.0001     evaluation reward: 1.41\n","episode: 548   score: 2.0   memory length: 101943   epsilon: 0.9961508800000836    steps: 219    lr: 0.0001     evaluation reward: 1.42\n","episode: 549   score: 2.0   memory length: 102126   epsilon: 0.9957885400000914    steps: 183    lr: 0.0001     evaluation reward: 1.44\n","episode: 550   score: 1.0   memory length: 102296   epsilon: 0.9954519400000987    steps: 170    lr: 0.0001     evaluation reward: 1.45\n","episode: 551   score: 0.0   memory length: 102420   epsilon: 0.9952064200001041    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 552   score: 1.0   memory length: 102572   epsilon: 0.9949054600001106    steps: 152    lr: 0.0001     evaluation reward: 1.44\n","episode: 553   score: 0.0   memory length: 102696   epsilon: 0.9946599400001159    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 554   score: 0.0   memory length: 102820   epsilon: 0.9944144200001213    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 555   score: 1.0   memory length: 102990   epsilon: 0.9940778200001286    steps: 170    lr: 0.0001     evaluation reward: 1.37\n","episode: 556   score: 0.0   memory length: 103114   epsilon: 0.9938323000001339    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 557   score: 2.0   memory length: 103333   epsilon: 0.9933986800001433    steps: 219    lr: 0.0001     evaluation reward: 1.36\n","episode: 558   score: 1.0   memory length: 103506   epsilon: 0.9930561400001507    steps: 173    lr: 0.0001     evaluation reward: 1.37\n","episode: 559   score: 0.0   memory length: 103630   epsilon: 0.9928106200001561    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 560   score: 0.0   memory length: 103754   epsilon: 0.9925651000001614    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 561   score: 1.0   memory length: 103905   epsilon: 0.9922661200001679    steps: 151    lr: 0.0001     evaluation reward: 1.34\n","episode: 562   score: 1.0   memory length: 104077   epsilon: 0.9919255600001753    steps: 172    lr: 0.0001     evaluation reward: 1.31\n","episode: 563   score: 0.0   memory length: 104201   epsilon: 0.9916800400001806    steps: 124    lr: 0.0001     evaluation reward: 1.28\n","episode: 564   score: 5.0   memory length: 104530   epsilon: 0.9910286200001948    steps: 329    lr: 0.0001     evaluation reward: 1.33\n","episode: 565   score: 1.0   memory length: 104700   epsilon: 0.9906920200002021    steps: 170    lr: 0.0001     evaluation reward: 1.34\n","episode: 566   score: 1.0   memory length: 104852   epsilon: 0.9903910600002086    steps: 152    lr: 0.0001     evaluation reward: 1.34\n","episode: 567   score: 2.0   memory length: 105050   epsilon: 0.9899990200002171    steps: 198    lr: 0.0001     evaluation reward: 1.35\n","episode: 568   score: 0.0   memory length: 105173   epsilon: 0.9897554800002224    steps: 123    lr: 0.0001     evaluation reward: 1.35\n","episode: 569   score: 1.0   memory length: 105344   epsilon: 0.9894169000002297    steps: 171    lr: 0.0001     evaluation reward: 1.33\n","episode: 570   score: 2.0   memory length: 105543   epsilon: 0.9890228800002383    steps: 199    lr: 0.0001     evaluation reward: 1.34\n","episode: 571   score: 2.0   memory length: 105761   epsilon: 0.9885912400002477    steps: 218    lr: 0.0001     evaluation reward: 1.36\n","episode: 572   score: 3.0   memory length: 105990   epsilon: 0.9881378200002575    steps: 229    lr: 0.0001     evaluation reward: 1.39\n","episode: 573   score: 2.0   memory length: 106188   epsilon: 0.987745780000266    steps: 198    lr: 0.0001     evaluation reward: 1.39\n","episode: 574   score: 2.0   memory length: 106407   epsilon: 0.9873121600002754    steps: 219    lr: 0.0001     evaluation reward: 1.4\n","episode: 575   score: 1.0   memory length: 106579   epsilon: 0.9869716000002828    steps: 172    lr: 0.0001     evaluation reward: 1.38\n","episode: 576   score: 4.0   memory length: 106876   epsilon: 0.9863835400002956    steps: 297    lr: 0.0001     evaluation reward: 1.42\n","episode: 577   score: 0.0   memory length: 107000   epsilon: 0.9861380200003009    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 578   score: 1.0   memory length: 107170   epsilon: 0.9858014200003082    steps: 170    lr: 0.0001     evaluation reward: 1.41\n","episode: 579   score: 3.0   memory length: 107402   epsilon: 0.9853420600003182    steps: 232    lr: 0.0001     evaluation reward: 1.43\n","episode: 580   score: 2.0   memory length: 107619   epsilon: 0.9849124000003275    steps: 217    lr: 0.0001     evaluation reward: 1.45\n","episode: 581   score: 1.0   memory length: 107789   epsilon: 0.9845758000003348    steps: 170    lr: 0.0001     evaluation reward: 1.45\n","episode: 582   score: 1.0   memory length: 107962   epsilon: 0.9842332600003423    steps: 173    lr: 0.0001     evaluation reward: 1.44\n","episode: 583   score: 0.0   memory length: 108086   epsilon: 0.9839877400003476    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 584   score: 1.0   memory length: 108256   epsilon: 0.9836511400003549    steps: 170    lr: 0.0001     evaluation reward: 1.43\n","episode: 585   score: 0.0   memory length: 108380   epsilon: 0.9834056200003602    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 586   score: 2.0   memory length: 108579   epsilon: 0.9830116000003688    steps: 199    lr: 0.0001     evaluation reward: 1.41\n","episode: 587   score: 2.0   memory length: 108798   epsilon: 0.9825779800003782    steps: 219    lr: 0.0001     evaluation reward: 1.43\n","episode: 588   score: 1.0   memory length: 108968   epsilon: 0.9822413800003855    steps: 170    lr: 0.0001     evaluation reward: 1.39\n","episode: 589   score: 3.0   memory length: 109235   epsilon: 0.981712720000397    steps: 267    lr: 0.0001     evaluation reward: 1.42\n","episode: 590   score: 0.0   memory length: 109358   epsilon: 0.9814691800004023    steps: 123    lr: 0.0001     evaluation reward: 1.4\n","episode: 591   score: 3.0   memory length: 109605   epsilon: 0.9809801200004129    steps: 247    lr: 0.0001     evaluation reward: 1.41\n","episode: 592   score: 2.0   memory length: 109805   epsilon: 0.9805841200004215    steps: 200    lr: 0.0001     evaluation reward: 1.41\n","episode: 593   score: 0.0   memory length: 109928   epsilon: 0.9803405800004268    steps: 123    lr: 0.0001     evaluation reward: 1.4\n","episode: 594   score: 2.0   memory length: 110111   epsilon: 0.9799782400004347    steps: 183    lr: 0.0001     evaluation reward: 1.42\n","episode: 595   score: 2.0   memory length: 110310   epsilon: 0.9795842200004432    steps: 199    lr: 0.0001     evaluation reward: 1.42\n","episode: 596   score: 2.0   memory length: 110529   epsilon: 0.9791506000004526    steps: 219    lr: 0.0001     evaluation reward: 1.43\n","episode: 597   score: 1.0   memory length: 110681   epsilon: 0.9788496400004592    steps: 152    lr: 0.0001     evaluation reward: 1.37\n","episode: 598   score: 0.0   memory length: 110804   epsilon: 0.9786061000004644    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 599   score: 2.0   memory length: 110985   epsilon: 0.9782477200004722    steps: 181    lr: 0.0001     evaluation reward: 1.39\n","episode: 600   score: 0.0   memory length: 111109   epsilon: 0.9780022000004776    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 601   score: 2.0   memory length: 111329   epsilon: 0.977566600000487    steps: 220    lr: 0.0001     evaluation reward: 1.34\n","episode: 602   score: 1.0   memory length: 111498   epsilon: 0.9772319800004943    steps: 169    lr: 0.0001     evaluation reward: 1.32\n","episode: 603   score: 0.0   memory length: 111621   epsilon: 0.9769884400004996    steps: 123    lr: 0.0001     evaluation reward: 1.29\n","episode: 604   score: 7.0   memory length: 111922   epsilon: 0.9763924600005125    steps: 301    lr: 0.0001     evaluation reward: 1.33\n","episode: 605   score: 2.0   memory length: 112121   epsilon: 0.975998440000521    steps: 199    lr: 0.0001     evaluation reward: 1.35\n","episode: 606   score: 0.0   memory length: 112244   epsilon: 0.9757549000005263    steps: 123    lr: 0.0001     evaluation reward: 1.35\n","episode: 607   score: 0.0   memory length: 112367   epsilon: 0.9755113600005316    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 608   score: 4.0   memory length: 112663   epsilon: 0.9749252800005443    steps: 296    lr: 0.0001     evaluation reward: 1.35\n","episode: 609   score: 0.0   memory length: 112787   epsilon: 0.9746797600005497    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 610   score: 2.0   memory length: 113004   epsilon: 0.974250100000559    steps: 217    lr: 0.0001     evaluation reward: 1.34\n","episode: 611   score: 2.0   memory length: 113208   epsilon: 0.9738461800005678    steps: 204    lr: 0.0001     evaluation reward: 1.34\n","episode: 612   score: 1.0   memory length: 113378   epsilon: 0.9735095800005751    steps: 170    lr: 0.0001     evaluation reward: 1.32\n","episode: 613   score: 1.0   memory length: 113531   epsilon: 0.9732066400005817    steps: 153    lr: 0.0001     evaluation reward: 1.32\n","episode: 614   score: 2.0   memory length: 113712   epsilon: 0.9728482600005894    steps: 181    lr: 0.0001     evaluation reward: 1.29\n","episode: 615   score: 1.0   memory length: 113881   epsilon: 0.9725136400005967    steps: 169    lr: 0.0001     evaluation reward: 1.27\n","episode: 616   score: 2.0   memory length: 114085   epsilon: 0.9721097200006055    steps: 204    lr: 0.0001     evaluation reward: 1.28\n","episode: 617   score: 1.0   memory length: 114257   epsilon: 0.9717691600006129    steps: 172    lr: 0.0001     evaluation reward: 1.28\n","episode: 618   score: 2.0   memory length: 114455   epsilon: 0.9713771200006214    steps: 198    lr: 0.0001     evaluation reward: 1.29\n","episode: 619   score: 1.0   memory length: 114607   epsilon: 0.9710761600006279    steps: 152    lr: 0.0001     evaluation reward: 1.3\n","episode: 620   score: 1.0   memory length: 114777   epsilon: 0.9707395600006352    steps: 170    lr: 0.0001     evaluation reward: 1.3\n","episode: 621   score: 3.0   memory length: 115021   epsilon: 0.9702564400006457    steps: 244    lr: 0.0001     evaluation reward: 1.33\n","episode: 622   score: 3.0   memory length: 115268   epsilon: 0.9697673800006563    steps: 247    lr: 0.0001     evaluation reward: 1.35\n","episode: 623   score: 2.0   memory length: 115468   epsilon: 0.9693713800006649    steps: 200    lr: 0.0001     evaluation reward: 1.36\n","episode: 624   score: 1.0   memory length: 115638   epsilon: 0.9690347800006722    steps: 170    lr: 0.0001     evaluation reward: 1.36\n","episode: 625   score: 1.0   memory length: 115810   epsilon: 0.9686942200006796    steps: 172    lr: 0.0001     evaluation reward: 1.35\n","episode: 626   score: 2.0   memory length: 116009   epsilon: 0.9683002000006882    steps: 199    lr: 0.0001     evaluation reward: 1.37\n","episode: 627   score: 2.0   memory length: 116207   epsilon: 0.9679081600006967    steps: 198    lr: 0.0001     evaluation reward: 1.39\n","episode: 628   score: 1.0   memory length: 116379   epsilon: 0.9675676000007041    steps: 172    lr: 0.0001     evaluation reward: 1.4\n","episode: 629   score: 1.0   memory length: 116550   epsilon: 0.9672290200007114    steps: 171    lr: 0.0001     evaluation reward: 1.4\n","episode: 630   score: 1.0   memory length: 116723   epsilon: 0.9668864800007189    steps: 173    lr: 0.0001     evaluation reward: 1.4\n","episode: 631   score: 2.0   memory length: 116922   epsilon: 0.9664924600007274    steps: 199    lr: 0.0001     evaluation reward: 1.42\n","episode: 632   score: 0.0   memory length: 117046   epsilon: 0.9662469400007327    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 633   score: 0.0   memory length: 117170   epsilon: 0.9660014200007381    steps: 124    lr: 0.0001     evaluation reward: 1.4\n","episode: 634   score: 2.0   memory length: 117368   epsilon: 0.9656093800007466    steps: 198    lr: 0.0001     evaluation reward: 1.41\n","episode: 635   score: 1.0   memory length: 117519   epsilon: 0.9653104000007531    steps: 151    lr: 0.0001     evaluation reward: 1.39\n","episode: 636   score: 2.0   memory length: 117718   epsilon: 0.9649163800007616    steps: 199    lr: 0.0001     evaluation reward: 1.4\n","episode: 637   score: 0.0   memory length: 117842   epsilon: 0.964670860000767    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 638   score: 0.0   memory length: 117966   epsilon: 0.9644253400007723    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 639   score: 0.0   memory length: 118089   epsilon: 0.9641818000007776    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 640   score: 1.0   memory length: 118260   epsilon: 0.9638432200007849    steps: 171    lr: 0.0001     evaluation reward: 1.34\n","episode: 641   score: 0.0   memory length: 118383   epsilon: 0.9635996800007902    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 642   score: 2.0   memory length: 118582   epsilon: 0.9632056600007988    steps: 199    lr: 0.0001     evaluation reward: 1.35\n","episode: 643   score: 1.0   memory length: 118734   epsilon: 0.9629047000008053    steps: 152    lr: 0.0001     evaluation reward: 1.34\n","episode: 644   score: 3.0   memory length: 118981   epsilon: 0.9624156400008159    steps: 247    lr: 0.0001     evaluation reward: 1.36\n","episode: 645   score: 2.0   memory length: 119180   epsilon: 0.9620216200008245    steps: 199    lr: 0.0001     evaluation reward: 1.38\n","episode: 646   score: 2.0   memory length: 119378   epsilon: 0.961629580000833    steps: 198    lr: 0.0001     evaluation reward: 1.38\n","episode: 647   score: 1.0   memory length: 119548   epsilon: 0.9612929800008403    steps: 170    lr: 0.0001     evaluation reward: 1.37\n","episode: 648   score: 2.0   memory length: 119747   epsilon: 0.9608989600008488    steps: 199    lr: 0.0001     evaluation reward: 1.37\n","episode: 649   score: 1.0   memory length: 119899   epsilon: 0.9605980000008554    steps: 152    lr: 0.0001     evaluation reward: 1.36\n","episode: 650   score: 1.0   memory length: 120069   epsilon: 0.9602614000008627    steps: 170    lr: 0.0001     evaluation reward: 1.36\n","episode: 651   score: 0.0   memory length: 120193   epsilon: 0.960015880000868    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 652   score: 0.0   memory length: 120317   epsilon: 0.9597703600008733    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 653   score: 3.0   memory length: 120544   epsilon: 0.9593209000008831    steps: 227    lr: 0.0001     evaluation reward: 1.38\n","episode: 654   score: 1.0   memory length: 120714   epsilon: 0.9589843000008904    steps: 170    lr: 0.0001     evaluation reward: 1.39\n","episode: 655   score: 0.0   memory length: 120837   epsilon: 0.9587407600008957    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 656   score: 5.0   memory length: 121178   epsilon: 0.9580655800009104    steps: 341    lr: 0.0001     evaluation reward: 1.43\n","episode: 657   score: 3.0   memory length: 121445   epsilon: 0.9575369200009218    steps: 267    lr: 0.0001     evaluation reward: 1.44\n","episode: 658   score: 0.0   memory length: 121569   epsilon: 0.9572914000009272    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 659   score: 0.0   memory length: 121692   epsilon: 0.9570478600009324    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 660   score: 0.0   memory length: 121816   epsilon: 0.9568023400009378    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 661   score: 1.0   memory length: 121986   epsilon: 0.9564657400009451    steps: 170    lr: 0.0001     evaluation reward: 1.43\n","episode: 662   score: 4.0   memory length: 122279   epsilon: 0.9558856000009577    steps: 293    lr: 0.0001     evaluation reward: 1.46\n","episode: 663   score: 0.0   memory length: 122402   epsilon: 0.955642060000963    steps: 123    lr: 0.0001     evaluation reward: 1.46\n","episode: 664   score: 1.0   memory length: 122571   epsilon: 0.9553074400009702    steps: 169    lr: 0.0001     evaluation reward: 1.42\n","episode: 665   score: 3.0   memory length: 122820   epsilon: 0.9548144200009809    steps: 249    lr: 0.0001     evaluation reward: 1.44\n","episode: 666   score: 2.0   memory length: 123023   epsilon: 0.9544124800009897    steps: 203    lr: 0.0001     evaluation reward: 1.45\n","episode: 667   score: 5.0   memory length: 123371   epsilon: 0.9537234400010046    steps: 348    lr: 0.0001     evaluation reward: 1.48\n","episode: 668   score: 3.0   memory length: 123598   epsilon: 0.9532739800010144    steps: 227    lr: 0.0001     evaluation reward: 1.51\n","episode: 669   score: 2.0   memory length: 123796   epsilon: 0.9528819400010229    steps: 198    lr: 0.0001     evaluation reward: 1.52\n","episode: 670   score: 2.0   memory length: 123995   epsilon: 0.9524879200010314    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 671   score: 2.0   memory length: 124194   epsilon: 0.95209390000104    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 672   score: 0.0   memory length: 124318   epsilon: 0.9518483800010453    steps: 124    lr: 0.0001     evaluation reward: 1.49\n","episode: 673   score: 4.0   memory length: 124598   epsilon: 0.9512939800010574    steps: 280    lr: 0.0001     evaluation reward: 1.51\n","episode: 674   score: 0.0   memory length: 124722   epsilon: 0.9510484600010627    steps: 124    lr: 0.0001     evaluation reward: 1.49\n","episode: 675   score: 2.0   memory length: 124941   epsilon: 0.9506148400010721    steps: 219    lr: 0.0001     evaluation reward: 1.5\n","episode: 676   score: 3.0   memory length: 125170   epsilon: 0.950161420001082    steps: 229    lr: 0.0001     evaluation reward: 1.49\n","episode: 677   score: 4.0   memory length: 125469   epsilon: 0.9495694000010948    steps: 299    lr: 0.0001     evaluation reward: 1.53\n","episode: 678   score: 4.0   memory length: 125745   epsilon: 0.9490229200011067    steps: 276    lr: 0.0001     evaluation reward: 1.56\n","episode: 679   score: 2.0   memory length: 125964   epsilon: 0.9485893000011161    steps: 219    lr: 0.0001     evaluation reward: 1.55\n","episode: 680   score: 3.0   memory length: 126231   epsilon: 0.9480606400011276    steps: 267    lr: 0.0001     evaluation reward: 1.56\n","episode: 681   score: 2.0   memory length: 126447   epsilon: 0.9476329600011368    steps: 216    lr: 0.0001     evaluation reward: 1.57\n","episode: 682   score: 1.0   memory length: 126600   epsilon: 0.9473300200011434    steps: 153    lr: 0.0001     evaluation reward: 1.57\n","episode: 683   score: 0.0   memory length: 126724   epsilon: 0.9470845000011487    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 684   score: 2.0   memory length: 126923   epsilon: 0.9466904800011573    steps: 199    lr: 0.0001     evaluation reward: 1.58\n","episode: 685   score: 0.0   memory length: 127046   epsilon: 0.9464469400011626    steps: 123    lr: 0.0001     evaluation reward: 1.58\n","episode: 686   score: 1.0   memory length: 127200   epsilon: 0.9461420200011692    steps: 154    lr: 0.0001     evaluation reward: 1.57\n","episode: 687   score: 2.0   memory length: 127399   epsilon: 0.9457480000011778    steps: 199    lr: 0.0001     evaluation reward: 1.57\n","episode: 688   score: 1.0   memory length: 127551   epsilon: 0.9454470400011843    steps: 152    lr: 0.0001     evaluation reward: 1.57\n","episode: 689   score: 0.0   memory length: 127675   epsilon: 0.9452015200011896    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 690   score: 2.0   memory length: 127873   epsilon: 0.9448094800011981    steps: 198    lr: 0.0001     evaluation reward: 1.56\n","episode: 691   score: 0.0   memory length: 127997   epsilon: 0.9445639600012035    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 692   score: 2.0   memory length: 128215   epsilon: 0.9441323200012128    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 693   score: 0.0   memory length: 128338   epsilon: 0.9438887800012181    steps: 123    lr: 0.0001     evaluation reward: 1.53\n","episode: 694   score: 1.0   memory length: 128509   epsilon: 0.9435502000012255    steps: 171    lr: 0.0001     evaluation reward: 1.52\n","episode: 695   score: 3.0   memory length: 128721   epsilon: 0.9431304400012346    steps: 212    lr: 0.0001     evaluation reward: 1.53\n","episode: 696   score: 2.0   memory length: 128919   epsilon: 0.9427384000012431    steps: 198    lr: 0.0001     evaluation reward: 1.53\n","episode: 697   score: 1.0   memory length: 129089   epsilon: 0.9424018000012504    steps: 170    lr: 0.0001     evaluation reward: 1.53\n","episode: 698   score: 1.0   memory length: 129259   epsilon: 0.9420652000012577    steps: 170    lr: 0.0001     evaluation reward: 1.54\n","episode: 699   score: 0.0   memory length: 129382   epsilon: 0.941821660001263    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 700   score: 1.0   memory length: 129534   epsilon: 0.9415207000012695    steps: 152    lr: 0.0001     evaluation reward: 1.53\n","episode: 701   score: 1.0   memory length: 129705   epsilon: 0.9411821200012769    steps: 171    lr: 0.0001     evaluation reward: 1.52\n","episode: 702   score: 0.0   memory length: 129829   epsilon: 0.9409366000012822    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 703   score: 0.0   memory length: 129953   epsilon: 0.9406910800012875    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 704   score: 2.0   memory length: 130172   epsilon: 0.940257460001297    steps: 219    lr: 0.0001     evaluation reward: 1.46\n","episode: 705   score: 0.0   memory length: 130296   epsilon: 0.9400119400013023    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 706   score: 1.0   memory length: 130466   epsilon: 0.9396753400013096    steps: 170    lr: 0.0001     evaluation reward: 1.45\n","episode: 707   score: 2.0   memory length: 130664   epsilon: 0.9392833000013181    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 708   score: 4.0   memory length: 130964   epsilon: 0.938689300001331    steps: 300    lr: 0.0001     evaluation reward: 1.47\n","episode: 709   score: 3.0   memory length: 131211   epsilon: 0.9382002400013416    steps: 247    lr: 0.0001     evaluation reward: 1.5\n","episode: 710   score: 2.0   memory length: 131409   epsilon: 0.9378082000013501    steps: 198    lr: 0.0001     evaluation reward: 1.5\n","episode: 711   score: 0.0   memory length: 131533   epsilon: 0.9375626800013555    steps: 124    lr: 0.0001     evaluation reward: 1.48\n","episode: 712   score: 1.0   memory length: 131704   epsilon: 0.9372241000013628    steps: 171    lr: 0.0001     evaluation reward: 1.48\n","episode: 713   score: 1.0   memory length: 131874   epsilon: 0.9368875000013701    steps: 170    lr: 0.0001     evaluation reward: 1.48\n","episode: 714   score: 0.0   memory length: 131997   epsilon: 0.9366439600013754    steps: 123    lr: 0.0001     evaluation reward: 1.46\n","episode: 715   score: 3.0   memory length: 132242   epsilon: 0.9361588600013859    steps: 245    lr: 0.0001     evaluation reward: 1.48\n","episode: 716   score: 1.0   memory length: 132413   epsilon: 0.9358202800013933    steps: 171    lr: 0.0001     evaluation reward: 1.47\n","episode: 717   score: 1.0   memory length: 132584   epsilon: 0.9354817000014006    steps: 171    lr: 0.0001     evaluation reward: 1.47\n","episode: 718   score: 0.0   memory length: 132708   epsilon: 0.935236180001406    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 719   score: 2.0   memory length: 132909   epsilon: 0.9348382000014146    steps: 201    lr: 0.0001     evaluation reward: 1.46\n","episode: 720   score: 2.0   memory length: 133107   epsilon: 0.9344461600014231    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 721   score: 2.0   memory length: 133305   epsilon: 0.9340541200014316    steps: 198    lr: 0.0001     evaluation reward: 1.46\n","episode: 722   score: 6.0   memory length: 133641   epsilon: 0.9333888400014461    steps: 336    lr: 0.0001     evaluation reward: 1.49\n","episode: 723   score: 0.0   memory length: 133764   epsilon: 0.9331453000014513    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 724   score: 1.0   memory length: 133933   epsilon: 0.9328106800014586    steps: 169    lr: 0.0001     evaluation reward: 1.47\n","episode: 725   score: 1.0   memory length: 134103   epsilon: 0.9324740800014659    steps: 170    lr: 0.0001     evaluation reward: 1.47\n","episode: 726   score: 1.0   memory length: 134272   epsilon: 0.9321394600014732    steps: 169    lr: 0.0001     evaluation reward: 1.46\n","episode: 727   score: 0.0   memory length: 134395   epsilon: 0.9318959200014785    steps: 123    lr: 0.0001     evaluation reward: 1.44\n","episode: 728   score: 1.0   memory length: 134565   epsilon: 0.9315593200014858    steps: 170    lr: 0.0001     evaluation reward: 1.44\n","episode: 729   score: 1.0   memory length: 134716   epsilon: 0.9312603400014923    steps: 151    lr: 0.0001     evaluation reward: 1.44\n","episode: 730   score: 1.0   memory length: 134887   epsilon: 0.9309217600014996    steps: 171    lr: 0.0001     evaluation reward: 1.44\n","episode: 731   score: 0.0   memory length: 135010   epsilon: 0.9306782200015049    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 732   score: 0.0   memory length: 135134   epsilon: 0.9304327000015102    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 733   score: 1.0   memory length: 135287   epsilon: 0.9301297600015168    steps: 153    lr: 0.0001     evaluation reward: 1.43\n","episode: 734   score: 2.0   memory length: 135506   epsilon: 0.9296961400015262    steps: 219    lr: 0.0001     evaluation reward: 1.43\n","episode: 735   score: 3.0   memory length: 135754   epsilon: 0.9292051000015369    steps: 248    lr: 0.0001     evaluation reward: 1.45\n","episode: 736   score: 4.0   memory length: 136035   epsilon: 0.928648720001549    steps: 281    lr: 0.0001     evaluation reward: 1.47\n","episode: 737   score: 0.0   memory length: 136159   epsilon: 0.9284032000015543    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 738   score: 2.0   memory length: 136341   epsilon: 0.9280428400015621    steps: 182    lr: 0.0001     evaluation reward: 1.49\n","episode: 739   score: 3.0   memory length: 136587   epsilon: 0.9275557600015727    steps: 246    lr: 0.0001     evaluation reward: 1.52\n","episode: 740   score: 2.0   memory length: 136786   epsilon: 0.9271617400015812    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 741   score: 3.0   memory length: 137035   epsilon: 0.926668720001592    steps: 249    lr: 0.0001     evaluation reward: 1.56\n","episode: 742   score: 4.0   memory length: 137312   epsilon: 0.9261202600016039    steps: 277    lr: 0.0001     evaluation reward: 1.58\n","episode: 743   score: 1.0   memory length: 137464   epsilon: 0.9258193000016104    steps: 152    lr: 0.0001     evaluation reward: 1.58\n","episode: 744   score: 1.0   memory length: 137634   epsilon: 0.9254827000016177    steps: 170    lr: 0.0001     evaluation reward: 1.56\n","episode: 745   score: 1.0   memory length: 137804   epsilon: 0.925146100001625    steps: 170    lr: 0.0001     evaluation reward: 1.55\n","episode: 746   score: 0.0   memory length: 137928   epsilon: 0.9249005800016303    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 747   score: 2.0   memory length: 138130   epsilon: 0.924500620001639    steps: 202    lr: 0.0001     evaluation reward: 1.54\n","episode: 748   score: 0.0   memory length: 138253   epsilon: 0.9242570800016443    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 749   score: 1.0   memory length: 138422   epsilon: 0.9239224600016516    steps: 169    lr: 0.0001     evaluation reward: 1.52\n","episode: 750   score: 2.0   memory length: 138621   epsilon: 0.9235284400016601    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 751   score: 5.0   memory length: 138944   epsilon: 0.922888900001674    steps: 323    lr: 0.0001     evaluation reward: 1.58\n","episode: 752   score: 0.0   memory length: 139068   epsilon: 0.9226433800016793    steps: 124    lr: 0.0001     evaluation reward: 1.58\n","episode: 753   score: 3.0   memory length: 139316   epsilon: 0.92215234000169    steps: 248    lr: 0.0001     evaluation reward: 1.58\n","episode: 754   score: 3.0   memory length: 139565   epsilon: 0.9216593200017007    steps: 249    lr: 0.0001     evaluation reward: 1.6\n","episode: 755   score: 0.0   memory length: 139688   epsilon: 0.921415780001706    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 756   score: 1.0   memory length: 139861   epsilon: 0.9210732400017134    steps: 173    lr: 0.0001     evaluation reward: 1.56\n","episode: 757   score: 1.0   memory length: 140012   epsilon: 0.9207742600017199    steps: 151    lr: 0.0001     evaluation reward: 1.54\n","episode: 758   score: 2.0   memory length: 140234   epsilon: 0.9203347000017295    steps: 222    lr: 0.0001     evaluation reward: 1.56\n","episode: 759   score: 3.0   memory length: 140462   epsilon: 0.9198832600017393    steps: 228    lr: 0.0001     evaluation reward: 1.59\n","episode: 760   score: 1.0   memory length: 140632   epsilon: 0.9195466600017466    steps: 170    lr: 0.0001     evaluation reward: 1.6\n","episode: 761   score: 1.0   memory length: 140805   epsilon: 0.919204120001754    steps: 173    lr: 0.0001     evaluation reward: 1.6\n","episode: 762   score: 2.0   memory length: 141004   epsilon: 0.9188101000017626    steps: 199    lr: 0.0001     evaluation reward: 1.58\n","episode: 763   score: 3.0   memory length: 141251   epsilon: 0.9183210400017732    steps: 247    lr: 0.0001     evaluation reward: 1.61\n","episode: 764   score: 2.0   memory length: 141449   epsilon: 0.9179290000017817    steps: 198    lr: 0.0001     evaluation reward: 1.62\n","episode: 765   score: 0.0   memory length: 141572   epsilon: 0.917685460001787    steps: 123    lr: 0.0001     evaluation reward: 1.59\n","episode: 766   score: 2.0   memory length: 141771   epsilon: 0.9172914400017955    steps: 199    lr: 0.0001     evaluation reward: 1.59\n","episode: 767   score: 0.0   memory length: 141894   epsilon: 0.9170479000018008    steps: 123    lr: 0.0001     evaluation reward: 1.54\n","episode: 768   score: 2.0   memory length: 142112   epsilon: 0.9166162600018102    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 769   score: 1.0   memory length: 142263   epsilon: 0.9163172800018167    steps: 151    lr: 0.0001     evaluation reward: 1.52\n","episode: 770   score: 2.0   memory length: 142462   epsilon: 0.9159232600018252    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 771   score: 2.0   memory length: 142662   epsilon: 0.9155272600018338    steps: 200    lr: 0.0001     evaluation reward: 1.52\n","episode: 772   score: 4.0   memory length: 142979   epsilon: 0.9148996000018474    steps: 317    lr: 0.0001     evaluation reward: 1.56\n","episode: 773   score: 1.0   memory length: 143149   epsilon: 0.9145630000018548    steps: 170    lr: 0.0001     evaluation reward: 1.53\n","episode: 774   score: 0.0   memory length: 143273   epsilon: 0.9143174800018601    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 775   score: 0.0   memory length: 143397   epsilon: 0.9140719600018654    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 776   score: 2.0   memory length: 143596   epsilon: 0.913677940001874    steps: 199    lr: 0.0001     evaluation reward: 1.5\n","episode: 777   score: 3.0   memory length: 143845   epsilon: 0.9131849200018847    steps: 249    lr: 0.0001     evaluation reward: 1.49\n","episode: 778   score: 2.0   memory length: 144063   epsilon: 0.912753280001894    steps: 218    lr: 0.0001     evaluation reward: 1.47\n","episode: 779   score: 2.0   memory length: 144281   epsilon: 0.9123216400019034    steps: 218    lr: 0.0001     evaluation reward: 1.47\n","episode: 780   score: 2.0   memory length: 144500   epsilon: 0.9118880200019128    steps: 219    lr: 0.0001     evaluation reward: 1.46\n","episode: 781   score: 5.0   memory length: 144847   epsilon: 0.9112009600019277    steps: 347    lr: 0.0001     evaluation reward: 1.49\n","episode: 782   score: 0.0   memory length: 144970   epsilon: 0.910957420001933    steps: 123    lr: 0.0001     evaluation reward: 1.48\n","episode: 783   score: 3.0   memory length: 145202   epsilon: 0.910498060001943    steps: 232    lr: 0.0001     evaluation reward: 1.51\n","episode: 784   score: 2.0   memory length: 145421   epsilon: 0.9100644400019524    steps: 219    lr: 0.0001     evaluation reward: 1.51\n","episode: 785   score: 3.0   memory length: 145687   epsilon: 0.9095377600019638    steps: 266    lr: 0.0001     evaluation reward: 1.54\n","episode: 786   score: 2.0   memory length: 145888   epsilon: 0.9091397800019725    steps: 201    lr: 0.0001     evaluation reward: 1.55\n","episode: 787   score: 3.0   memory length: 146161   epsilon: 0.9085992400019842    steps: 273    lr: 0.0001     evaluation reward: 1.56\n","episode: 788   score: 0.0   memory length: 146284   epsilon: 0.9083557000019895    steps: 123    lr: 0.0001     evaluation reward: 1.55\n","episode: 789   score: 2.0   memory length: 146501   epsilon: 0.9079260400019988    steps: 217    lr: 0.0001     evaluation reward: 1.57\n","episode: 790   score: 0.0   memory length: 146624   epsilon: 0.9076825000020041    steps: 123    lr: 0.0001     evaluation reward: 1.55\n","episode: 791   score: 2.0   memory length: 146804   epsilon: 0.9073261000020119    steps: 180    lr: 0.0001     evaluation reward: 1.57\n","episode: 792   score: 1.0   memory length: 146955   epsilon: 0.9070271200020183    steps: 151    lr: 0.0001     evaluation reward: 1.56\n","episode: 793   score: 0.0   memory length: 147078   epsilon: 0.9067835800020236    steps: 123    lr: 0.0001     evaluation reward: 1.56\n","episode: 794   score: 0.0   memory length: 147201   epsilon: 0.9065400400020289    steps: 123    lr: 0.0001     evaluation reward: 1.55\n","episode: 795   score: 3.0   memory length: 147450   epsilon: 0.9060470200020396    steps: 249    lr: 0.0001     evaluation reward: 1.55\n","episode: 796   score: 1.0   memory length: 147602   epsilon: 0.9057460600020462    steps: 152    lr: 0.0001     evaluation reward: 1.54\n","episode: 797   score: 1.0   memory length: 147773   epsilon: 0.9054074800020535    steps: 171    lr: 0.0001     evaluation reward: 1.54\n","episode: 798   score: 0.0   memory length: 147897   epsilon: 0.9051619600020588    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 799   score: 2.0   memory length: 148096   epsilon: 0.9047679400020674    steps: 199    lr: 0.0001     evaluation reward: 1.55\n","episode: 800   score: 2.0   memory length: 148294   epsilon: 0.9043759000020759    steps: 198    lr: 0.0001     evaluation reward: 1.56\n","episode: 801   score: 0.0   memory length: 148417   epsilon: 0.9041323600020812    steps: 123    lr: 0.0001     evaluation reward: 1.55\n","episode: 802   score: 3.0   memory length: 148662   epsilon: 0.9036472600020917    steps: 245    lr: 0.0001     evaluation reward: 1.58\n","episode: 803   score: 2.0   memory length: 148847   epsilon: 0.9032809600020997    steps: 185    lr: 0.0001     evaluation reward: 1.6\n","episode: 804   score: 0.0   memory length: 148971   epsilon: 0.903035440002105    steps: 124    lr: 0.0001     evaluation reward: 1.58\n","episode: 805   score: 1.0   memory length: 149140   epsilon: 0.9027008200021123    steps: 169    lr: 0.0001     evaluation reward: 1.59\n","episode: 806   score: 2.0   memory length: 149339   epsilon: 0.9023068000021208    steps: 199    lr: 0.0001     evaluation reward: 1.6\n","episode: 807   score: 1.0   memory length: 149509   epsilon: 0.9019702000021281    steps: 170    lr: 0.0001     evaluation reward: 1.59\n","episode: 808   score: 3.0   memory length: 149736   epsilon: 0.9015207400021379    steps: 227    lr: 0.0001     evaluation reward: 1.58\n","episode: 809   score: 1.0   memory length: 149906   epsilon: 0.9011841400021452    steps: 170    lr: 0.0001     evaluation reward: 1.56\n","episode: 810   score: 0.0   memory length: 150030   epsilon: 0.9009386200021505    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 811   score: 2.0   memory length: 150249   epsilon: 0.9005050000021599    steps: 219    lr: 0.0001     evaluation reward: 1.56\n","episode: 812   score: 1.0   memory length: 150422   epsilon: 0.9001624600021674    steps: 173    lr: 0.0001     evaluation reward: 1.56\n","episode: 813   score: 2.0   memory length: 150638   epsilon: 0.8997347800021767    steps: 216    lr: 0.0001     evaluation reward: 1.57\n","episode: 814   score: 0.0   memory length: 150762   epsilon: 0.899489260002182    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 815   score: 0.0   memory length: 150886   epsilon: 0.8992437400021873    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 816   score: 4.0   memory length: 151164   epsilon: 0.8986933000021993    steps: 278    lr: 0.0001     evaluation reward: 1.57\n","episode: 817   score: 2.0   memory length: 151383   epsilon: 0.8982596800022087    steps: 219    lr: 0.0001     evaluation reward: 1.58\n","episode: 818   score: 2.0   memory length: 151601   epsilon: 0.897828040002218    steps: 218    lr: 0.0001     evaluation reward: 1.6\n","episode: 819   score: 1.0   memory length: 151770   epsilon: 0.8974934200022253    steps: 169    lr: 0.0001     evaluation reward: 1.59\n","episode: 820   score: 1.0   memory length: 151942   epsilon: 0.8971528600022327    steps: 172    lr: 0.0001     evaluation reward: 1.58\n","episode: 821   score: 2.0   memory length: 152164   epsilon: 0.8967133000022423    steps: 222    lr: 0.0001     evaluation reward: 1.58\n","episode: 822   score: 4.0   memory length: 152461   epsilon: 0.896125240002255    steps: 297    lr: 0.0001     evaluation reward: 1.56\n","episode: 823   score: 0.0   memory length: 152584   epsilon: 0.8958817000022603    steps: 123    lr: 0.0001     evaluation reward: 1.56\n","episode: 824   score: 1.0   memory length: 152755   epsilon: 0.8955431200022677    steps: 171    lr: 0.0001     evaluation reward: 1.56\n","episode: 825   score: 0.0   memory length: 152879   epsilon: 0.895297600002273    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 826   score: 2.0   memory length: 153096   epsilon: 0.8948679400022823    steps: 217    lr: 0.0001     evaluation reward: 1.56\n","episode: 827   score: 3.0   memory length: 153346   epsilon: 0.8943729400022931    steps: 250    lr: 0.0001     evaluation reward: 1.59\n","episode: 828   score: 2.0   memory length: 153545   epsilon: 0.8939789200023016    steps: 199    lr: 0.0001     evaluation reward: 1.6\n","episode: 829   score: 1.0   memory length: 153697   epsilon: 0.8936779600023081    steps: 152    lr: 0.0001     evaluation reward: 1.6\n","episode: 830   score: 1.0   memory length: 153848   epsilon: 0.8933789800023146    steps: 151    lr: 0.0001     evaluation reward: 1.6\n","episode: 831   score: 0.0   memory length: 153971   epsilon: 0.8931354400023199    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 832   score: 0.0   memory length: 154095   epsilon: 0.8928899200023253    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 833   score: 3.0   memory length: 154322   epsilon: 0.892440460002335    steps: 227    lr: 0.0001     evaluation reward: 1.62\n","episode: 834   score: 2.0   memory length: 154542   epsilon: 0.8920048600023445    steps: 220    lr: 0.0001     evaluation reward: 1.62\n","episode: 835   score: 0.0   memory length: 154666   epsilon: 0.8917593400023498    steps: 124    lr: 0.0001     evaluation reward: 1.59\n","episode: 836   score: 0.0   memory length: 154789   epsilon: 0.8915158000023551    steps: 123    lr: 0.0001     evaluation reward: 1.55\n","episode: 837   score: 0.0   memory length: 154913   epsilon: 0.8912702800023604    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 838   score: 2.0   memory length: 155115   epsilon: 0.8908703200023691    steps: 202    lr: 0.0001     evaluation reward: 1.55\n","episode: 839   score: 0.0   memory length: 155239   epsilon: 0.8906248000023744    steps: 124    lr: 0.0001     evaluation reward: 1.52\n","episode: 840   score: 0.0   memory length: 155363   epsilon: 0.8903792800023798    steps: 124    lr: 0.0001     evaluation reward: 1.5\n","episode: 841   score: 1.0   memory length: 155516   epsilon: 0.8900763400023863    steps: 153    lr: 0.0001     evaluation reward: 1.48\n","episode: 842   score: 1.0   memory length: 155668   epsilon: 0.8897753800023929    steps: 152    lr: 0.0001     evaluation reward: 1.45\n","episode: 843   score: 0.0   memory length: 155791   epsilon: 0.8895318400023982    steps: 123    lr: 0.0001     evaluation reward: 1.44\n","episode: 844   score: 3.0   memory length: 156037   epsilon: 0.8890447600024087    steps: 246    lr: 0.0001     evaluation reward: 1.46\n","episode: 845   score: 3.0   memory length: 156283   epsilon: 0.8885576800024193    steps: 246    lr: 0.0001     evaluation reward: 1.48\n","episode: 846   score: 1.0   memory length: 156435   epsilon: 0.8882567200024258    steps: 152    lr: 0.0001     evaluation reward: 1.49\n","episode: 847   score: 1.0   memory length: 156586   epsilon: 0.8879577400024323    steps: 151    lr: 0.0001     evaluation reward: 1.48\n","episode: 848   score: 5.0   memory length: 156914   epsilon: 0.8873083000024464    steps: 328    lr: 0.0001     evaluation reward: 1.53\n","episode: 849   score: 0.0   memory length: 157037   epsilon: 0.8870647600024517    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 850   score: 0.0   memory length: 157160   epsilon: 0.886821220002457    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 851   score: 1.0   memory length: 157333   epsilon: 0.8864786800024644    steps: 173    lr: 0.0001     evaluation reward: 1.46\n","episode: 852   score: 2.0   memory length: 157533   epsilon: 0.886082680002473    steps: 200    lr: 0.0001     evaluation reward: 1.48\n","episode: 853   score: 0.0   memory length: 157657   epsilon: 0.8858371600024784    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 854   score: 3.0   memory length: 157904   epsilon: 0.885348100002489    steps: 247    lr: 0.0001     evaluation reward: 1.45\n","episode: 855   score: 0.0   memory length: 158028   epsilon: 0.8851025800024943    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 856   score: 0.0   memory length: 158151   epsilon: 0.8848590400024996    steps: 123    lr: 0.0001     evaluation reward: 1.44\n","episode: 857   score: 2.0   memory length: 158352   epsilon: 0.8844610600025082    steps: 201    lr: 0.0001     evaluation reward: 1.45\n","episode: 858   score: 0.0   memory length: 158475   epsilon: 0.8842175200025135    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 859   score: 4.0   memory length: 158757   epsilon: 0.8836591600025256    steps: 282    lr: 0.0001     evaluation reward: 1.44\n","episode: 860   score: 2.0   memory length: 158960   epsilon: 0.8832572200025344    steps: 203    lr: 0.0001     evaluation reward: 1.45\n","episode: 861   score: 3.0   memory length: 159204   epsilon: 0.8827741000025449    steps: 244    lr: 0.0001     evaluation reward: 1.47\n","episode: 862   score: 0.0   memory length: 159328   epsilon: 0.8825285800025502    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 863   score: 2.0   memory length: 159527   epsilon: 0.8821345600025587    steps: 199    lr: 0.0001     evaluation reward: 1.44\n","episode: 864   score: 2.0   memory length: 159745   epsilon: 0.8817029200025681    steps: 218    lr: 0.0001     evaluation reward: 1.44\n","episode: 865   score: 4.0   memory length: 160021   epsilon: 0.88115644000258    steps: 276    lr: 0.0001     evaluation reward: 1.48\n","episode: 866   score: 2.0   memory length: 160224   epsilon: 0.8807545000025887    steps: 203    lr: 0.0001     evaluation reward: 1.48\n","episode: 867   score: 1.0   memory length: 160375   epsilon: 0.8804555200025952    steps: 151    lr: 0.0001     evaluation reward: 1.49\n","episode: 868   score: 1.0   memory length: 160547   epsilon: 0.8801149600026026    steps: 172    lr: 0.0001     evaluation reward: 1.48\n","episode: 869   score: 3.0   memory length: 160817   epsilon: 0.8795803600026142    steps: 270    lr: 0.0001     evaluation reward: 1.5\n","episode: 870   score: 0.0   memory length: 160940   epsilon: 0.8793368200026195    steps: 123    lr: 0.0001     evaluation reward: 1.48\n","episode: 871   score: 1.0   memory length: 161092   epsilon: 0.879035860002626    steps: 152    lr: 0.0001     evaluation reward: 1.47\n","episode: 872   score: 2.0   memory length: 161311   epsilon: 0.8786022400026354    steps: 219    lr: 0.0001     evaluation reward: 1.45\n","episode: 873   score: 0.0   memory length: 161435   epsilon: 0.8783567200026408    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 874   score: 0.0   memory length: 161559   epsilon: 0.8781112000026461    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 875   score: 5.0   memory length: 161877   epsilon: 0.8774815600026598    steps: 318    lr: 0.0001     evaluation reward: 1.49\n","episode: 876   score: 2.0   memory length: 162076   epsilon: 0.8770875400026683    steps: 199    lr: 0.0001     evaluation reward: 1.49\n","episode: 877   score: 2.0   memory length: 162257   epsilon: 0.8767291600026761    steps: 181    lr: 0.0001     evaluation reward: 1.48\n","episode: 878   score: 1.0   memory length: 162430   epsilon: 0.8763866200026835    steps: 173    lr: 0.0001     evaluation reward: 1.47\n","episode: 879   score: 0.0   memory length: 162553   epsilon: 0.8761430800026888    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 880   score: 2.0   memory length: 162771   epsilon: 0.8757114400026982    steps: 218    lr: 0.0001     evaluation reward: 1.45\n","episode: 881   score: 3.0   memory length: 163039   epsilon: 0.8751808000027097    steps: 268    lr: 0.0001     evaluation reward: 1.43\n","episode: 882   score: 3.0   memory length: 163287   epsilon: 0.8746897600027204    steps: 248    lr: 0.0001     evaluation reward: 1.46\n","episode: 883   score: 1.0   memory length: 163458   epsilon: 0.8743511800027277    steps: 171    lr: 0.0001     evaluation reward: 1.44\n","episode: 884   score: 1.0   memory length: 163628   epsilon: 0.874014580002735    steps: 170    lr: 0.0001     evaluation reward: 1.43\n","episode: 885   score: 0.0   memory length: 163751   epsilon: 0.8737710400027403    steps: 123    lr: 0.0001     evaluation reward: 1.4\n","episode: 886   score: 6.0   memory length: 164162   epsilon: 0.872957260002758    steps: 411    lr: 0.0001     evaluation reward: 1.44\n","episode: 887   score: 0.0   memory length: 164285   epsilon: 0.8727137200027633    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 888   score: 1.0   memory length: 164454   epsilon: 0.8723791000027705    steps: 169    lr: 0.0001     evaluation reward: 1.42\n","episode: 889   score: 3.0   memory length: 164704   epsilon: 0.8718841000027813    steps: 250    lr: 0.0001     evaluation reward: 1.43\n","episode: 890   score: 0.0   memory length: 164828   epsilon: 0.8716385800027866    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 891   score: 0.0   memory length: 164952   epsilon: 0.8713930600027919    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 892   score: 2.0   memory length: 165153   epsilon: 0.8709950800028006    steps: 201    lr: 0.0001     evaluation reward: 1.42\n","episode: 893   score: 3.0   memory length: 165398   epsilon: 0.8705099800028111    steps: 245    lr: 0.0001     evaluation reward: 1.45\n","episode: 894   score: 2.0   memory length: 165617   epsilon: 0.8700763600028205    steps: 219    lr: 0.0001     evaluation reward: 1.47\n","episode: 895   score: 0.0   memory length: 165741   epsilon: 0.8698308400028258    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 896   score: 1.0   memory length: 165912   epsilon: 0.8694922600028332    steps: 171    lr: 0.0001     evaluation reward: 1.44\n","episode: 897   score: 6.0   memory length: 166286   epsilon: 0.8687517400028493    steps: 374    lr: 0.0001     evaluation reward: 1.49\n","episode: 898   score: 0.0   memory length: 166410   epsilon: 0.8685062200028546    steps: 124    lr: 0.0001     evaluation reward: 1.49\n","episode: 899   score: 1.0   memory length: 166580   epsilon: 0.8681696200028619    steps: 170    lr: 0.0001     evaluation reward: 1.48\n","episode: 900   score: 2.0   memory length: 166799   epsilon: 0.8677360000028713    steps: 219    lr: 0.0001     evaluation reward: 1.48\n","episode: 901   score: 1.0   memory length: 166952   epsilon: 0.8674330600028779    steps: 153    lr: 0.0001     evaluation reward: 1.49\n","episode: 902   score: 2.0   memory length: 167135   epsilon: 0.8670707200028858    steps: 183    lr: 0.0001     evaluation reward: 1.48\n","episode: 903   score: 2.0   memory length: 167355   epsilon: 0.8666351200028952    steps: 220    lr: 0.0001     evaluation reward: 1.48\n","episode: 904   score: 2.0   memory length: 167557   epsilon: 0.8662351600029039    steps: 202    lr: 0.0001     evaluation reward: 1.5\n","episode: 905   score: 2.0   memory length: 167755   epsilon: 0.8658431200029124    steps: 198    lr: 0.0001     evaluation reward: 1.51\n","episode: 906   score: 3.0   memory length: 168002   epsilon: 0.865354060002923    steps: 247    lr: 0.0001     evaluation reward: 1.52\n","episode: 907   score: 3.0   memory length: 168271   epsilon: 0.8648214400029346    steps: 269    lr: 0.0001     evaluation reward: 1.54\n","episode: 908   score: 4.0   memory length: 168549   epsilon: 0.8642710000029465    steps: 278    lr: 0.0001     evaluation reward: 1.55\n","episode: 909   score: 0.0   memory length: 168673   epsilon: 0.8640254800029519    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 910   score: 0.0   memory length: 168796   epsilon: 0.8637819400029572    steps: 123    lr: 0.0001     evaluation reward: 1.54\n","episode: 911   score: 2.0   memory length: 168995   epsilon: 0.8633879200029657    steps: 199    lr: 0.0001     evaluation reward: 1.54\n","episode: 912   score: 2.0   memory length: 169176   epsilon: 0.8630295400029735    steps: 181    lr: 0.0001     evaluation reward: 1.55\n","episode: 913   score: 1.0   memory length: 169327   epsilon: 0.86273056000298    steps: 151    lr: 0.0001     evaluation reward: 1.54\n","episode: 914   score: 3.0   memory length: 169554   epsilon: 0.8622811000029897    steps: 227    lr: 0.0001     evaluation reward: 1.57\n","episode: 915   score: 2.0   memory length: 169752   epsilon: 0.8618890600029983    steps: 198    lr: 0.0001     evaluation reward: 1.59\n","episode: 916   score: 2.0   memory length: 169936   epsilon: 0.8615247400030062    steps: 184    lr: 0.0001     evaluation reward: 1.57\n","episode: 917   score: 0.0   memory length: 170060   epsilon: 0.8612792200030115    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 918   score: 0.0   memory length: 170184   epsilon: 0.8610337000030168    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 919   score: 0.0   memory length: 170308   epsilon: 0.8607881800030222    steps: 124    lr: 0.0001     evaluation reward: 1.52\n","episode: 920   score: 2.0   memory length: 170507   epsilon: 0.8603941600030307    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 921   score: 4.0   memory length: 170783   epsilon: 0.8598476800030426    steps: 276    lr: 0.0001     evaluation reward: 1.55\n","episode: 922   score: 1.0   memory length: 170936   epsilon: 0.8595447400030491    steps: 153    lr: 0.0001     evaluation reward: 1.52\n","episode: 923   score: 2.0   memory length: 171135   epsilon: 0.8591507200030577    steps: 199    lr: 0.0001     evaluation reward: 1.54\n","episode: 924   score: 2.0   memory length: 171355   epsilon: 0.8587151200030672    steps: 220    lr: 0.0001     evaluation reward: 1.55\n","episode: 925   score: 3.0   memory length: 171603   epsilon: 0.8582240800030778    steps: 248    lr: 0.0001     evaluation reward: 1.58\n","episode: 926   score: 2.0   memory length: 171802   epsilon: 0.8578300600030864    steps: 199    lr: 0.0001     evaluation reward: 1.58\n","episode: 927   score: 1.0   memory length: 171955   epsilon: 0.857527120003093    steps: 153    lr: 0.0001     evaluation reward: 1.56\n","episode: 928   score: 4.0   memory length: 172253   epsilon: 0.8569370800031058    steps: 298    lr: 0.0001     evaluation reward: 1.58\n","episode: 929   score: 0.0   memory length: 172376   epsilon: 0.856693540003111    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 930   score: 3.0   memory length: 172621   epsilon: 0.8562084400031216    steps: 245    lr: 0.0001     evaluation reward: 1.59\n","episode: 931   score: 0.0   memory length: 172745   epsilon: 0.8559629200031269    steps: 124    lr: 0.0001     evaluation reward: 1.59\n","episode: 932   score: 1.0   memory length: 172916   epsilon: 0.8556243400031343    steps: 171    lr: 0.0001     evaluation reward: 1.6\n","episode: 933   score: 0.0   memory length: 173040   epsilon: 0.8553788200031396    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 934   score: 2.0   memory length: 173239   epsilon: 0.8549848000031481    steps: 199    lr: 0.0001     evaluation reward: 1.57\n","episode: 935   score: 0.0   memory length: 173363   epsilon: 0.8547392800031535    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 936   score: 0.0   memory length: 173487   epsilon: 0.8544937600031588    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 937   score: 1.0   memory length: 173656   epsilon: 0.8541591400031661    steps: 169    lr: 0.0001     evaluation reward: 1.58\n","episode: 938   score: 2.0   memory length: 173854   epsilon: 0.8537671000031746    steps: 198    lr: 0.0001     evaluation reward: 1.58\n","episode: 939   score: 4.0   memory length: 174127   epsilon: 0.8532265600031863    steps: 273    lr: 0.0001     evaluation reward: 1.62\n","episode: 940   score: 0.0   memory length: 174251   epsilon: 0.8529810400031916    steps: 124    lr: 0.0001     evaluation reward: 1.62\n","episode: 941   score: 3.0   memory length: 174497   epsilon: 0.8524939600032022    steps: 246    lr: 0.0001     evaluation reward: 1.64\n","episode: 942   score: 2.0   memory length: 174716   epsilon: 0.8520603400032116    steps: 219    lr: 0.0001     evaluation reward: 1.65\n","episode: 943   score: 1.0   memory length: 174868   epsilon: 0.8517593800032182    steps: 152    lr: 0.0001     evaluation reward: 1.66\n","episode: 944   score: 2.0   memory length: 175066   epsilon: 0.8513673400032267    steps: 198    lr: 0.0001     evaluation reward: 1.65\n","episode: 945   score: 2.0   memory length: 175287   epsilon: 0.8509297600032362    steps: 221    lr: 0.0001     evaluation reward: 1.64\n","episode: 946   score: 1.0   memory length: 175439   epsilon: 0.8506288000032427    steps: 152    lr: 0.0001     evaluation reward: 1.64\n","episode: 947   score: 3.0   memory length: 175666   epsilon: 0.8501793400032525    steps: 227    lr: 0.0001     evaluation reward: 1.66\n","episode: 948   score: 2.0   memory length: 175865   epsilon: 0.849785320003261    steps: 199    lr: 0.0001     evaluation reward: 1.63\n","episode: 949   score: 1.0   memory length: 176017   epsilon: 0.8494843600032675    steps: 152    lr: 0.0001     evaluation reward: 1.64\n","episode: 950   score: 1.0   memory length: 176186   epsilon: 0.8491497400032748    steps: 169    lr: 0.0001     evaluation reward: 1.65\n","episode: 951   score: 3.0   memory length: 176440   epsilon: 0.8486468200032857    steps: 254    lr: 0.0001     evaluation reward: 1.67\n","episode: 952   score: 0.0   memory length: 176564   epsilon: 0.8484013000032911    steps: 124    lr: 0.0001     evaluation reward: 1.65\n","episode: 953   score: 2.0   memory length: 176763   epsilon: 0.8480072800032996    steps: 199    lr: 0.0001     evaluation reward: 1.67\n","episode: 954   score: 2.0   memory length: 176962   epsilon: 0.8476132600033082    steps: 199    lr: 0.0001     evaluation reward: 1.66\n","episode: 955   score: 5.0   memory length: 177290   epsilon: 0.8469638200033223    steps: 328    lr: 0.0001     evaluation reward: 1.71\n","episode: 956   score: 1.0   memory length: 177459   epsilon: 0.8466292000033295    steps: 169    lr: 0.0001     evaluation reward: 1.72\n","episode: 957   score: 0.0   memory length: 177583   epsilon: 0.8463836800033349    steps: 124    lr: 0.0001     evaluation reward: 1.7\n","episode: 958   score: 1.0   memory length: 177735   epsilon: 0.8460827200033414    steps: 152    lr: 0.0001     evaluation reward: 1.71\n","episode: 959   score: 0.0   memory length: 177859   epsilon: 0.8458372000033467    steps: 124    lr: 0.0001     evaluation reward: 1.67\n","episode: 960   score: 1.0   memory length: 178032   epsilon: 0.8454946600033542    steps: 173    lr: 0.0001     evaluation reward: 1.66\n","episode: 961   score: 0.0   memory length: 178156   epsilon: 0.8452491400033595    steps: 124    lr: 0.0001     evaluation reward: 1.63\n","episode: 962   score: 2.0   memory length: 178375   epsilon: 0.8448155200033689    steps: 219    lr: 0.0001     evaluation reward: 1.65\n","episode: 963   score: 4.0   memory length: 178650   epsilon: 0.8442710200033807    steps: 275    lr: 0.0001     evaluation reward: 1.67\n","episode: 964   score: 1.0   memory length: 178803   epsilon: 0.8439680800033873    steps: 153    lr: 0.0001     evaluation reward: 1.66\n","episode: 965   score: 3.0   memory length: 179052   epsilon: 0.843475060003398    steps: 249    lr: 0.0001     evaluation reward: 1.65\n","episode: 966   score: 3.0   memory length: 179300   epsilon: 0.8429840200034087    steps: 248    lr: 0.0001     evaluation reward: 1.66\n","episode: 967   score: 0.0   memory length: 179423   epsilon: 0.842740480003414    steps: 123    lr: 0.0001     evaluation reward: 1.65\n","episode: 968   score: 3.0   memory length: 179670   epsilon: 0.8422514200034246    steps: 247    lr: 0.0001     evaluation reward: 1.67\n","episode: 969   score: 2.0   memory length: 179868   epsilon: 0.8418593800034331    steps: 198    lr: 0.0001     evaluation reward: 1.66\n","episode: 970   score: 1.0   memory length: 180038   epsilon: 0.8415227800034404    steps: 170    lr: 0.0001     evaluation reward: 1.67\n","episode: 971   score: 2.0   memory length: 180261   epsilon: 0.84108124000345    steps: 223    lr: 0.0001     evaluation reward: 1.68\n","episode: 972   score: 2.0   memory length: 180460   epsilon: 0.8406872200034585    steps: 199    lr: 0.0001     evaluation reward: 1.68\n","episode: 973   score: 2.0   memory length: 180659   epsilon: 0.8402932000034671    steps: 199    lr: 0.0001     evaluation reward: 1.7\n","episode: 974   score: 3.0   memory length: 180907   epsilon: 0.8398021600034777    steps: 248    lr: 0.0001     evaluation reward: 1.73\n","episode: 975   score: 3.0   memory length: 181137   epsilon: 0.8393467600034876    steps: 230    lr: 0.0001     evaluation reward: 1.71\n","episode: 976   score: 6.0   memory length: 181504   epsilon: 0.8386201000035034    steps: 367    lr: 0.0001     evaluation reward: 1.75\n","episode: 977   score: 3.0   memory length: 181730   epsilon: 0.8381726200035131    steps: 226    lr: 0.0001     evaluation reward: 1.76\n","episode: 978   score: 0.0   memory length: 181854   epsilon: 0.8379271000035184    steps: 124    lr: 0.0001     evaluation reward: 1.75\n","episode: 979   score: 1.0   memory length: 182027   epsilon: 0.8375845600035259    steps: 173    lr: 0.0001     evaluation reward: 1.76\n","episode: 980   score: 2.0   memory length: 182226   epsilon: 0.8371905400035344    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 981   score: 0.0   memory length: 182349   epsilon: 0.8369470000035397    steps: 123    lr: 0.0001     evaluation reward: 1.73\n","episode: 982   score: 2.0   memory length: 182551   epsilon: 0.8365470400035484    steps: 202    lr: 0.0001     evaluation reward: 1.72\n","episode: 983   score: 1.0   memory length: 182703   epsilon: 0.8362460800035549    steps: 152    lr: 0.0001     evaluation reward: 1.72\n","episode: 984   score: 1.0   memory length: 182854   epsilon: 0.8359471000035614    steps: 151    lr: 0.0001     evaluation reward: 1.72\n","episode: 985   score: 4.0   memory length: 183150   epsilon: 0.8353610200035742    steps: 296    lr: 0.0001     evaluation reward: 1.76\n","episode: 986   score: 4.0   memory length: 183468   epsilon: 0.8347313800035878    steps: 318    lr: 0.0001     evaluation reward: 1.74\n","episode: 987   score: 2.0   memory length: 183667   epsilon: 0.8343373600035964    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 988   score: 2.0   memory length: 183865   epsilon: 0.8339453200036049    steps: 198    lr: 0.0001     evaluation reward: 1.77\n","episode: 989   score: 2.0   memory length: 184064   epsilon: 0.8335513000036134    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 990   score: 0.0   memory length: 184188   epsilon: 0.8333057800036188    steps: 124    lr: 0.0001     evaluation reward: 1.76\n","episode: 991   score: 4.0   memory length: 184485   epsilon: 0.8327177200036315    steps: 297    lr: 0.0001     evaluation reward: 1.8\n","episode: 992   score: 2.0   memory length: 184707   epsilon: 0.8322781600036411    steps: 222    lr: 0.0001     evaluation reward: 1.8\n","episode: 993   score: 1.0   memory length: 184878   epsilon: 0.8319395800036484    steps: 171    lr: 0.0001     evaluation reward: 1.78\n","episode: 994   score: 0.0   memory length: 185002   epsilon: 0.8316940600036538    steps: 124    lr: 0.0001     evaluation reward: 1.76\n","episode: 995   score: 4.0   memory length: 185281   epsilon: 0.8311416400036657    steps: 279    lr: 0.0001     evaluation reward: 1.8\n","episode: 996   score: 1.0   memory length: 185432   epsilon: 0.8308426600036722    steps: 151    lr: 0.0001     evaluation reward: 1.8\n","episode: 997   score: 2.0   memory length: 185630   epsilon: 0.8304506200036808    steps: 198    lr: 0.0001     evaluation reward: 1.76\n","episode: 998   score: 2.0   memory length: 185850   epsilon: 0.8300150200036902    steps: 220    lr: 0.0001     evaluation reward: 1.78\n","episode: 999   score: 0.0   memory length: 185973   epsilon: 0.8297714800036955    steps: 123    lr: 0.0001     evaluation reward: 1.77\n","episode: 1000   score: 0.0   memory length: 186097   epsilon: 0.8295259600037008    steps: 124    lr: 0.0001     evaluation reward: 1.75\n","episode: 1001   score: 1.0   memory length: 186269   epsilon: 0.8291854000037082    steps: 172    lr: 0.0001     evaluation reward: 1.75\n","episode: 1002   score: 2.0   memory length: 186468   epsilon: 0.8287913800037168    steps: 199    lr: 0.0001     evaluation reward: 1.75\n","episode: 1003   score: 0.0   memory length: 186592   epsilon: 0.8285458600037221    steps: 124    lr: 0.0001     evaluation reward: 1.73\n","episode: 1004   score: 0.0   memory length: 186716   epsilon: 0.8283003400037274    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 1005   score: 0.0   memory length: 186840   epsilon: 0.8280548200037328    steps: 124    lr: 0.0001     evaluation reward: 1.69\n","episode: 1006   score: 4.0   memory length: 187118   epsilon: 0.8275043800037447    steps: 278    lr: 0.0001     evaluation reward: 1.7\n","episode: 1007   score: 3.0   memory length: 187367   epsilon: 0.8270113600037554    steps: 249    lr: 0.0001     evaluation reward: 1.7\n","episode: 1008   score: 1.0   memory length: 187537   epsilon: 0.8266747600037627    steps: 170    lr: 0.0001     evaluation reward: 1.67\n","episode: 1009   score: 0.0   memory length: 187661   epsilon: 0.826429240003768    steps: 124    lr: 0.0001     evaluation reward: 1.67\n","episode: 1010   score: 2.0   memory length: 187860   epsilon: 0.8260352200037766    steps: 199    lr: 0.0001     evaluation reward: 1.69\n","episode: 1011   score: 1.0   memory length: 188012   epsilon: 0.8257342600037831    steps: 152    lr: 0.0001     evaluation reward: 1.68\n","episode: 1012   score: 1.0   memory length: 188182   epsilon: 0.8253976600037904    steps: 170    lr: 0.0001     evaluation reward: 1.67\n","episode: 1013   score: 3.0   memory length: 188427   epsilon: 0.824912560003801    steps: 245    lr: 0.0001     evaluation reward: 1.69\n","episode: 1014   score: 3.0   memory length: 188672   epsilon: 0.8244274600038115    steps: 245    lr: 0.0001     evaluation reward: 1.69\n","episode: 1015   score: 3.0   memory length: 188920   epsilon: 0.8239364200038222    steps: 248    lr: 0.0001     evaluation reward: 1.7\n","episode: 1016   score: 0.0   memory length: 189044   epsilon: 0.8236909000038275    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 1017   score: 3.0   memory length: 189272   epsilon: 0.8232394600038373    steps: 228    lr: 0.0001     evaluation reward: 1.71\n","episode: 1018   score: 0.0   memory length: 189396   epsilon: 0.8229939400038426    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 1019   score: 6.0   memory length: 189771   epsilon: 0.8222514400038587    steps: 375    lr: 0.0001     evaluation reward: 1.77\n","episode: 1020   score: 1.0   memory length: 189923   epsilon: 0.8219504800038653    steps: 152    lr: 0.0001     evaluation reward: 1.76\n","episode: 1021   score: 3.0   memory length: 190192   epsilon: 0.8214178600038768    steps: 269    lr: 0.0001     evaluation reward: 1.75\n","episode: 1022   score: 2.0   memory length: 190390   epsilon: 0.8210258200038854    steps: 198    lr: 0.0001     evaluation reward: 1.76\n","episode: 1023   score: 4.0   memory length: 190683   epsilon: 0.820445680003898    steps: 293    lr: 0.0001     evaluation reward: 1.78\n","episode: 1024   score: 4.0   memory length: 190981   epsilon: 0.8198556400039108    steps: 298    lr: 0.0001     evaluation reward: 1.8\n","episode: 1025   score: 0.0   memory length: 191105   epsilon: 0.8196101200039161    steps: 124    lr: 0.0001     evaluation reward: 1.77\n","episode: 1026   score: 1.0   memory length: 191256   epsilon: 0.8193111400039226    steps: 151    lr: 0.0001     evaluation reward: 1.76\n","episode: 1027   score: 1.0   memory length: 191429   epsilon: 0.81896860000393    steps: 173    lr: 0.0001     evaluation reward: 1.76\n","episode: 1028   score: 3.0   memory length: 191696   epsilon: 0.8184399400039415    steps: 267    lr: 0.0001     evaluation reward: 1.75\n","episode: 1029   score: 1.0   memory length: 191866   epsilon: 0.8181033400039488    steps: 170    lr: 0.0001     evaluation reward: 1.76\n","episode: 1030   score: 3.0   memory length: 192114   epsilon: 0.8176123000039595    steps: 248    lr: 0.0001     evaluation reward: 1.76\n","episode: 1031   score: 3.0   memory length: 192361   epsilon: 0.8171232400039701    steps: 247    lr: 0.0001     evaluation reward: 1.79\n","episode: 1032   score: 2.0   memory length: 192582   epsilon: 0.8166856600039796    steps: 221    lr: 0.0001     evaluation reward: 1.8\n","episode: 1033   score: 2.0   memory length: 192781   epsilon: 0.8162916400039881    steps: 199    lr: 0.0001     evaluation reward: 1.82\n","episode: 1034   score: 0.0   memory length: 192904   epsilon: 0.8160481000039934    steps: 123    lr: 0.0001     evaluation reward: 1.8\n","episode: 1035   score: 1.0   memory length: 193074   epsilon: 0.8157115000040007    steps: 170    lr: 0.0001     evaluation reward: 1.81\n","episode: 1036   score: 2.0   memory length: 193290   epsilon: 0.81528382000401    steps: 216    lr: 0.0001     evaluation reward: 1.83\n","episode: 1037   score: 4.0   memory length: 193586   epsilon: 0.8146977400040227    steps: 296    lr: 0.0001     evaluation reward: 1.86\n","episode: 1038   score: 0.0   memory length: 193710   epsilon: 0.8144522200040281    steps: 124    lr: 0.0001     evaluation reward: 1.84\n","episode: 1039   score: 0.0   memory length: 193833   epsilon: 0.8142086800040333    steps: 123    lr: 0.0001     evaluation reward: 1.8\n","episode: 1040   score: 2.0   memory length: 194031   epsilon: 0.8138166400040419    steps: 198    lr: 0.0001     evaluation reward: 1.82\n","episode: 1041   score: 6.0   memory length: 194408   epsilon: 0.8130701800040581    steps: 377    lr: 0.0001     evaluation reward: 1.85\n","episode: 1042   score: 2.0   memory length: 194607   epsilon: 0.8126761600040666    steps: 199    lr: 0.0001     evaluation reward: 1.85\n","episode: 1043   score: 2.0   memory length: 194806   epsilon: 0.8122821400040752    steps: 199    lr: 0.0001     evaluation reward: 1.86\n","episode: 1044   score: 2.0   memory length: 195004   epsilon: 0.8118901000040837    steps: 198    lr: 0.0001     evaluation reward: 1.86\n","episode: 1045   score: 3.0   memory length: 195232   epsilon: 0.8114386600040935    steps: 228    lr: 0.0001     evaluation reward: 1.87\n","episode: 1046   score: 0.0   memory length: 195356   epsilon: 0.8111931400040988    steps: 124    lr: 0.0001     evaluation reward: 1.86\n","episode: 1047   score: 4.0   memory length: 195674   epsilon: 0.8105635000041125    steps: 318    lr: 0.0001     evaluation reward: 1.87\n","episode: 1048   score: 1.0   memory length: 195844   epsilon: 0.8102269000041198    steps: 170    lr: 0.0001     evaluation reward: 1.86\n","episode: 1049   score: 2.0   memory length: 196063   epsilon: 0.8097932800041292    steps: 219    lr: 0.0001     evaluation reward: 1.87\n","episode: 1050   score: 0.0   memory length: 196187   epsilon: 0.8095477600041345    steps: 124    lr: 0.0001     evaluation reward: 1.86\n","episode: 1051   score: 2.0   memory length: 196405   epsilon: 0.8091161200041439    steps: 218    lr: 0.0001     evaluation reward: 1.85\n","episode: 1052   score: 3.0   memory length: 196651   epsilon: 0.8086290400041545    steps: 246    lr: 0.0001     evaluation reward: 1.88\n","episode: 1053   score: 1.0   memory length: 196821   epsilon: 0.8082924400041618    steps: 170    lr: 0.0001     evaluation reward: 1.87\n","episode: 1054   score: 4.0   memory length: 197118   epsilon: 0.8077043800041745    steps: 297    lr: 0.0001     evaluation reward: 1.89\n","episode: 1055   score: 0.0   memory length: 197242   epsilon: 0.8074588600041799    steps: 124    lr: 0.0001     evaluation reward: 1.84\n","episode: 1056   score: 0.0   memory length: 197366   epsilon: 0.8072133400041852    steps: 124    lr: 0.0001     evaluation reward: 1.83\n","episode: 1057   score: 2.0   memory length: 197564   epsilon: 0.8068213000041937    steps: 198    lr: 0.0001     evaluation reward: 1.85\n","episode: 1058   score: 0.0   memory length: 197688   epsilon: 0.806575780004199    steps: 124    lr: 0.0001     evaluation reward: 1.84\n","episode: 1059   score: 1.0   memory length: 197840   epsilon: 0.8062748200042056    steps: 152    lr: 0.0001     evaluation reward: 1.85\n","episode: 1060   score: 2.0   memory length: 198044   epsilon: 0.8058709000042144    steps: 204    lr: 0.0001     evaluation reward: 1.86\n","episode: 1061   score: 3.0   memory length: 198312   epsilon: 0.8053402600042259    steps: 268    lr: 0.0001     evaluation reward: 1.89\n","episode: 1062   score: 2.0   memory length: 198511   epsilon: 0.8049462400042344    steps: 199    lr: 0.0001     evaluation reward: 1.89\n","episode: 1063   score: 1.0   memory length: 198680   epsilon: 0.8046116200042417    steps: 169    lr: 0.0001     evaluation reward: 1.86\n","episode: 1064   score: 1.0   memory length: 198851   epsilon: 0.804273040004249    steps: 171    lr: 0.0001     evaluation reward: 1.86\n","episode: 1065   score: 0.0   memory length: 198974   epsilon: 0.8040295000042543    steps: 123    lr: 0.0001     evaluation reward: 1.83\n","episode: 1066   score: 2.0   memory length: 199193   epsilon: 0.8035958800042637    steps: 219    lr: 0.0001     evaluation reward: 1.82\n","episode: 1067   score: 2.0   memory length: 199392   epsilon: 0.8032018600042723    steps: 199    lr: 0.0001     evaluation reward: 1.84\n","episode: 1068   score: 2.0   memory length: 199614   epsilon: 0.8027623000042818    steps: 222    lr: 0.0001     evaluation reward: 1.83\n","episode: 1069   score: 0.0   memory length: 199737   epsilon: 0.8025187600042871    steps: 123    lr: 0.0001     evaluation reward: 1.81\n","episode: 1070   score: 4.0   memory length: 200036   epsilon: 0.8019267400043    steps: 299    lr: 4e-05     evaluation reward: 1.84\n","episode: 1071   score: 0.0   memory length: 200160   epsilon: 0.8016812200043053    steps: 124    lr: 4e-05     evaluation reward: 1.82\n","episode: 1072   score: 2.0   memory length: 200358   epsilon: 0.8012891800043138    steps: 198    lr: 4e-05     evaluation reward: 1.82\n","episode: 1073   score: 0.0   memory length: 200481   epsilon: 0.8010456400043191    steps: 123    lr: 4e-05     evaluation reward: 1.8\n","episode: 1074   score: 3.0   memory length: 200707   epsilon: 0.8005981600043288    steps: 226    lr: 4e-05     evaluation reward: 1.8\n","episode: 1075   score: 3.0   memory length: 200933   epsilon: 0.8001506800043385    steps: 226    lr: 4e-05     evaluation reward: 1.8\n","episode: 1076   score: 3.0   memory length: 201180   epsilon: 0.7996616200043491    steps: 247    lr: 4e-05     evaluation reward: 1.77\n","episode: 1077   score: 3.0   memory length: 201429   epsilon: 0.7991686000043599    steps: 249    lr: 4e-05     evaluation reward: 1.77\n","episode: 1078   score: 2.0   memory length: 201648   epsilon: 0.7987349800043693    steps: 219    lr: 4e-05     evaluation reward: 1.79\n","episode: 1079   score: 3.0   memory length: 201895   epsilon: 0.7982459200043799    steps: 247    lr: 4e-05     evaluation reward: 1.81\n","episode: 1080   score: 2.0   memory length: 202094   epsilon: 0.7978519000043884    steps: 199    lr: 4e-05     evaluation reward: 1.81\n","episode: 1081   score: 3.0   memory length: 202323   epsilon: 0.7973984800043983    steps: 229    lr: 4e-05     evaluation reward: 1.84\n","episode: 1082   score: 1.0   memory length: 202475   epsilon: 0.7970975200044048    steps: 152    lr: 4e-05     evaluation reward: 1.83\n","episode: 1083   score: 3.0   memory length: 202704   epsilon: 0.7966441000044147    steps: 229    lr: 4e-05     evaluation reward: 1.85\n","episode: 1084   score: 3.0   memory length: 202953   epsilon: 0.7961510800044254    steps: 249    lr: 4e-05     evaluation reward: 1.87\n","episode: 1085   score: 3.0   memory length: 203180   epsilon: 0.7957016200044351    steps: 227    lr: 4e-05     evaluation reward: 1.86\n","episode: 1086   score: 2.0   memory length: 203398   epsilon: 0.7952699800044445    steps: 218    lr: 4e-05     evaluation reward: 1.84\n","episode: 1087   score: 3.0   memory length: 203666   epsilon: 0.794739340004456    steps: 268    lr: 4e-05     evaluation reward: 1.85\n","episode: 1088   score: 2.0   memory length: 203885   epsilon: 0.7943057200044654    steps: 219    lr: 4e-05     evaluation reward: 1.85\n","episode: 1089   score: 3.0   memory length: 204131   epsilon: 0.793818640004476    steps: 246    lr: 4e-05     evaluation reward: 1.86\n","episode: 1090   score: 3.0   memory length: 204379   epsilon: 0.7933276000044867    steps: 248    lr: 4e-05     evaluation reward: 1.89\n","episode: 1091   score: 2.0   memory length: 204578   epsilon: 0.7929335800044952    steps: 199    lr: 4e-05     evaluation reward: 1.87\n","episode: 1092   score: 2.0   memory length: 204777   epsilon: 0.7925395600045038    steps: 199    lr: 4e-05     evaluation reward: 1.87\n","episode: 1093   score: 3.0   memory length: 205022   epsilon: 0.7920544600045143    steps: 245    lr: 4e-05     evaluation reward: 1.89\n","episode: 1094   score: 3.0   memory length: 205266   epsilon: 0.7915713400045248    steps: 244    lr: 4e-05     evaluation reward: 1.92\n","episode: 1095   score: 1.0   memory length: 205436   epsilon: 0.7912347400045321    steps: 170    lr: 4e-05     evaluation reward: 1.89\n","episode: 1096   score: 0.0   memory length: 205560   epsilon: 0.7909892200045374    steps: 124    lr: 4e-05     evaluation reward: 1.88\n","episode: 1097   score: 1.0   memory length: 205711   epsilon: 0.7906902400045439    steps: 151    lr: 4e-05     evaluation reward: 1.87\n","episode: 1098   score: 2.0   memory length: 205932   epsilon: 0.7902526600045534    steps: 221    lr: 4e-05     evaluation reward: 1.87\n","episode: 1099   score: 0.0   memory length: 206056   epsilon: 0.7900071400045587    steps: 124    lr: 4e-05     evaluation reward: 1.87\n","episode: 1100   score: 3.0   memory length: 206285   epsilon: 0.7895537200045686    steps: 229    lr: 4e-05     evaluation reward: 1.9\n","episode: 1101   score: 2.0   memory length: 206484   epsilon: 0.7891597000045771    steps: 199    lr: 4e-05     evaluation reward: 1.91\n","episode: 1102   score: 4.0   memory length: 206760   epsilon: 0.788613220004589    steps: 276    lr: 4e-05     evaluation reward: 1.93\n","episode: 1103   score: 2.0   memory length: 206958   epsilon: 0.7882211800045975    steps: 198    lr: 4e-05     evaluation reward: 1.95\n","episode: 1104   score: 0.0   memory length: 207082   epsilon: 0.7879756600046028    steps: 124    lr: 4e-05     evaluation reward: 1.95\n","episode: 1105   score: 4.0   memory length: 207353   epsilon: 0.7874390800046145    steps: 271    lr: 4e-05     evaluation reward: 1.99\n","episode: 1106   score: 0.0   memory length: 207477   epsilon: 0.7871935600046198    steps: 124    lr: 4e-05     evaluation reward: 1.95\n","episode: 1107   score: 0.0   memory length: 207601   epsilon: 0.7869480400046251    steps: 124    lr: 4e-05     evaluation reward: 1.92\n","episode: 1108   score: 2.0   memory length: 207800   epsilon: 0.7865540200046337    steps: 199    lr: 4e-05     evaluation reward: 1.93\n","episode: 1109   score: 0.0   memory length: 207924   epsilon: 0.786308500004639    steps: 124    lr: 4e-05     evaluation reward: 1.93\n","episode: 1110   score: 5.0   memory length: 208250   epsilon: 0.785663020004653    steps: 326    lr: 4e-05     evaluation reward: 1.96\n","episode: 1111   score: 2.0   memory length: 208450   epsilon: 0.7852670200046616    steps: 200    lr: 4e-05     evaluation reward: 1.97\n","episode: 1112   score: 1.0   memory length: 208620   epsilon: 0.784930420004669    steps: 170    lr: 4e-05     evaluation reward: 1.97\n","episode: 1113   score: 2.0   memory length: 208839   epsilon: 0.7844968000046784    steps: 219    lr: 4e-05     evaluation reward: 1.96\n","episode: 1114   score: 2.0   memory length: 209038   epsilon: 0.7841027800046869    steps: 199    lr: 4e-05     evaluation reward: 1.95\n","episode: 1115   score: 2.0   memory length: 209220   epsilon: 0.7837424200046947    steps: 182    lr: 4e-05     evaluation reward: 1.94\n","episode: 1116   score: 4.0   memory length: 209480   epsilon: 0.7832276200047059    steps: 260    lr: 4e-05     evaluation reward: 1.98\n","episode: 1117   score: 3.0   memory length: 209750   epsilon: 0.7826930200047175    steps: 270    lr: 4e-05     evaluation reward: 1.98\n","episode: 1118   score: 3.0   memory length: 209996   epsilon: 0.7822059400047281    steps: 246    lr: 4e-05     evaluation reward: 2.01\n","episode: 1119   score: 1.0   memory length: 210148   epsilon: 0.7819049800047346    steps: 152    lr: 4e-05     evaluation reward: 1.96\n","episode: 1120   score: 0.0   memory length: 210272   epsilon: 0.78165946000474    steps: 124    lr: 4e-05     evaluation reward: 1.95\n","episode: 1121   score: 3.0   memory length: 210499   epsilon: 0.7812100000047497    steps: 227    lr: 4e-05     evaluation reward: 1.95\n","episode: 1122   score: 3.0   memory length: 210730   epsilon: 0.7807526200047596    steps: 231    lr: 4e-05     evaluation reward: 1.96\n","episode: 1123   score: 2.0   memory length: 210949   epsilon: 0.7803190000047691    steps: 219    lr: 4e-05     evaluation reward: 1.94\n","episode: 1124   score: 3.0   memory length: 211197   epsilon: 0.7798279600047797    steps: 248    lr: 4e-05     evaluation reward: 1.93\n","episode: 1125   score: 1.0   memory length: 211349   epsilon: 0.7795270000047863    steps: 152    lr: 4e-05     evaluation reward: 1.94\n","episode: 1126   score: 0.0   memory length: 211472   epsilon: 0.7792834600047915    steps: 123    lr: 4e-05     evaluation reward: 1.93\n","episode: 1127   score: 1.0   memory length: 211643   epsilon: 0.7789448800047989    steps: 171    lr: 4e-05     evaluation reward: 1.93\n","episode: 1128   score: 0.0   memory length: 211767   epsilon: 0.7786993600048042    steps: 124    lr: 4e-05     evaluation reward: 1.9\n","episode: 1129   score: 2.0   memory length: 211966   epsilon: 0.7783053400048128    steps: 199    lr: 4e-05     evaluation reward: 1.91\n","episode: 1130   score: 3.0   memory length: 212193   epsilon: 0.7778558800048225    steps: 227    lr: 4e-05     evaluation reward: 1.91\n","episode: 1131   score: 2.0   memory length: 212391   epsilon: 0.777463840004831    steps: 198    lr: 4e-05     evaluation reward: 1.9\n","episode: 1132   score: 6.0   memory length: 212755   epsilon: 0.7767431200048467    steps: 364    lr: 4e-05     evaluation reward: 1.94\n","episode: 1133   score: 2.0   memory length: 212954   epsilon: 0.7763491000048552    steps: 199    lr: 4e-05     evaluation reward: 1.94\n","episode: 1134   score: 2.0   memory length: 213172   epsilon: 0.7759174600048646    steps: 218    lr: 4e-05     evaluation reward: 1.96\n","episode: 1135   score: 0.0   memory length: 213296   epsilon: 0.7756719400048699    steps: 124    lr: 4e-05     evaluation reward: 1.95\n","episode: 1136   score: 2.0   memory length: 213477   epsilon: 0.7753135600048777    steps: 181    lr: 4e-05     evaluation reward: 1.95\n","episode: 1137   score: 2.0   memory length: 213676   epsilon: 0.7749195400048863    steps: 199    lr: 4e-05     evaluation reward: 1.93\n","episode: 1138   score: 2.0   memory length: 213875   epsilon: 0.7745255200048948    steps: 199    lr: 4e-05     evaluation reward: 1.95\n","episode: 1139   score: 5.0   memory length: 214220   epsilon: 0.7738424200049097    steps: 345    lr: 4e-05     evaluation reward: 2.0\n","episode: 1140   score: 2.0   memory length: 214402   epsilon: 0.7734820600049175    steps: 182    lr: 4e-05     evaluation reward: 2.0\n","episode: 1141   score: 3.0   memory length: 214631   epsilon: 0.7730286400049273    steps: 229    lr: 4e-05     evaluation reward: 1.97\n","episode: 1142   score: 2.0   memory length: 214830   epsilon: 0.7726346200049359    steps: 199    lr: 4e-05     evaluation reward: 1.97\n","episode: 1143   score: 2.0   memory length: 215051   epsilon: 0.7721970400049454    steps: 221    lr: 4e-05     evaluation reward: 1.97\n","episode: 1144   score: 10.0   memory length: 215425   epsilon: 0.7714565200049615    steps: 374    lr: 4e-05     evaluation reward: 2.05\n","episode: 1145   score: 4.0   memory length: 215704   epsilon: 0.7709041000049734    steps: 279    lr: 4e-05     evaluation reward: 2.06\n","episode: 1146   score: 2.0   memory length: 215921   epsilon: 0.7704744400049828    steps: 217    lr: 4e-05     evaluation reward: 2.08\n","episode: 1147   score: 2.0   memory length: 216119   epsilon: 0.7700824000049913    steps: 198    lr: 4e-05     evaluation reward: 2.06\n","episode: 1148   score: 5.0   memory length: 216416   epsilon: 0.769494340005004    steps: 297    lr: 4e-05     evaluation reward: 2.1\n","episode: 1149   score: 2.0   memory length: 216615   epsilon: 0.7691003200050126    steps: 199    lr: 4e-05     evaluation reward: 2.1\n","episode: 1150   score: 2.0   memory length: 216834   epsilon: 0.768666700005022    steps: 219    lr: 4e-05     evaluation reward: 2.12\n","episode: 1151   score: 2.0   memory length: 217033   epsilon: 0.7682726800050306    steps: 199    lr: 4e-05     evaluation reward: 2.12\n","episode: 1152   score: 2.0   memory length: 217231   epsilon: 0.7678806400050391    steps: 198    lr: 4e-05     evaluation reward: 2.11\n","episode: 1153   score: 4.0   memory length: 217529   epsilon: 0.7672906000050519    steps: 298    lr: 4e-05     evaluation reward: 2.14\n","episode: 1154   score: 4.0   memory length: 217803   epsilon: 0.7667480800050637    steps: 274    lr: 4e-05     evaluation reward: 2.14\n","episode: 1155   score: 3.0   memory length: 218049   epsilon: 0.7662610000050742    steps: 246    lr: 4e-05     evaluation reward: 2.17\n","episode: 1156   score: 4.0   memory length: 218329   epsilon: 0.7657066000050863    steps: 280    lr: 4e-05     evaluation reward: 2.21\n","episode: 1157   score: 1.0   memory length: 218501   epsilon: 0.7653660400050937    steps: 172    lr: 4e-05     evaluation reward: 2.2\n","episode: 1158   score: 4.0   memory length: 218815   epsilon: 0.7647443200051072    steps: 314    lr: 4e-05     evaluation reward: 2.24\n","episode: 1159   score: 2.0   memory length: 219013   epsilon: 0.7643522800051157    steps: 198    lr: 4e-05     evaluation reward: 2.25\n","episode: 1160   score: 2.0   memory length: 219214   epsilon: 0.7639543000051243    steps: 201    lr: 4e-05     evaluation reward: 2.25\n","episode: 1161   score: 2.0   memory length: 219412   epsilon: 0.7635622600051328    steps: 198    lr: 4e-05     evaluation reward: 2.24\n","episode: 1162   score: 2.0   memory length: 219611   epsilon: 0.7631682400051414    steps: 199    lr: 4e-05     evaluation reward: 2.24\n","episode: 1163   score: 3.0   memory length: 219855   epsilon: 0.7626851200051519    steps: 244    lr: 4e-05     evaluation reward: 2.26\n","episode: 1164   score: 2.0   memory length: 220054   epsilon: 0.7622911000051604    steps: 199    lr: 4e-05     evaluation reward: 2.27\n","episode: 1165   score: 2.0   memory length: 220253   epsilon: 0.761897080005169    steps: 199    lr: 4e-05     evaluation reward: 2.29\n","episode: 1166   score: 2.0   memory length: 220434   epsilon: 0.7615387000051768    steps: 181    lr: 4e-05     evaluation reward: 2.29\n","episode: 1167   score: 0.0   memory length: 220558   epsilon: 0.7612931800051821    steps: 124    lr: 4e-05     evaluation reward: 2.27\n","episode: 1168   score: 3.0   memory length: 220785   epsilon: 0.7608437200051918    steps: 227    lr: 4e-05     evaluation reward: 2.28\n","episode: 1169   score: 0.0   memory length: 220908   epsilon: 0.7606001800051971    steps: 123    lr: 4e-05     evaluation reward: 2.28\n","episode: 1170   score: 3.0   memory length: 221155   epsilon: 0.7601111200052078    steps: 247    lr: 4e-05     evaluation reward: 2.27\n","episode: 1171   score: 0.0   memory length: 221278   epsilon: 0.759867580005213    steps: 123    lr: 4e-05     evaluation reward: 2.27\n","episode: 1172   score: 2.0   memory length: 221477   epsilon: 0.7594735600052216    steps: 199    lr: 4e-05     evaluation reward: 2.27\n","episode: 1173   score: 6.0   memory length: 221860   epsilon: 0.7587152200052381    steps: 383    lr: 4e-05     evaluation reward: 2.33\n","episode: 1174   score: 1.0   memory length: 222033   epsilon: 0.7583726800052455    steps: 173    lr: 4e-05     evaluation reward: 2.31\n","episode: 1175   score: 3.0   memory length: 222282   epsilon: 0.7578796600052562    steps: 249    lr: 4e-05     evaluation reward: 2.31\n","episode: 1176   score: 2.0   memory length: 222482   epsilon: 0.7574836600052648    steps: 200    lr: 4e-05     evaluation reward: 2.3\n","episode: 1177   score: 2.0   memory length: 222704   epsilon: 0.7570441000052743    steps: 222    lr: 4e-05     evaluation reward: 2.29\n","episode: 1178   score: 2.0   memory length: 222923   epsilon: 0.7566104800052837    steps: 219    lr: 4e-05     evaluation reward: 2.29\n","episode: 1179   score: 2.0   memory length: 223142   epsilon: 0.7561768600052932    steps: 219    lr: 4e-05     evaluation reward: 2.28\n","episode: 1180   score: 1.0   memory length: 223313   epsilon: 0.7558382800053005    steps: 171    lr: 4e-05     evaluation reward: 2.27\n","episode: 1181   score: 2.0   memory length: 223531   epsilon: 0.7554066400053099    steps: 218    lr: 4e-05     evaluation reward: 2.26\n","episode: 1182   score: 2.0   memory length: 223749   epsilon: 0.7549750000053193    steps: 218    lr: 4e-05     evaluation reward: 2.27\n","episode: 1183   score: 4.0   memory length: 224043   epsilon: 0.7543928800053319    steps: 294    lr: 4e-05     evaluation reward: 2.28\n","episode: 1184   score: 3.0   memory length: 224291   epsilon: 0.7539018400053425    steps: 248    lr: 4e-05     evaluation reward: 2.28\n","episode: 1185   score: 2.0   memory length: 224472   epsilon: 0.7535434600053503    steps: 181    lr: 4e-05     evaluation reward: 2.27\n","episode: 1186   score: 4.0   memory length: 224750   epsilon: 0.7529930200053623    steps: 278    lr: 4e-05     evaluation reward: 2.29\n","episode: 1187   score: 2.0   memory length: 224949   epsilon: 0.7525990000053708    steps: 199    lr: 4e-05     evaluation reward: 2.28\n","episode: 1188   score: 2.0   memory length: 225151   epsilon: 0.7521990400053795    steps: 202    lr: 4e-05     evaluation reward: 2.28\n","episode: 1189   score: 2.0   memory length: 225370   epsilon: 0.7517654200053889    steps: 219    lr: 4e-05     evaluation reward: 2.27\n","episode: 1190   score: 3.0   memory length: 225616   epsilon: 0.7512783400053995    steps: 246    lr: 4e-05     evaluation reward: 2.27\n","episode: 1191   score: 2.0   memory length: 225815   epsilon: 0.7508843200054081    steps: 199    lr: 4e-05     evaluation reward: 2.27\n","episode: 1192   score: 3.0   memory length: 226042   epsilon: 0.7504348600054178    steps: 227    lr: 4e-05     evaluation reward: 2.28\n","episode: 1193   score: 1.0   memory length: 226214   epsilon: 0.7500943000054252    steps: 172    lr: 4e-05     evaluation reward: 2.26\n","episode: 1194   score: 0.0   memory length: 226337   epsilon: 0.7498507600054305    steps: 123    lr: 4e-05     evaluation reward: 2.23\n","episode: 1195   score: 2.0   memory length: 226536   epsilon: 0.749456740005439    steps: 199    lr: 4e-05     evaluation reward: 2.24\n","episode: 1196   score: 3.0   memory length: 226763   epsilon: 0.7490072800054488    steps: 227    lr: 4e-05     evaluation reward: 2.27\n","episode: 1197   score: 4.0   memory length: 227063   epsilon: 0.7484132800054617    steps: 300    lr: 4e-05     evaluation reward: 2.3\n","episode: 1198   score: 3.0   memory length: 227295   epsilon: 0.7479539200054717    steps: 232    lr: 4e-05     evaluation reward: 2.31\n","episode: 1199   score: 0.0   memory length: 227418   epsilon: 0.747710380005477    steps: 123    lr: 4e-05     evaluation reward: 2.31\n","episode: 1200   score: 0.0   memory length: 227542   epsilon: 0.7474648600054823    steps: 124    lr: 4e-05     evaluation reward: 2.28\n","episode: 1201   score: 2.0   memory length: 227741   epsilon: 0.7470708400054908    steps: 199    lr: 4e-05     evaluation reward: 2.28\n","episode: 1202   score: 2.0   memory length: 227940   epsilon: 0.7466768200054994    steps: 199    lr: 4e-05     evaluation reward: 2.26\n","episode: 1203   score: 2.0   memory length: 228139   epsilon: 0.746282800005508    steps: 199    lr: 4e-05     evaluation reward: 2.26\n","episode: 1204   score: 1.0   memory length: 228309   epsilon: 0.7459462000055153    steps: 170    lr: 4e-05     evaluation reward: 2.27\n","episode: 1205   score: 1.0   memory length: 228481   epsilon: 0.7456056400055227    steps: 172    lr: 4e-05     evaluation reward: 2.24\n","episode: 1206   score: 3.0   memory length: 228729   epsilon: 0.7451146000055333    steps: 248    lr: 4e-05     evaluation reward: 2.27\n","episode: 1207   score: 1.0   memory length: 228880   epsilon: 0.7448156200055398    steps: 151    lr: 4e-05     evaluation reward: 2.28\n","episode: 1208   score: 3.0   memory length: 229127   epsilon: 0.7443265600055504    steps: 247    lr: 4e-05     evaluation reward: 2.29\n","episode: 1209   score: 4.0   memory length: 229445   epsilon: 0.7436969200055641    steps: 318    lr: 4e-05     evaluation reward: 2.33\n","episode: 1210   score: 4.0   memory length: 229705   epsilon: 0.7431821200055753    steps: 260    lr: 4e-05     evaluation reward: 2.32\n","episode: 1211   score: 1.0   memory length: 229857   epsilon: 0.7428811600055818    steps: 152    lr: 4e-05     evaluation reward: 2.31\n","episode: 1212   score: 5.0   memory length: 230183   epsilon: 0.7422356800055958    steps: 326    lr: 4e-05     evaluation reward: 2.35\n","episode: 1213   score: 3.0   memory length: 230410   epsilon: 0.7417862200056056    steps: 227    lr: 4e-05     evaluation reward: 2.36\n","episode: 1214   score: 4.0   memory length: 230664   epsilon: 0.7412833000056165    steps: 254    lr: 4e-05     evaluation reward: 2.38\n","episode: 1215   score: 3.0   memory length: 230929   epsilon: 0.7407586000056279    steps: 265    lr: 4e-05     evaluation reward: 2.39\n","episode: 1216   score: 4.0   memory length: 231188   epsilon: 0.740245780005639    steps: 259    lr: 4e-05     evaluation reward: 2.39\n","episode: 1217   score: 3.0   memory length: 231422   epsilon: 0.7397824600056491    steps: 234    lr: 4e-05     evaluation reward: 2.39\n","episode: 1218   score: 1.0   memory length: 231574   epsilon: 0.7394815000056556    steps: 152    lr: 4e-05     evaluation reward: 2.37\n","episode: 1219   score: 3.0   memory length: 231808   epsilon: 0.7390181800056657    steps: 234    lr: 4e-05     evaluation reward: 2.39\n","episode: 1220   score: 3.0   memory length: 232038   epsilon: 0.7385627800056755    steps: 230    lr: 4e-05     evaluation reward: 2.42\n","episode: 1221   score: 3.0   memory length: 232266   epsilon: 0.7381113400056853    steps: 228    lr: 4e-05     evaluation reward: 2.42\n","episode: 1222   score: 2.0   memory length: 232485   epsilon: 0.7376777200056948    steps: 219    lr: 4e-05     evaluation reward: 2.41\n","episode: 1223   score: 0.0   memory length: 232609   epsilon: 0.7374322000057001    steps: 124    lr: 4e-05     evaluation reward: 2.39\n","episode: 1224   score: 3.0   memory length: 232838   epsilon: 0.7369787800057099    steps: 229    lr: 4e-05     evaluation reward: 2.39\n","episode: 1225   score: 1.0   memory length: 232990   epsilon: 0.7366778200057165    steps: 152    lr: 4e-05     evaluation reward: 2.39\n","episode: 1226   score: 2.0   memory length: 233189   epsilon: 0.736283800005725    steps: 199    lr: 4e-05     evaluation reward: 2.41\n","episode: 1227   score: 6.0   memory length: 233564   epsilon: 0.7355413000057411    steps: 375    lr: 4e-05     evaluation reward: 2.46\n","episode: 1228   score: 3.0   memory length: 233791   epsilon: 0.7350918400057509    steps: 227    lr: 4e-05     evaluation reward: 2.49\n","episode: 1229   score: 2.0   memory length: 233990   epsilon: 0.7346978200057594    steps: 199    lr: 4e-05     evaluation reward: 2.49\n","episode: 1230   score: 3.0   memory length: 234219   epsilon: 0.7342444000057693    steps: 229    lr: 4e-05     evaluation reward: 2.49\n","episode: 1231   score: 2.0   memory length: 234417   epsilon: 0.7338523600057778    steps: 198    lr: 4e-05     evaluation reward: 2.49\n","episode: 1232   score: 2.0   memory length: 234599   epsilon: 0.7334920000057856    steps: 182    lr: 4e-05     evaluation reward: 2.45\n","episode: 1233   score: 3.0   memory length: 234826   epsilon: 0.7330425400057954    steps: 227    lr: 4e-05     evaluation reward: 2.46\n","episode: 1234   score: 4.0   memory length: 235082   epsilon: 0.7325356600058064    steps: 256    lr: 4e-05     evaluation reward: 2.48\n","episode: 1235   score: 2.0   memory length: 235263   epsilon: 0.7321772800058142    steps: 181    lr: 4e-05     evaluation reward: 2.5\n","episode: 1236   score: 2.0   memory length: 235443   epsilon: 0.7318208800058219    steps: 180    lr: 4e-05     evaluation reward: 2.5\n","episode: 1237   score: 4.0   memory length: 235718   epsilon: 0.7312763800058337    steps: 275    lr: 4e-05     evaluation reward: 2.52\n","episode: 1238   score: 2.0   memory length: 235920   epsilon: 0.7308764200058424    steps: 202    lr: 4e-05     evaluation reward: 2.52\n","episode: 1239   score: 3.0   memory length: 236167   epsilon: 0.730387360005853    steps: 247    lr: 4e-05     evaluation reward: 2.5\n","episode: 1240   score: 4.0   memory length: 236427   epsilon: 0.7298725600058642    steps: 260    lr: 4e-05     evaluation reward: 2.52\n","episode: 1241   score: 2.0   memory length: 236625   epsilon: 0.7294805200058727    steps: 198    lr: 4e-05     evaluation reward: 2.51\n","episode: 1242   score: 1.0   memory length: 236777   epsilon: 0.7291795600058792    steps: 152    lr: 4e-05     evaluation reward: 2.5\n","episode: 1243   score: 4.0   memory length: 237053   epsilon: 0.7286330800058911    steps: 276    lr: 4e-05     evaluation reward: 2.52\n","episode: 1244   score: 0.0   memory length: 237177   epsilon: 0.7283875600058964    steps: 124    lr: 4e-05     evaluation reward: 2.42\n","episode: 1245   score: 4.0   memory length: 237477   epsilon: 0.7277935600059093    steps: 300    lr: 4e-05     evaluation reward: 2.42\n","episode: 1246   score: 2.0   memory length: 237676   epsilon: 0.7273995400059179    steps: 199    lr: 4e-05     evaluation reward: 2.42\n","episode: 1247   score: 0.0   memory length: 237800   epsilon: 0.7271540200059232    steps: 124    lr: 4e-05     evaluation reward: 2.4\n","episode: 1248   score: 7.0   memory length: 238049   epsilon: 0.7266610000059339    steps: 249    lr: 4e-05     evaluation reward: 2.42\n","episode: 1249   score: 4.0   memory length: 238328   epsilon: 0.7261085800059459    steps: 279    lr: 4e-05     evaluation reward: 2.44\n","episode: 1250   score: 2.0   memory length: 238547   epsilon: 0.7256749600059553    steps: 219    lr: 4e-05     evaluation reward: 2.44\n","episode: 1251   score: 4.0   memory length: 238842   epsilon: 0.725090860005968    steps: 295    lr: 4e-05     evaluation reward: 2.46\n","episode: 1252   score: 5.0   memory length: 239147   epsilon: 0.7244869600059811    steps: 305    lr: 4e-05     evaluation reward: 2.49\n","episode: 1253   score: 5.0   memory length: 239474   epsilon: 0.7238395000059952    steps: 327    lr: 4e-05     evaluation reward: 2.5\n","episode: 1254   score: 2.0   memory length: 239672   epsilon: 0.7234474600060037    steps: 198    lr: 4e-05     evaluation reward: 2.48\n","episode: 1255   score: 2.0   memory length: 239873   epsilon: 0.7230494800060123    steps: 201    lr: 4e-05     evaluation reward: 2.47\n","episode: 1256   score: 2.0   memory length: 240090   epsilon: 0.7226198200060217    steps: 217    lr: 4e-05     evaluation reward: 2.45\n","episode: 1257   score: 2.0   memory length: 240289   epsilon: 0.7222258000060302    steps: 199    lr: 4e-05     evaluation reward: 2.46\n","episode: 1258   score: 4.0   memory length: 240587   epsilon: 0.721635760006043    steps: 298    lr: 4e-05     evaluation reward: 2.46\n","episode: 1259   score: 2.0   memory length: 240786   epsilon: 0.7212417400060516    steps: 199    lr: 4e-05     evaluation reward: 2.46\n","episode: 1260   score: 2.0   memory length: 240968   epsilon: 0.7208813800060594    steps: 182    lr: 4e-05     evaluation reward: 2.46\n","episode: 1261   score: 3.0   memory length: 241196   epsilon: 0.7204299400060692    steps: 228    lr: 4e-05     evaluation reward: 2.47\n","episode: 1262   score: 3.0   memory length: 241423   epsilon: 0.719980480006079    steps: 227    lr: 4e-05     evaluation reward: 2.48\n","episode: 1263   score: 1.0   memory length: 241575   epsilon: 0.7196795200060855    steps: 152    lr: 4e-05     evaluation reward: 2.46\n","episode: 1264   score: 0.0   memory length: 241699   epsilon: 0.7194340000060908    steps: 124    lr: 4e-05     evaluation reward: 2.44\n","episode: 1265   score: 3.0   memory length: 241925   epsilon: 0.7189865200061005    steps: 226    lr: 4e-05     evaluation reward: 2.45\n","episode: 1266   score: 3.0   memory length: 242152   epsilon: 0.7185370600061103    steps: 227    lr: 4e-05     evaluation reward: 2.46\n","episode: 1267   score: 3.0   memory length: 242379   epsilon: 0.71808760000612    steps: 227    lr: 4e-05     evaluation reward: 2.49\n","episode: 1268   score: 4.0   memory length: 242638   epsilon: 0.7175747800061312    steps: 259    lr: 4e-05     evaluation reward: 2.5\n","episode: 1269   score: 2.0   memory length: 242837   epsilon: 0.7171807600061397    steps: 199    lr: 4e-05     evaluation reward: 2.52\n","episode: 1270   score: 3.0   memory length: 243087   epsilon: 0.7166857600061505    steps: 250    lr: 4e-05     evaluation reward: 2.52\n","episode: 1271   score: 4.0   memory length: 243342   epsilon: 0.7161808600061614    steps: 255    lr: 4e-05     evaluation reward: 2.56\n","episode: 1272   score: 3.0   memory length: 243590   epsilon: 0.7156898200061721    steps: 248    lr: 4e-05     evaluation reward: 2.57\n","episode: 1273   score: 6.0   memory length: 243985   epsilon: 0.7149077200061891    steps: 395    lr: 4e-05     evaluation reward: 2.57\n","episode: 1274   score: 2.0   memory length: 244208   epsilon: 0.7144661800061987    steps: 223    lr: 4e-05     evaluation reward: 2.58\n","episode: 1275   score: 3.0   memory length: 244435   epsilon: 0.7140167200062084    steps: 227    lr: 4e-05     evaluation reward: 2.58\n","episode: 1276   score: 1.0   memory length: 244608   epsilon: 0.7136741800062159    steps: 173    lr: 4e-05     evaluation reward: 2.57\n","episode: 1277   score: 3.0   memory length: 244835   epsilon: 0.7132247200062256    steps: 227    lr: 4e-05     evaluation reward: 2.58\n","episode: 1278   score: 2.0   memory length: 245034   epsilon: 0.7128307000062342    steps: 199    lr: 4e-05     evaluation reward: 2.58\n","episode: 1279   score: 2.0   memory length: 245214   epsilon: 0.7124743000062419    steps: 180    lr: 4e-05     evaluation reward: 2.58\n","episode: 1280   score: 2.0   memory length: 245415   epsilon: 0.7120763200062505    steps: 201    lr: 4e-05     evaluation reward: 2.59\n","episode: 1281   score: 3.0   memory length: 245663   epsilon: 0.7115852800062612    steps: 248    lr: 4e-05     evaluation reward: 2.6\n","episode: 1282   score: 4.0   memory length: 245981   epsilon: 0.7109556400062749    steps: 318    lr: 4e-05     evaluation reward: 2.62\n","episode: 1283   score: 3.0   memory length: 246209   epsilon: 0.7105042000062847    steps: 228    lr: 4e-05     evaluation reward: 2.61\n","episode: 1284   score: 3.0   memory length: 246435   epsilon: 0.7100567200062944    steps: 226    lr: 4e-05     evaluation reward: 2.61\n","episode: 1285   score: 6.0   memory length: 246788   epsilon: 0.7093577800063096    steps: 353    lr: 4e-05     evaluation reward: 2.65\n","episode: 1286   score: 2.0   memory length: 246969   epsilon: 0.7089994000063173    steps: 181    lr: 4e-05     evaluation reward: 2.63\n","episode: 1287   score: 2.0   memory length: 247149   epsilon: 0.7086430000063251    steps: 180    lr: 4e-05     evaluation reward: 2.63\n","episode: 1288   score: 2.0   memory length: 247348   epsilon: 0.7082489800063336    steps: 199    lr: 4e-05     evaluation reward: 2.63\n","episode: 1289   score: 3.0   memory length: 247592   epsilon: 0.7077658600063441    steps: 244    lr: 4e-05     evaluation reward: 2.64\n","episode: 1290   score: 2.0   memory length: 247791   epsilon: 0.7073718400063527    steps: 199    lr: 4e-05     evaluation reward: 2.63\n","episode: 1291   score: 2.0   memory length: 247990   epsilon: 0.7069778200063612    steps: 199    lr: 4e-05     evaluation reward: 2.63\n","episode: 1292   score: 3.0   memory length: 248220   epsilon: 0.7065224200063711    steps: 230    lr: 4e-05     evaluation reward: 2.63\n","episode: 1293   score: 3.0   memory length: 248487   epsilon: 0.7059937600063826    steps: 267    lr: 4e-05     evaluation reward: 2.65\n","episode: 1294   score: 4.0   memory length: 248796   epsilon: 0.7053819400063959    steps: 309    lr: 4e-05     evaluation reward: 2.69\n","episode: 1295   score: 4.0   memory length: 249075   epsilon: 0.7048295200064079    steps: 279    lr: 4e-05     evaluation reward: 2.71\n","episode: 1296   score: 4.0   memory length: 249351   epsilon: 0.7042830400064197    steps: 276    lr: 4e-05     evaluation reward: 2.72\n","episode: 1297   score: 1.0   memory length: 249503   epsilon: 0.7039820800064263    steps: 152    lr: 4e-05     evaluation reward: 2.69\n","episode: 1298   score: 0.0   memory length: 249627   epsilon: 0.7037365600064316    steps: 124    lr: 4e-05     evaluation reward: 2.66\n","episode: 1299   score: 3.0   memory length: 249874   epsilon: 0.7032475000064422    steps: 247    lr: 4e-05     evaluation reward: 2.69\n","episode: 1300   score: 0.0   memory length: 249997   epsilon: 0.7030039600064475    steps: 123    lr: 4e-05     evaluation reward: 2.69\n","episode: 1301   score: 1.0   memory length: 250149   epsilon: 0.702703000006454    steps: 152    lr: 4e-05     evaluation reward: 2.68\n","episode: 1302   score: 4.0   memory length: 250446   epsilon: 0.7021149400064668    steps: 297    lr: 4e-05     evaluation reward: 2.7\n","episode: 1303   score: 2.0   memory length: 250645   epsilon: 0.7017209200064753    steps: 199    lr: 4e-05     evaluation reward: 2.7\n","episode: 1304   score: 3.0   memory length: 250893   epsilon: 0.701229880006486    steps: 248    lr: 4e-05     evaluation reward: 2.72\n","episode: 1305   score: 5.0   memory length: 251220   epsilon: 0.7005824200065001    steps: 327    lr: 4e-05     evaluation reward: 2.76\n","episode: 1306   score: 4.0   memory length: 251493   epsilon: 0.7000418800065118    steps: 273    lr: 4e-05     evaluation reward: 2.77\n","episode: 1307   score: 6.0   memory length: 251871   epsilon: 0.699293440006528    steps: 378    lr: 4e-05     evaluation reward: 2.82\n","episode: 1308   score: 2.0   memory length: 252054   epsilon: 0.6989311000065359    steps: 183    lr: 4e-05     evaluation reward: 2.81\n","episode: 1309   score: 2.0   memory length: 252252   epsilon: 0.6985390600065444    steps: 198    lr: 4e-05     evaluation reward: 2.79\n","episode: 1310   score: 2.0   memory length: 252470   epsilon: 0.6981074200065538    steps: 218    lr: 4e-05     evaluation reward: 2.77\n","episode: 1311   score: 5.0   memory length: 252794   epsilon: 0.6974659000065677    steps: 324    lr: 4e-05     evaluation reward: 2.81\n","episode: 1312   score: 4.0   memory length: 253070   epsilon: 0.6969194200065796    steps: 276    lr: 4e-05     evaluation reward: 2.8\n","episode: 1313   score: 2.0   memory length: 253269   epsilon: 0.6965254000065881    steps: 199    lr: 4e-05     evaluation reward: 2.79\n","episode: 1314   score: 4.0   memory length: 253562   epsilon: 0.6959452600066007    steps: 293    lr: 4e-05     evaluation reward: 2.79\n","episode: 1315   score: 4.0   memory length: 253820   epsilon: 0.6954344200066118    steps: 258    lr: 4e-05     evaluation reward: 2.8\n","episode: 1316   score: 4.0   memory length: 254095   epsilon: 0.6948899200066236    steps: 275    lr: 4e-05     evaluation reward: 2.8\n","episode: 1317   score: 3.0   memory length: 254322   epsilon: 0.6944404600066334    steps: 227    lr: 4e-05     evaluation reward: 2.8\n","episode: 1318   score: 2.0   memory length: 254523   epsilon: 0.694042480006642    steps: 201    lr: 4e-05     evaluation reward: 2.81\n","episode: 1319   score: 3.0   memory length: 254772   epsilon: 0.6935494600066527    steps: 249    lr: 4e-05     evaluation reward: 2.81\n","episode: 1320   score: 7.0   memory length: 255238   epsilon: 0.6926267800066728    steps: 466    lr: 4e-05     evaluation reward: 2.85\n","episode: 1321   score: 3.0   memory length: 255469   epsilon: 0.6921694000066827    steps: 231    lr: 4e-05     evaluation reward: 2.85\n","episode: 1322   score: 1.0   memory length: 255621   epsilon: 0.6918684400066892    steps: 152    lr: 4e-05     evaluation reward: 2.84\n","episode: 1323   score: 2.0   memory length: 255804   epsilon: 0.6915061000066971    steps: 183    lr: 4e-05     evaluation reward: 2.86\n","episode: 1324   score: 2.0   memory length: 256026   epsilon: 0.6910665400067066    steps: 222    lr: 4e-05     evaluation reward: 2.85\n","episode: 1325   score: 4.0   memory length: 256324   epsilon: 0.6904765000067195    steps: 298    lr: 4e-05     evaluation reward: 2.88\n","episode: 1326   score: 2.0   memory length: 256505   epsilon: 0.6901181200067272    steps: 181    lr: 4e-05     evaluation reward: 2.88\n","episode: 1327   score: 2.0   memory length: 256706   epsilon: 0.6897201400067359    steps: 201    lr: 4e-05     evaluation reward: 2.84\n","episode: 1328   score: 2.0   memory length: 256905   epsilon: 0.6893261200067444    steps: 199    lr: 4e-05     evaluation reward: 2.83\n","episode: 1329   score: 4.0   memory length: 257202   epsilon: 0.6887380600067572    steps: 297    lr: 4e-05     evaluation reward: 2.85\n","episode: 1330   score: 2.0   memory length: 257401   epsilon: 0.6883440400067657    steps: 199    lr: 4e-05     evaluation reward: 2.84\n","episode: 1331   score: 2.0   memory length: 257620   epsilon: 0.6879104200067752    steps: 219    lr: 4e-05     evaluation reward: 2.84\n","episode: 1332   score: 4.0   memory length: 257908   epsilon: 0.6873401800067875    steps: 288    lr: 4e-05     evaluation reward: 2.86\n","episode: 1333   score: 3.0   memory length: 258153   epsilon: 0.6868550800067981    steps: 245    lr: 4e-05     evaluation reward: 2.86\n","episode: 1334   score: 3.0   memory length: 258379   epsilon: 0.6864076000068078    steps: 226    lr: 4e-05     evaluation reward: 2.85\n","episode: 1335   score: 3.0   memory length: 258606   epsilon: 0.6859581400068175    steps: 227    lr: 4e-05     evaluation reward: 2.86\n","episode: 1336   score: 3.0   memory length: 258836   epsilon: 0.6855027400068274    steps: 230    lr: 4e-05     evaluation reward: 2.87\n","episode: 1337   score: 2.0   memory length: 259035   epsilon: 0.685108720006836    steps: 199    lr: 4e-05     evaluation reward: 2.85\n","episode: 1338   score: 2.0   memory length: 259234   epsilon: 0.6847147000068445    steps: 199    lr: 4e-05     evaluation reward: 2.85\n","episode: 1339   score: 4.0   memory length: 259531   epsilon: 0.6841266400068573    steps: 297    lr: 4e-05     evaluation reward: 2.86\n","episode: 1340   score: 0.0   memory length: 259655   epsilon: 0.6838811200068626    steps: 124    lr: 4e-05     evaluation reward: 2.82\n","episode: 1341   score: 0.0   memory length: 259779   epsilon: 0.683635600006868    steps: 124    lr: 4e-05     evaluation reward: 2.8\n","episode: 1342   score: 4.0   memory length: 260100   epsilon: 0.6830000200068818    steps: 321    lr: 4e-05     evaluation reward: 2.83\n","episode: 1343   score: 2.0   memory length: 260299   epsilon: 0.6826060000068903    steps: 199    lr: 4e-05     evaluation reward: 2.81\n","episode: 1344   score: 0.0   memory length: 260423   epsilon: 0.6823604800068956    steps: 124    lr: 4e-05     evaluation reward: 2.81\n","episode: 1345   score: 2.0   memory length: 260622   epsilon: 0.6819664600069042    steps: 199    lr: 4e-05     evaluation reward: 2.79\n","episode: 1346   score: 3.0   memory length: 260869   epsilon: 0.6814774000069148    steps: 247    lr: 4e-05     evaluation reward: 2.8\n","episode: 1347   score: 5.0   memory length: 261166   epsilon: 0.6808893400069276    steps: 297    lr: 4e-05     evaluation reward: 2.85\n","episode: 1348   score: 2.0   memory length: 261365   epsilon: 0.6804953200069361    steps: 199    lr: 4e-05     evaluation reward: 2.8\n","episode: 1349   score: 3.0   memory length: 261612   epsilon: 0.6800062600069467    steps: 247    lr: 4e-05     evaluation reward: 2.79\n","episode: 1350   score: 3.0   memory length: 261840   epsilon: 0.6795548200069566    steps: 228    lr: 4e-05     evaluation reward: 2.8\n","episode: 1351   score: 3.0   memory length: 262067   epsilon: 0.6791053600069663    steps: 227    lr: 4e-05     evaluation reward: 2.79\n","episode: 1352   score: 0.0   memory length: 262190   epsilon: 0.6788618200069716    steps: 123    lr: 4e-05     evaluation reward: 2.74\n","episode: 1353   score: 3.0   memory length: 262419   epsilon: 0.6784084000069814    steps: 229    lr: 4e-05     evaluation reward: 2.72\n","episode: 1354   score: 3.0   memory length: 262646   epsilon: 0.6779589400069912    steps: 227    lr: 4e-05     evaluation reward: 2.73\n","episode: 1355   score: 2.0   memory length: 262827   epsilon: 0.677600560006999    steps: 181    lr: 4e-05     evaluation reward: 2.73\n","episode: 1356   score: 3.0   memory length: 263076   epsilon: 0.6771075400070097    steps: 249    lr: 4e-05     evaluation reward: 2.74\n","episode: 1357   score: 3.0   memory length: 263305   epsilon: 0.6766541200070195    steps: 229    lr: 4e-05     evaluation reward: 2.75\n","episode: 1358   score: 1.0   memory length: 263456   epsilon: 0.676355140007026    steps: 151    lr: 4e-05     evaluation reward: 2.72\n","episode: 1359   score: 1.0   memory length: 263628   epsilon: 0.6760145800070334    steps: 172    lr: 4e-05     evaluation reward: 2.71\n","episode: 1360   score: 7.0   memory length: 263949   epsilon: 0.6753790000070472    steps: 321    lr: 4e-05     evaluation reward: 2.76\n","episode: 1361   score: 3.0   memory length: 264176   epsilon: 0.674929540007057    steps: 227    lr: 4e-05     evaluation reward: 2.76\n","episode: 1362   score: 4.0   memory length: 264453   epsilon: 0.6743810800070689    steps: 277    lr: 4e-05     evaluation reward: 2.77\n","episode: 1363   score: 3.0   memory length: 264680   epsilon: 0.6739316200070786    steps: 227    lr: 4e-05     evaluation reward: 2.79\n","episode: 1364   score: 1.0   memory length: 264849   epsilon: 0.6735970000070859    steps: 169    lr: 4e-05     evaluation reward: 2.8\n","episode: 1365   score: 6.0   memory length: 265228   epsilon: 0.6728465800071022    steps: 379    lr: 4e-05     evaluation reward: 2.83\n","episode: 1366   score: 4.0   memory length: 265525   epsilon: 0.672258520007115    steps: 297    lr: 4e-05     evaluation reward: 2.84\n","episode: 1367   score: 2.0   memory length: 265744   epsilon: 0.6718249000071244    steps: 219    lr: 4e-05     evaluation reward: 2.83\n","episode: 1368   score: 0.0   memory length: 265867   epsilon: 0.6715813600071296    steps: 123    lr: 4e-05     evaluation reward: 2.79\n","episode: 1369   score: 3.0   memory length: 266118   epsilon: 0.6710843800071404    steps: 251    lr: 4e-05     evaluation reward: 2.8\n","episode: 1370   score: 2.0   memory length: 266319   epsilon: 0.6706864000071491    steps: 201    lr: 4e-05     evaluation reward: 2.79\n","episode: 1371   score: 0.0   memory length: 266443   epsilon: 0.6704408800071544    steps: 124    lr: 4e-05     evaluation reward: 2.75\n","episode: 1372   score: 1.0   memory length: 266615   epsilon: 0.6701003200071618    steps: 172    lr: 4e-05     evaluation reward: 2.73\n","episode: 1373   score: 2.0   memory length: 266818   epsilon: 0.6696983800071705    steps: 203    lr: 4e-05     evaluation reward: 2.69\n","episode: 1374   score: 3.0   memory length: 267065   epsilon: 0.6692093200071811    steps: 247    lr: 4e-05     evaluation reward: 2.7\n","episode: 1375   score: 2.0   memory length: 267284   epsilon: 0.6687757000071906    steps: 219    lr: 4e-05     evaluation reward: 2.69\n","episode: 1376   score: 4.0   memory length: 267602   epsilon: 0.6681460600072042    steps: 318    lr: 4e-05     evaluation reward: 2.72\n","episode: 1377   score: 2.0   memory length: 267800   epsilon: 0.6677540200072127    steps: 198    lr: 4e-05     evaluation reward: 2.71\n","episode: 1378   score: 5.0   memory length: 268134   epsilon: 0.6670927000072271    steps: 334    lr: 4e-05     evaluation reward: 2.74\n","episode: 1379   score: 3.0   memory length: 268361   epsilon: 0.6666432400072368    steps: 227    lr: 4e-05     evaluation reward: 2.75\n","episode: 1380   score: 4.0   memory length: 268639   epsilon: 0.6660928000072488    steps: 278    lr: 4e-05     evaluation reward: 2.77\n","episode: 1381   score: 0.0   memory length: 268762   epsilon: 0.6658492600072541    steps: 123    lr: 4e-05     evaluation reward: 2.74\n","episode: 1382   score: 3.0   memory length: 268989   epsilon: 0.6653998000072638    steps: 227    lr: 4e-05     evaluation reward: 2.73\n","episode: 1383   score: 3.0   memory length: 269216   epsilon: 0.6649503400072736    steps: 227    lr: 4e-05     evaluation reward: 2.73\n","episode: 1384   score: 4.0   memory length: 269530   epsilon: 0.6643286200072871    steps: 314    lr: 4e-05     evaluation reward: 2.74\n","episode: 1385   score: 3.0   memory length: 269779   epsilon: 0.6638356000072978    steps: 249    lr: 4e-05     evaluation reward: 2.71\n","episode: 1386   score: 2.0   memory length: 269978   epsilon: 0.6634415800073064    steps: 199    lr: 4e-05     evaluation reward: 2.71\n","episode: 1387   score: 5.0   memory length: 270305   epsilon: 0.6627941200073204    steps: 327    lr: 4e-05     evaluation reward: 2.74\n","episode: 1388   score: 3.0   memory length: 270574   epsilon: 0.662261500007332    steps: 269    lr: 4e-05     evaluation reward: 2.75\n","episode: 1389   score: 4.0   memory length: 270852   epsilon: 0.6617110600073439    steps: 278    lr: 4e-05     evaluation reward: 2.76\n","episode: 1390   score: 2.0   memory length: 271051   epsilon: 0.6613170400073525    steps: 199    lr: 4e-05     evaluation reward: 2.76\n","episode: 1391   score: 2.0   memory length: 271234   epsilon: 0.6609547000073603    steps: 183    lr: 4e-05     evaluation reward: 2.76\n","episode: 1392   score: 3.0   memory length: 271444   epsilon: 0.6605389000073694    steps: 210    lr: 4e-05     evaluation reward: 2.76\n","episode: 1393   score: 1.0   memory length: 271596   epsilon: 0.6602379400073759    steps: 152    lr: 4e-05     evaluation reward: 2.74\n","episode: 1394   score: 2.0   memory length: 271795   epsilon: 0.6598439200073845    steps: 199    lr: 4e-05     evaluation reward: 2.72\n","episode: 1395   score: 8.0   memory length: 272111   epsilon: 0.659218240007398    steps: 316    lr: 4e-05     evaluation reward: 2.76\n","episode: 1396   score: 4.0   memory length: 272370   epsilon: 0.6587054200074092    steps: 259    lr: 4e-05     evaluation reward: 2.76\n","episode: 1397   score: 3.0   memory length: 272596   epsilon: 0.6582579400074189    steps: 226    lr: 4e-05     evaluation reward: 2.78\n","episode: 1398   score: 4.0   memory length: 272873   epsilon: 0.6577094800074308    steps: 277    lr: 4e-05     evaluation reward: 2.82\n","episode: 1399   score: 6.0   memory length: 273210   epsilon: 0.6570422200074453    steps: 337    lr: 4e-05     evaluation reward: 2.85\n","episode: 1400   score: 4.0   memory length: 273469   epsilon: 0.6565294000074564    steps: 259    lr: 4e-05     evaluation reward: 2.89\n","episode: 1401   score: 3.0   memory length: 273716   epsilon: 0.656040340007467    steps: 247    lr: 4e-05     evaluation reward: 2.91\n","episode: 1402   score: 3.0   memory length: 273963   epsilon: 0.6555512800074776    steps: 247    lr: 4e-05     evaluation reward: 2.9\n","episode: 1403   score: 4.0   memory length: 274242   epsilon: 0.6549988600074896    steps: 279    lr: 4e-05     evaluation reward: 2.92\n","episode: 1404   score: 4.0   memory length: 274517   epsilon: 0.6544543600075015    steps: 275    lr: 4e-05     evaluation reward: 2.93\n","episode: 1405   score: 3.0   memory length: 274744   epsilon: 0.6540049000075112    steps: 227    lr: 4e-05     evaluation reward: 2.91\n","episode: 1406   score: 2.0   memory length: 274945   epsilon: 0.6536069200075199    steps: 201    lr: 4e-05     evaluation reward: 2.89\n","episode: 1407   score: 5.0   memory length: 275272   epsilon: 0.6529594600075339    steps: 327    lr: 4e-05     evaluation reward: 2.88\n","episode: 1408   score: 2.0   memory length: 275471   epsilon: 0.6525654400075425    steps: 199    lr: 4e-05     evaluation reward: 2.88\n","episode: 1409   score: 1.0   memory length: 275643   epsilon: 0.6522248800075499    steps: 172    lr: 4e-05     evaluation reward: 2.87\n","episode: 1410   score: 3.0   memory length: 275894   epsilon: 0.6517279000075606    steps: 251    lr: 4e-05     evaluation reward: 2.88\n","episode: 1411   score: 4.0   memory length: 276191   epsilon: 0.6511398400075734    steps: 297    lr: 4e-05     evaluation reward: 2.87\n","episode: 1412   score: 3.0   memory length: 276418   epsilon: 0.6506903800075832    steps: 227    lr: 4e-05     evaluation reward: 2.86\n","episode: 1413   score: 0.0   memory length: 276542   epsilon: 0.6504448600075885    steps: 124    lr: 4e-05     evaluation reward: 2.84\n","episode: 1414   score: 3.0   memory length: 276809   epsilon: 0.6499162000076    steps: 267    lr: 4e-05     evaluation reward: 2.83\n","episode: 1415   score: 4.0   memory length: 277085   epsilon: 0.6493697200076118    steps: 276    lr: 4e-05     evaluation reward: 2.83\n","episode: 1416   score: 0.0   memory length: 277209   epsilon: 0.6491242000076172    steps: 124    lr: 4e-05     evaluation reward: 2.79\n","episode: 1417   score: 4.0   memory length: 277508   epsilon: 0.64853218000763    steps: 299    lr: 4e-05     evaluation reward: 2.8\n","episode: 1418   score: 3.0   memory length: 277735   epsilon: 0.6480827200076398    steps: 227    lr: 4e-05     evaluation reward: 2.81\n","episode: 1419   score: 3.0   memory length: 277984   epsilon: 0.6475897000076505    steps: 249    lr: 4e-05     evaluation reward: 2.81\n","episode: 1420   score: 9.0   memory length: 278367   epsilon: 0.646831360007667    steps: 383    lr: 4e-05     evaluation reward: 2.83\n","episode: 1421   score: 3.0   memory length: 278594   epsilon: 0.6463819000076767    steps: 227    lr: 4e-05     evaluation reward: 2.83\n","episode: 1422   score: 1.0   memory length: 278746   epsilon: 0.6460809400076832    steps: 152    lr: 4e-05     evaluation reward: 2.83\n","episode: 1423   score: 1.0   memory length: 278898   epsilon: 0.6457799800076898    steps: 152    lr: 4e-05     evaluation reward: 2.82\n","episode: 1424   score: 4.0   memory length: 279195   epsilon: 0.6451919200077025    steps: 297    lr: 4e-05     evaluation reward: 2.84\n","episode: 1425   score: 3.0   memory length: 279423   epsilon: 0.6447404800077123    steps: 228    lr: 4e-05     evaluation reward: 2.83\n","episode: 1426   score: 4.0   memory length: 279740   epsilon: 0.644112820007726    steps: 317    lr: 4e-05     evaluation reward: 2.85\n","episode: 1427   score: 4.0   memory length: 280056   epsilon: 0.6434871400077395    steps: 316    lr: 4e-05     evaluation reward: 2.87\n","episode: 1428   score: 4.0   memory length: 280332   epsilon: 0.6429406600077514    steps: 276    lr: 4e-05     evaluation reward: 2.89\n","episode: 1429   score: 4.0   memory length: 280609   epsilon: 0.6423922000077633    steps: 277    lr: 4e-05     evaluation reward: 2.89\n","episode: 1430   score: 0.0   memory length: 280732   epsilon: 0.6421486600077686    steps: 123    lr: 4e-05     evaluation reward: 2.87\n","episode: 1431   score: 7.0   memory length: 281164   epsilon: 0.6412933000077872    steps: 432    lr: 4e-05     evaluation reward: 2.92\n","episode: 1432   score: 4.0   memory length: 281461   epsilon: 0.6407052400077999    steps: 297    lr: 4e-05     evaluation reward: 2.92\n","episode: 1433   score: 2.0   memory length: 281660   epsilon: 0.6403112200078085    steps: 199    lr: 4e-05     evaluation reward: 2.91\n","episode: 1434   score: 7.0   memory length: 282062   epsilon: 0.6395152600078258    steps: 402    lr: 4e-05     evaluation reward: 2.95\n","episode: 1435   score: 2.0   memory length: 282260   epsilon: 0.6391232200078343    steps: 198    lr: 4e-05     evaluation reward: 2.94\n","episode: 1436   score: 2.0   memory length: 282459   epsilon: 0.6387292000078428    steps: 199    lr: 4e-05     evaluation reward: 2.93\n","episode: 1437   score: 4.0   memory length: 282737   epsilon: 0.6381787600078548    steps: 278    lr: 4e-05     evaluation reward: 2.95\n","episode: 1438   score: 6.0   memory length: 283112   epsilon: 0.6374362600078709    steps: 375    lr: 4e-05     evaluation reward: 2.99\n","episode: 1439   score: 2.0   memory length: 283311   epsilon: 0.6370422400078795    steps: 199    lr: 4e-05     evaluation reward: 2.97\n","episode: 1440   score: 4.0   memory length: 283608   epsilon: 0.6364541800078922    steps: 297    lr: 4e-05     evaluation reward: 3.01\n","episode: 1441   score: 2.0   memory length: 283807   epsilon: 0.6360601600079008    steps: 199    lr: 4e-05     evaluation reward: 3.03\n","episode: 1442   score: 4.0   memory length: 284125   epsilon: 0.6354305200079144    steps: 318    lr: 4e-05     evaluation reward: 3.03\n","episode: 1443   score: 2.0   memory length: 284323   epsilon: 0.635038480007923    steps: 198    lr: 4e-05     evaluation reward: 3.03\n","episode: 1444   score: 0.0   memory length: 284447   epsilon: 0.6347929600079283    steps: 124    lr: 4e-05     evaluation reward: 3.03\n","episode: 1445   score: 1.0   memory length: 284619   epsilon: 0.6344524000079357    steps: 172    lr: 4e-05     evaluation reward: 3.02\n","episode: 1446   score: 1.0   memory length: 284771   epsilon: 0.6341514400079422    steps: 152    lr: 4e-05     evaluation reward: 3.0\n","episode: 1447   score: 3.0   memory length: 285019   epsilon: 0.6336604000079529    steps: 248    lr: 4e-05     evaluation reward: 2.98\n","episode: 1448   score: 2.0   memory length: 285220   epsilon: 0.6332624200079615    steps: 201    lr: 4e-05     evaluation reward: 2.98\n","episode: 1449   score: 5.0   memory length: 285527   epsilon: 0.6326545600079747    steps: 307    lr: 4e-05     evaluation reward: 3.0\n","episode: 1450   score: 3.0   memory length: 285774   epsilon: 0.6321655000079853    steps: 247    lr: 4e-05     evaluation reward: 3.0\n","episode: 1451   score: 5.0   memory length: 286100   epsilon: 0.6315200200079993    steps: 326    lr: 4e-05     evaluation reward: 3.02\n","episode: 1452   score: 3.0   memory length: 286349   epsilon: 0.63102700000801    steps: 249    lr: 4e-05     evaluation reward: 3.05\n","episode: 1453   score: 0.0   memory length: 286472   epsilon: 0.6307834600080153    steps: 123    lr: 4e-05     evaluation reward: 3.02\n","episode: 1454   score: 1.0   memory length: 286624   epsilon: 0.6304825000080219    steps: 152    lr: 4e-05     evaluation reward: 3.0\n","episode: 1455   score: 2.0   memory length: 286827   epsilon: 0.6300805600080306    steps: 203    lr: 4e-05     evaluation reward: 3.0\n","episode: 1456   score: 4.0   memory length: 287104   epsilon: 0.6295321000080425    steps: 277    lr: 4e-05     evaluation reward: 3.01\n","episode: 1457   score: 5.0   memory length: 287396   epsilon: 0.628953940008055    steps: 292    lr: 4e-05     evaluation reward: 3.03\n","episode: 1458   score: 2.0   memory length: 287595   epsilon: 0.6285599200080636    steps: 199    lr: 4e-05     evaluation reward: 3.04\n","episode: 1459   score: 3.0   memory length: 287861   epsilon: 0.628033240008075    steps: 266    lr: 4e-05     evaluation reward: 3.06\n","episode: 1460   score: 4.0   memory length: 288156   epsilon: 0.6274491400080877    steps: 295    lr: 4e-05     evaluation reward: 3.03\n","episode: 1461   score: 4.0   memory length: 288418   epsilon: 0.626930380008099    steps: 262    lr: 4e-05     evaluation reward: 3.04\n","episode: 1462   score: 3.0   memory length: 288647   epsilon: 0.6264769600081088    steps: 229    lr: 4e-05     evaluation reward: 3.03\n","episode: 1463   score: 4.0   memory length: 288944   epsilon: 0.6258889000081216    steps: 297    lr: 4e-05     evaluation reward: 3.04\n","episode: 1464   score: 3.0   memory length: 289189   epsilon: 0.6254038000081321    steps: 245    lr: 4e-05     evaluation reward: 3.06\n","episode: 1465   score: 3.0   memory length: 289437   epsilon: 0.6249127600081428    steps: 248    lr: 4e-05     evaluation reward: 3.03\n","episode: 1466   score: 6.0   memory length: 289828   epsilon: 0.6241385800081596    steps: 391    lr: 4e-05     evaluation reward: 3.05\n","episode: 1467   score: 3.0   memory length: 290060   epsilon: 0.6236792200081696    steps: 232    lr: 4e-05     evaluation reward: 3.06\n","episode: 1468   score: 7.0   memory length: 290448   epsilon: 0.6229109800081862    steps: 388    lr: 4e-05     evaluation reward: 3.13\n","episode: 1469   score: 3.0   memory length: 290695   epsilon: 0.6224219200081968    steps: 247    lr: 4e-05     evaluation reward: 3.13\n","episode: 1470   score: 2.0   memory length: 290897   epsilon: 0.6220219600082055    steps: 202    lr: 4e-05     evaluation reward: 3.13\n","episode: 1471   score: 6.0   memory length: 291291   epsilon: 0.6212418400082225    steps: 394    lr: 4e-05     evaluation reward: 3.19\n","episode: 1472   score: 2.0   memory length: 291490   epsilon: 0.620847820008231    steps: 199    lr: 4e-05     evaluation reward: 3.2\n","episode: 1473   score: 4.0   memory length: 291808   epsilon: 0.6202181800082447    steps: 318    lr: 4e-05     evaluation reward: 3.22\n","episode: 1474   score: 2.0   memory length: 292024   epsilon: 0.619790500008254    steps: 216    lr: 4e-05     evaluation reward: 3.21\n","episode: 1475   score: 2.0   memory length: 292242   epsilon: 0.6193588600082633    steps: 218    lr: 4e-05     evaluation reward: 3.21\n","episode: 1476   score: 3.0   memory length: 292490   epsilon: 0.618867820008274    steps: 248    lr: 4e-05     evaluation reward: 3.2\n","episode: 1477   score: 2.0   memory length: 292672   epsilon: 0.6185074600082818    steps: 182    lr: 4e-05     evaluation reward: 3.2\n","episode: 1478   score: 3.0   memory length: 292899   epsilon: 0.6180580000082916    steps: 227    lr: 4e-05     evaluation reward: 3.18\n","episode: 1479   score: 2.0   memory length: 293098   epsilon: 0.6176639800083001    steps: 199    lr: 4e-05     evaluation reward: 3.17\n","episode: 1480   score: 6.0   memory length: 293457   epsilon: 0.6169531600083156    steps: 359    lr: 4e-05     evaluation reward: 3.19\n","episode: 1481   score: 4.0   memory length: 293736   epsilon: 0.6164007400083276    steps: 279    lr: 4e-05     evaluation reward: 3.23\n","episode: 1482   score: 2.0   memory length: 293935   epsilon: 0.6160067200083361    steps: 199    lr: 4e-05     evaluation reward: 3.22\n","episode: 1483   score: 1.0   memory length: 294086   epsilon: 0.6157077400083426    steps: 151    lr: 4e-05     evaluation reward: 3.2\n","episode: 1484   score: 2.0   memory length: 294285   epsilon: 0.6153137200083512    steps: 199    lr: 4e-05     evaluation reward: 3.18\n","episode: 1485   score: 3.0   memory length: 294532   epsilon: 0.6148246600083618    steps: 247    lr: 4e-05     evaluation reward: 3.18\n","episode: 1486   score: 5.0   memory length: 294860   epsilon: 0.6141752200083759    steps: 328    lr: 4e-05     evaluation reward: 3.21\n","episode: 1487   score: 4.0   memory length: 295139   epsilon: 0.6136228000083879    steps: 279    lr: 4e-05     evaluation reward: 3.2\n","episode: 1488   score: 1.0   memory length: 295310   epsilon: 0.6132842200083952    steps: 171    lr: 4e-05     evaluation reward: 3.18\n","episode: 1489   score: 1.0   memory length: 295480   epsilon: 0.6129476200084025    steps: 170    lr: 4e-05     evaluation reward: 3.15\n","episode: 1490   score: 0.0   memory length: 295604   epsilon: 0.6127021000084079    steps: 124    lr: 4e-05     evaluation reward: 3.13\n","episode: 1491   score: 3.0   memory length: 295831   epsilon: 0.6122526400084176    steps: 227    lr: 4e-05     evaluation reward: 3.14\n","episode: 1492   score: 1.0   memory length: 296001   epsilon: 0.6119160400084249    steps: 170    lr: 4e-05     evaluation reward: 3.12\n","episode: 1493   score: 2.0   memory length: 296184   epsilon: 0.6115537000084328    steps: 183    lr: 4e-05     evaluation reward: 3.13\n","episode: 1494   score: 3.0   memory length: 296413   epsilon: 0.6111002800084426    steps: 229    lr: 4e-05     evaluation reward: 3.14\n","episode: 1495   score: 2.0   memory length: 296612   epsilon: 0.6107062600084512    steps: 199    lr: 4e-05     evaluation reward: 3.08\n","episode: 1496   score: 4.0   memory length: 296867   epsilon: 0.6102013600084621    steps: 255    lr: 4e-05     evaluation reward: 3.08\n","episode: 1497   score: 3.0   memory length: 297094   epsilon: 0.6097519000084719    steps: 227    lr: 4e-05     evaluation reward: 3.08\n","episode: 1498   score: 5.0   memory length: 297366   epsilon: 0.6092133400084836    steps: 272    lr: 4e-05     evaluation reward: 3.09\n","episode: 1499   score: 2.0   memory length: 297585   epsilon: 0.608779720008493    steps: 219    lr: 4e-05     evaluation reward: 3.05\n","episode: 1500   score: 3.0   memory length: 297812   epsilon: 0.6083302600085028    steps: 227    lr: 4e-05     evaluation reward: 3.04\n","episode: 1501   score: 4.0   memory length: 298088   epsilon: 0.6077837800085146    steps: 276    lr: 4e-05     evaluation reward: 3.05\n","episode: 1502   score: 4.0   memory length: 298364   epsilon: 0.6072373000085265    steps: 276    lr: 4e-05     evaluation reward: 3.06\n","episode: 1503   score: 2.0   memory length: 298545   epsilon: 0.6068789200085343    steps: 181    lr: 4e-05     evaluation reward: 3.04\n","episode: 1504   score: 3.0   memory length: 298772   epsilon: 0.606429460008544    steps: 227    lr: 4e-05     evaluation reward: 3.03\n","episode: 1505   score: 3.0   memory length: 299041   epsilon: 0.6058968400085556    steps: 269    lr: 4e-05     evaluation reward: 3.03\n","episode: 1506   score: 4.0   memory length: 299317   epsilon: 0.6053503600085675    steps: 276    lr: 4e-05     evaluation reward: 3.05\n","episode: 1507   score: 3.0   memory length: 299582   epsilon: 0.6048256600085788    steps: 265    lr: 4e-05     evaluation reward: 3.03\n","episode: 1508   score: 3.0   memory length: 299810   epsilon: 0.6043742200085886    steps: 228    lr: 4e-05     evaluation reward: 3.04\n","episode: 1509   score: 4.0   memory length: 300086   epsilon: 0.6038277400086005    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.07\n","episode: 1510   score: 3.0   memory length: 300333   epsilon: 0.6033386800086111    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.07\n","episode: 1511   score: 3.0   memory length: 300563   epsilon: 0.602883280008621    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.06\n","episode: 1512   score: 2.0   memory length: 300782   epsilon: 0.6024496600086304    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.05\n","episode: 1513   score: 2.0   memory length: 300981   epsilon: 0.602055640008639    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.07\n","episode: 1514   score: 3.0   memory length: 301229   epsilon: 0.6015646000086496    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.07\n","episode: 1515   score: 3.0   memory length: 301460   epsilon: 0.6011072200086596    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.06\n","episode: 1516   score: 5.0   memory length: 301822   epsilon: 0.6003904600086751    steps: 362    lr: 1.6000000000000003e-05     evaluation reward: 3.11\n","episode: 1517   score: 5.0   memory length: 302171   epsilon: 0.5996994400086901    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 3.12\n","episode: 1518   score: 4.0   memory length: 302449   epsilon: 0.5991490000087021    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.13\n","episode: 1519   score: 1.0   memory length: 302601   epsilon: 0.5988480400087086    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.11\n","episode: 1520   score: 1.0   memory length: 302753   epsilon: 0.5985470800087151    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.03\n","episode: 1521   score: 2.0   memory length: 302956   epsilon: 0.5981451400087239    steps: 203    lr: 1.6000000000000003e-05     evaluation reward: 3.02\n","episode: 1522   score: 3.0   memory length: 303186   epsilon: 0.5976897400087338    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.04\n","episode: 1523   score: 5.0   memory length: 303531   epsilon: 0.5970066400087486    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 3.08\n","episode: 1524   score: 6.0   memory length: 303888   epsilon: 0.5962997800087639    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.1\n","episode: 1525   score: 5.0   memory length: 304199   epsilon: 0.5956840000087773    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 3.12\n","episode: 1526   score: 5.0   memory length: 304495   epsilon: 0.59509792000879    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.13\n","episode: 1527   score: 5.0   memory length: 304791   epsilon: 0.5945118400088027    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.14\n","episode: 1528   score: 4.0   memory length: 305088   epsilon: 0.5939237800088155    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.14\n","episode: 1529   score: 5.0   memory length: 305394   epsilon: 0.5933179000088287    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.15\n","episode: 1530   score: 3.0   memory length: 305623   epsilon: 0.5928644800088385    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.18\n","episode: 1531   score: 3.0   memory length: 305850   epsilon: 0.5924150200088483    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.14\n","episode: 1532   score: 1.0   memory length: 306022   epsilon: 0.5920744600088557    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 3.11\n","episode: 1533   score: 3.0   memory length: 306270   epsilon: 0.5915834200088663    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.12\n","episode: 1534   score: 3.0   memory length: 306496   epsilon: 0.591135940008876    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.08\n","episode: 1535   score: 0.0   memory length: 306620   epsilon: 0.5908904200088814    steps: 124    lr: 1.6000000000000003e-05     evaluation reward: 3.06\n","episode: 1536   score: 3.0   memory length: 306833   epsilon: 0.5904686800088905    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.07\n","episode: 1537   score: 2.0   memory length: 307032   epsilon: 0.5900746600088991    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.05\n","episode: 1538   score: 2.0   memory length: 307233   epsilon: 0.5896766800089077    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 3.01\n","episode: 1539   score: 5.0   memory length: 307555   epsilon: 0.5890391200089216    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 3.04\n","episode: 1540   score: 1.0   memory length: 307707   epsilon: 0.5887381600089281    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.01\n","episode: 1541   score: 3.0   memory length: 307937   epsilon: 0.588282760008938    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.02\n","episode: 1542   score: 2.0   memory length: 308156   epsilon: 0.5878491400089474    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.0\n","episode: 1543   score: 2.0   memory length: 308355   epsilon: 0.5874551200089559    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.0\n","episode: 1544   score: 2.0   memory length: 308573   epsilon: 0.5870234800089653    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.02\n","episode: 1545   score: 6.0   memory length: 308938   epsilon: 0.586300780008981    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 3.07\n","episode: 1546   score: 3.0   memory length: 309166   epsilon: 0.5858493400089908    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.09\n","episode: 1547   score: 4.0   memory length: 309442   epsilon: 0.5853028600090027    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.1\n","episode: 1548   score: 3.0   memory length: 309671   epsilon: 0.5848494400090125    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.11\n","episode: 1549   score: 4.0   memory length: 309934   epsilon: 0.5843287000090238    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 3.1\n","episode: 1550   score: 8.0   memory length: 310234   epsilon: 0.5837347000090367    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 3.15\n","episode: 1551   score: 2.0   memory length: 310432   epsilon: 0.5833426600090452    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.12\n","episode: 1552   score: 5.0   memory length: 310760   epsilon: 0.5826932200090593    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 3.14\n","episode: 1553   score: 4.0   memory length: 311038   epsilon: 0.5821427800090713    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.18\n","episode: 1554   score: 2.0   memory length: 311220   epsilon: 0.5817824200090791    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n","episode: 1555   score: 3.0   memory length: 311453   epsilon: 0.5813210800090891    steps: 233    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1556   score: 5.0   memory length: 311800   epsilon: 0.580634020009104    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1557   score: 6.0   memory length: 312131   epsilon: 0.5799786400091183    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n","episode: 1558   score: 3.0   memory length: 312358   epsilon: 0.579529180009128    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n","episode: 1559   score: 3.0   memory length: 312568   epsilon: 0.579113380009137    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n","episode: 1560   score: 3.0   memory length: 312818   epsilon: 0.5786183800091478    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n","episode: 1561   score: 3.0   memory length: 313047   epsilon: 0.5781649600091576    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1562   score: 3.0   memory length: 313273   epsilon: 0.5777174800091673    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1563   score: 3.0   memory length: 313500   epsilon: 0.5772680200091771    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1564   score: 1.0   memory length: 313652   epsilon: 0.5769670600091836    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.18\n","episode: 1565   score: 6.0   memory length: 313998   epsilon: 0.5762819800091985    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1566   score: 6.0   memory length: 314348   epsilon: 0.5755889800092135    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1567   score: 1.0   memory length: 314518   epsilon: 0.5752523800092209    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n","episode: 1568   score: 3.0   memory length: 314765   epsilon: 0.5747633200092315    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.15\n","episode: 1569   score: 4.0   memory length: 315058   epsilon: 0.5741831800092441    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.16\n","episode: 1570   score: 9.0   memory length: 315574   epsilon: 0.5731615000092662    steps: 516    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n","episode: 1571   score: 2.0   memory length: 315756   epsilon: 0.5728011400092741    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n","episode: 1572   score: 3.0   memory length: 316025   epsilon: 0.5722685200092856    steps: 269    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1573   score: 4.0   memory length: 316269   epsilon: 0.5717854000092961    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1574   score: 3.0   memory length: 316498   epsilon: 0.571331980009306    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1575   score: 2.0   memory length: 316718   epsilon: 0.5708963800093154    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1576   score: 3.0   memory length: 316945   epsilon: 0.5704469200093252    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1577   score: 2.0   memory length: 317128   epsilon: 0.570084580009333    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n","episode: 1578   score: 4.0   memory length: 317404   epsilon: 0.5695381000093449    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n","episode: 1579   score: 3.0   memory length: 317633   epsilon: 0.5690846800093547    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n","episode: 1580   score: 3.0   memory length: 317861   epsilon: 0.5686332400093645    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1581   score: 3.0   memory length: 318088   epsilon: 0.5681837800093743    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n","episode: 1582   score: 3.0   memory length: 318315   epsilon: 0.5677343200093841    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1583   score: 1.0   memory length: 318467   epsilon: 0.5674333600093906    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1584   score: 2.0   memory length: 318668   epsilon: 0.5670353800093992    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1585   score: 3.0   memory length: 318895   epsilon: 0.566585920009409    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1586   score: 3.0   memory length: 319122   epsilon: 0.5661364600094188    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.18\n","episode: 1587   score: 3.0   memory length: 319370   epsilon: 0.5656454200094294    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.17\n","episode: 1588   score: 4.0   memory length: 319644   epsilon: 0.5651029000094412    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n","episode: 1589   score: 8.0   memory length: 320069   epsilon: 0.5642614000094595    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n","episode: 1590   score: 4.0   memory length: 320345   epsilon: 0.5637149200094713    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n","episode: 1591   score: 4.0   memory length: 320619   epsilon: 0.5631724000094831    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1592   score: 4.0   memory length: 320895   epsilon: 0.562625920009495    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n","episode: 1593   score: 3.0   memory length: 321106   epsilon: 0.562208140009504    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1594   score: 4.0   memory length: 321363   epsilon: 0.5616992800095151    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1595   score: 5.0   memory length: 321692   epsilon: 0.5610478600095292    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n","episode: 1596   score: 0.0   memory length: 321816   epsilon: 0.5608023400095346    steps: 124    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1597   score: 3.0   memory length: 322043   epsilon: 0.5603528800095443    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1598   score: 7.0   memory length: 322468   epsilon: 0.5595113800095626    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1599   score: 2.0   memory length: 322649   epsilon: 0.5591530000095704    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1600   score: 5.0   memory length: 322997   epsilon: 0.5584639600095853    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n","episode: 1601   score: 1.0   memory length: 323170   epsilon: 0.5581214200095928    steps: 173    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1602   score: 3.0   memory length: 323396   epsilon: 0.5576739400096025    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1603   score: 3.0   memory length: 323641   epsilon: 0.557188840009613    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1604   score: 3.0   memory length: 323889   epsilon: 0.5566978000096237    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1605   score: 4.0   memory length: 324167   epsilon: 0.5561473600096356    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1606   score: 4.0   memory length: 324443   epsilon: 0.5556008800096475    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1607   score: 2.0   memory length: 324661   epsilon: 0.5551692400096568    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1608   score: 7.0   memory length: 325083   epsilon: 0.554333680009675    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n","episode: 1609   score: 5.0   memory length: 325389   epsilon: 0.5537278000096881    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1610   score: 4.0   memory length: 325665   epsilon: 0.5531813200097    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n","episode: 1611   score: 1.0   memory length: 325817   epsilon: 0.5528803600097065    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n","episode: 1612   score: 3.0   memory length: 326064   epsilon: 0.5523913000097171    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1613   score: 1.0   memory length: 326235   epsilon: 0.5520527200097245    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n","episode: 1614   score: 4.0   memory length: 326529   epsilon: 0.5514706000097371    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1615   score: 3.0   memory length: 326758   epsilon: 0.551017180009747    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1616   score: 3.0   memory length: 326985   epsilon: 0.5505677200097567    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n","episode: 1617   score: 2.0   memory length: 327184   epsilon: 0.5501737000097653    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1618   score: 1.0   memory length: 327336   epsilon: 0.5498727400097718    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n","episode: 1619   score: 4.0   memory length: 327614   epsilon: 0.5493223000097838    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n","episode: 1620   score: 6.0   memory length: 327971   epsilon: 0.5486154400097991    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1621   score: 3.0   memory length: 328204   epsilon: 0.5481541000098091    steps: 233    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n","episode: 1622   score: 6.0   memory length: 328598   epsilon: 0.5473739800098261    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n","episode: 1623   score: 2.0   memory length: 328781   epsilon: 0.5470116400098339    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n","episode: 1624   score: 2.0   memory length: 328983   epsilon: 0.5466116800098426    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n","episode: 1625   score: 4.0   memory length: 329259   epsilon: 0.5460652000098545    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1626   score: 1.0   memory length: 329411   epsilon: 0.545764240009861    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n","episode: 1627   score: 3.0   memory length: 329637   epsilon: 0.5453167600098707    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1628   score: 3.0   memory length: 329864   epsilon: 0.5448673000098805    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n","episode: 1629   score: 3.0   memory length: 330075   epsilon: 0.5444495200098896    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n","episode: 1630   score: 1.0   memory length: 330248   epsilon: 0.544106980009897    steps: 173    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n","episode: 1631   score: 4.0   memory length: 330505   epsilon: 0.543598120009908    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 3.28\n","episode: 1632   score: 4.0   memory length: 330805   epsilon: 0.5430041200099209    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n","episode: 1633   score: 2.0   memory length: 330986   epsilon: 0.5426457400099287    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n","episode: 1634   score: 4.0   memory length: 331263   epsilon: 0.5420972800099406    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n","episode: 1635   score: 1.0   memory length: 331414   epsilon: 0.5417983000099471    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1636   score: 4.0   memory length: 331714   epsilon: 0.54120430000996    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n","episode: 1637   score: 3.0   memory length: 331941   epsilon: 0.5407548400099698    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n","episode: 1638   score: 0.0   memory length: 332065   epsilon: 0.5405093200099751    steps: 124    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1639   score: 4.0   memory length: 332360   epsilon: 0.5399252200099878    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n","episode: 1640   score: 2.0   memory length: 332542   epsilon: 0.5395648600099956    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1641   score: 3.0   memory length: 332770   epsilon: 0.5391134200100054    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1642   score: 2.0   memory length: 332969   epsilon: 0.538719400010014    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n","episode: 1643   score: 3.0   memory length: 333182   epsilon: 0.5382976600100231    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n","episode: 1644   score: 5.0   memory length: 333495   epsilon: 0.5376779200100366    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1645   score: 6.0   memory length: 333891   epsilon: 0.5368938400100536    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1646   score: 3.0   memory length: 334121   epsilon: 0.5364384400100635    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1647   score: 3.0   memory length: 334350   epsilon: 0.5359850200100733    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n","episode: 1648   score: 8.0   memory length: 334749   epsilon: 0.5351950000100905    steps: 399    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n","episode: 1649   score: 3.0   memory length: 334978   epsilon: 0.5347415800101003    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n","episode: 1650   score: 5.0   memory length: 335284   epsilon: 0.5341357000101135    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1651   score: 4.0   memory length: 335596   epsilon: 0.5335179400101269    steps: 312    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1652   score: 3.0   memory length: 335843   epsilon: 0.5330288800101375    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1653   score: 3.0   memory length: 336090   epsilon: 0.5325398200101481    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n","episode: 1654   score: 5.0   memory length: 336382   epsilon: 0.5319616600101607    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1655   score: 3.0   memory length: 336612   epsilon: 0.5315062600101705    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1656   score: 3.0   memory length: 336843   epsilon: 0.5310488800101805    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1657   score: 4.0   memory length: 337139   epsilon: 0.5304628000101932    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n","episode: 1658   score: 3.0   memory length: 337366   epsilon: 0.530013340010203    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n","episode: 1659   score: 5.0   memory length: 337675   epsilon: 0.5294015200102162    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n","episode: 1660   score: 5.0   memory length: 338025   epsilon: 0.5287085200102313    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n","episode: 1661   score: 6.0   memory length: 338364   epsilon: 0.5280373000102458    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n","episode: 1662   score: 4.0   memory length: 338643   epsilon: 0.5274848800102578    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1663   score: 6.0   memory length: 339018   epsilon: 0.526742380010274    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n","episode: 1664   score: 2.0   memory length: 339217   epsilon: 0.5263483600102825    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n","episode: 1665   score: 6.0   memory length: 339568   epsilon: 0.5256533800102976    steps: 351    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n","episode: 1666   score: 5.0   memory length: 339905   epsilon: 0.5249861200103121    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n","episode: 1667   score: 3.0   memory length: 340132   epsilon: 0.5245366600103218    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.47\n","episode: 1668   score: 3.0   memory length: 340364   epsilon: 0.5240773000103318    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.47\n","episode: 1669   score: 6.0   memory length: 340719   epsilon: 0.5233744000103471    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n","episode: 1670   score: 3.0   memory length: 340968   epsilon: 0.5228813800103578    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n","episode: 1671   score: 4.0   memory length: 341244   epsilon: 0.5223349000103696    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n","episode: 1672   score: 4.0   memory length: 341503   epsilon: 0.5218220800103808    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n","episode: 1673   score: 1.0   memory length: 341672   epsilon: 0.521487460010388    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n","episode: 1674   score: 2.0   memory length: 341852   epsilon: 0.5211310600103958    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1675   score: 1.0   memory length: 342024   epsilon: 0.5207905000104032    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n","episode: 1676   score: 3.0   memory length: 342271   epsilon: 0.5203014400104138    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n","episode: 1677   score: 3.0   memory length: 342518   epsilon: 0.5198123800104244    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n","episode: 1678   score: 5.0   memory length: 342822   epsilon: 0.5192104600104375    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n","episode: 1679   score: 4.0   memory length: 343098   epsilon: 0.5186639800104493    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n","episode: 1680   score: 4.0   memory length: 343354   epsilon: 0.5181571000104603    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n","episode: 1681   score: 6.0   memory length: 343693   epsilon: 0.5174858800104749    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 3.48\n","episode: 1682   score: 4.0   memory length: 344008   epsilon: 0.5168621800104884    steps: 315    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n","episode: 1683   score: 4.0   memory length: 344270   epsilon: 0.5163434200104997    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n","episode: 1684   score: 3.0   memory length: 344481   epsilon: 0.5159256400105088    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n","episode: 1685   score: 2.0   memory length: 344664   epsilon: 0.5155633000105166    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n","episode: 1686   score: 2.0   memory length: 344863   epsilon: 0.5151692800105252    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n","episode: 1687   score: 2.0   memory length: 345065   epsilon: 0.5147693200105339    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n","episode: 1688   score: 3.0   memory length: 345310   epsilon: 0.5142842200105444    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n","episode: 1689   score: 4.0   memory length: 345590   epsilon: 0.5137298200105564    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n","episode: 1690   score: 7.0   memory length: 345958   epsilon: 0.5130011800105723    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 3.48\n","episode: 1691   score: 6.0   memory length: 346296   epsilon: 0.5123319400105868    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n","episode: 1692   score: 6.0   memory length: 346632   epsilon: 0.5116666600106012    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n","episode: 1693   score: 4.0   memory length: 346892   epsilon: 0.5111518600106124    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n","episode: 1694   score: 4.0   memory length: 347168   epsilon: 0.5106053800106243    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n","episode: 1695   score: 3.0   memory length: 347420   epsilon: 0.5101064200106351    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n","episode: 1696   score: 3.0   memory length: 347648   epsilon: 0.5096549800106449    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n","episode: 1697   score: 5.0   memory length: 347957   epsilon: 0.5090431600106582    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n","episode: 1698   score: 3.0   memory length: 348188   epsilon: 0.5085857800106681    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n","episode: 1699   score: 4.0   memory length: 348465   epsilon: 0.50803732001068    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n","episode: 1700   score: 9.0   memory length: 348834   epsilon: 0.5073067000106959    steps: 369    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n","episode: 1701   score: 3.0   memory length: 349063   epsilon: 0.5068532800107057    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n","episode: 1702   score: 4.0   memory length: 349319   epsilon: 0.5063464000107167    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n","episode: 1703   score: 3.0   memory length: 349567   epsilon: 0.5058553600107274    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n","episode: 1704   score: 4.0   memory length: 349841   epsilon: 0.5053128400107392    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n","episode: 1705   score: 2.0   memory length: 350058   epsilon: 0.5048831800107485    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n","episode: 1706   score: 3.0   memory length: 350307   epsilon: 0.5043901600107592    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n","episode: 1707   score: 3.0   memory length: 350555   epsilon: 0.5038991200107699    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n","episode: 1708   score: 3.0   memory length: 350781   epsilon: 0.5034516400107796    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n","episode: 1709   score: 4.0   memory length: 351058   epsilon: 0.5029031800107915    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n","episode: 1710   score: 4.0   memory length: 351319   epsilon: 0.5023864000108027    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n","episode: 1711   score: 4.0   memory length: 351564   epsilon: 0.5019013000108132    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n","episode: 1712   score: 5.0   memory length: 351887   epsilon: 0.5012617600108271    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n","episode: 1713   score: 5.0   memory length: 352210   epsilon: 0.500622220010841    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n","episode: 1714   score: 2.0   memory length: 352408   epsilon: 0.5002301800108495    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n","episode: 1715   score: 4.0   memory length: 352701   epsilon: 0.4996500400108523    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n","episode: 1716   score: 3.0   memory length: 352930   epsilon: 0.4991966200108494    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n","episode: 1717   score: 5.0   memory length: 353298   epsilon: 0.4984679800108448    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n","episode: 1718   score: 5.0   memory length: 353593   epsilon: 0.4978838800108411    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n","episode: 1719   score: 2.0   memory length: 353792   epsilon: 0.4974898600108386    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n","episode: 1720   score: 3.0   memory length: 354037   epsilon: 0.49700476001083554    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n","episode: 1721   score: 4.0   memory length: 354299   epsilon: 0.49648600001083226    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n","episode: 1722   score: 2.0   memory length: 354481   epsilon: 0.49612564001083    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n","episode: 1723   score: 5.0   memory length: 354770   epsilon: 0.49555342001082636    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n","episode: 1724   score: 3.0   memory length: 355003   epsilon: 0.49509208001082344    steps: 233    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n","episode: 1725   score: 3.0   memory length: 355230   epsilon: 0.4946426200108206    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n","episode: 1726   score: 3.0   memory length: 355460   epsilon: 0.4941872200108177    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n","episode: 1727   score: 3.0   memory length: 355687   epsilon: 0.4937377600108149    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n","episode: 1728   score: 4.0   memory length: 355986   epsilon: 0.49314574001081113    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n","episode: 1729   score: 4.0   memory length: 356266   epsilon: 0.4925913400108076    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n","episode: 1730   score: 3.0   memory length: 356480   epsilon: 0.49216762001080494    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n","episode: 1731   score: 2.0   memory length: 356679   epsilon: 0.49177360001080245    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n","episode: 1732   score: 4.0   memory length: 356957   epsilon: 0.49122316001079896    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n","episode: 1733   score: 3.0   memory length: 357184   epsilon: 0.4907737000107961    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n","episode: 1734   score: 1.0   memory length: 357336   epsilon: 0.4904727400107942    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n","episode: 1735   score: 3.0   memory length: 357582   epsilon: 0.48998566001079114    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n","episode: 1736   score: 3.0   memory length: 357794   epsilon: 0.4895659000107885    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n","episode: 1737   score: 2.0   memory length: 358014   epsilon: 0.4891303000107857    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n","episode: 1738   score: 4.0   memory length: 358310   epsilon: 0.488544220010782    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n","episode: 1739   score: 8.0   memory length: 358735   epsilon: 0.4877027200107767    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1740   score: 5.0   memory length: 359062   epsilon: 0.4870552600107726    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1741   score: 3.0   memory length: 359289   epsilon: 0.48660580001076975    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1742   score: 1.0   memory length: 359441   epsilon: 0.48630484001076785    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1743   score: 2.0   memory length: 359640   epsilon: 0.48591082001076535    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n","episode: 1744   score: 7.0   memory length: 360016   epsilon: 0.48516634001076064    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1745   score: 4.0   memory length: 360310   epsilon: 0.48458422001075696    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n","episode: 1746   score: 4.0   memory length: 360589   epsilon: 0.48403180001075347    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1747   score: 3.0   memory length: 360819   epsilon: 0.4835764000107506    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1748   score: 4.0   memory length: 361075   epsilon: 0.4830695200107474    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1749   score: 4.0   memory length: 361375   epsilon: 0.4824755200107436    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n","episode: 1750   score: 9.0   memory length: 361878   epsilon: 0.4814795800107373    steps: 503    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1751   score: 9.0   memory length: 362225   epsilon: 0.48079252001073297    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1752   score: 3.0   memory length: 362456   epsilon: 0.4803351400107301    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1753   score: 4.0   memory length: 362754   epsilon: 0.47974510001072634    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n","episode: 1754   score: 7.0   memory length: 363001   epsilon: 0.47925604001072325    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1755   score: 3.0   memory length: 363249   epsilon: 0.47876500001072014    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1756   score: 5.0   memory length: 363593   epsilon: 0.47808388001071583    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n","episode: 1757   score: 3.0   memory length: 363845   epsilon: 0.4775849200107127    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n","episode: 1758   score: 3.0   memory length: 364074   epsilon: 0.4771315000107098    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n","episode: 1759   score: 6.0   memory length: 364414   epsilon: 0.47645830001070555    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n","episode: 1760   score: 3.0   memory length: 364641   epsilon: 0.4760088400107027    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1761   score: 3.0   memory length: 364888   epsilon: 0.4755197800106996    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1762   score: 4.0   memory length: 365164   epsilon: 0.47497330001069615    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1763   score: 3.0   memory length: 365392   epsilon: 0.4745218600106933    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1764   score: 4.0   memory length: 365670   epsilon: 0.4739714200106898    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1765   score: 5.0   memory length: 365976   epsilon: 0.473365540010686    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n","episode: 1766   score: 1.0   memory length: 366128   epsilon: 0.4730645800106841    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1767   score: 4.0   memory length: 366426   epsilon: 0.47247454001068034    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1768   score: 5.0   memory length: 366735   epsilon: 0.4718627200106765    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1769   score: 8.0   memory length: 367168   epsilon: 0.47100538001067105    steps: 433    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1770   score: 3.0   memory length: 367395   epsilon: 0.4705559200106682    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1771   score: 2.0   memory length: 367594   epsilon: 0.4701619000106657    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1772   score: 3.0   memory length: 367808   epsilon: 0.46973818001066303    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1773   score: 4.0   memory length: 368071   epsilon: 0.46921744001065974    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1774   score: 3.0   memory length: 368297   epsilon: 0.4687699600106569    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1775   score: 3.0   memory length: 368545   epsilon: 0.4682789200106538    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n","episode: 1776   score: 2.0   memory length: 368727   epsilon: 0.4679185600106515    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n","episode: 1777   score: 4.0   memory length: 368988   epsilon: 0.46740178001064825    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n","episode: 1778   score: 5.0   memory length: 369314   epsilon: 0.46675630001064417    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n","episode: 1779   score: 3.0   memory length: 369542   epsilon: 0.4663048600106413    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n","episode: 1780   score: 3.0   memory length: 369756   epsilon: 0.46588114001063863    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1781   score: 3.0   memory length: 369985   epsilon: 0.46542772001063576    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1782   score: 3.0   memory length: 370197   epsilon: 0.4650079600106331    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1783   score: 4.0   memory length: 370477   epsilon: 0.4644535600106296    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1784   score: 6.0   memory length: 370830   epsilon: 0.4637546200106252    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1785   score: 2.0   memory length: 371029   epsilon: 0.4633606000106227    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1786   score: 3.0   memory length: 371256   epsilon: 0.46291114001061984    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1787   score: 5.0   memory length: 371578   epsilon: 0.4622735800106158    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1788   score: 4.0   memory length: 371854   epsilon: 0.46172710001061235    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n","episode: 1789   score: 3.0   memory length: 372081   epsilon: 0.4612776400106095    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1790   score: 2.0   memory length: 372264   epsilon: 0.4609153000106072    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n","episode: 1791   score: 4.0   memory length: 372558   epsilon: 0.4603331800106035    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1792   score: 2.0   memory length: 372779   epsilon: 0.45989560001060076    steps: 221    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1793   score: 4.0   memory length: 373054   epsilon: 0.4593511000105973    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1794   score: 6.0   memory length: 373407   epsilon: 0.4586521600105929    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1795   score: 3.0   memory length: 373680   epsilon: 0.45811162001058947    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1796   score: 5.0   memory length: 373967   epsilon: 0.4575433600105859    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1797   score: 3.0   memory length: 374220   epsilon: 0.4570424200105827    steps: 253    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1798   score: 3.0   memory length: 374431   epsilon: 0.45662464001058006    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1799   score: 4.0   memory length: 374672   epsilon: 0.45614746001057704    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1800   score: 5.0   memory length: 374977   epsilon: 0.4555435600105732    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1801   score: 3.0   memory length: 375225   epsilon: 0.4550525200105701    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1802   score: 4.0   memory length: 375519   epsilon: 0.45447040001056643    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1803   score: 4.0   memory length: 375775   epsilon: 0.4539635200105632    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n","episode: 1804   score: 5.0   memory length: 376080   epsilon: 0.4533596200105594    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1805   score: 4.0   memory length: 376339   epsilon: 0.45284680001055616    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1806   score: 3.0   memory length: 376586   epsilon: 0.45235774001055307    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1807   score: 3.0   memory length: 376813   epsilon: 0.4519082800105502    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1808   score: 3.0   memory length: 377043   epsilon: 0.45145288001054734    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1809   score: 3.0   memory length: 377270   epsilon: 0.4510034200105445    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n","episode: 1810   score: 3.0   memory length: 377481   epsilon: 0.45058564001054185    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1811   score: 5.0   memory length: 377809   epsilon: 0.44993620001053775    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n","episode: 1812   score: 3.0   memory length: 378036   epsilon: 0.4494867400105349    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n","episode: 1813   score: 3.0   memory length: 378248   epsilon: 0.44906698001053225    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n","episode: 1814   score: 3.0   memory length: 378478   epsilon: 0.44861158001052936    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1815   score: 5.0   memory length: 378803   epsilon: 0.4479680800105253    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n","episode: 1816   score: 3.0   memory length: 379048   epsilon: 0.4474829800105222    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n","episode: 1817   score: 3.0   memory length: 379275   epsilon: 0.4470335200105194    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n","episode: 1818   score: 3.0   memory length: 379505   epsilon: 0.4465781200105165    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n","episode: 1819   score: 5.0   memory length: 379830   epsilon: 0.44593462001051243    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1820   score: 4.0   memory length: 380090   epsilon: 0.44541982001050917    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n","episode: 1821   score: 7.0   memory length: 380514   epsilon: 0.44458030001050386    steps: 424    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1822   score: 4.0   memory length: 380792   epsilon: 0.4440298600105004    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1823   score: 5.0   memory length: 381098   epsilon: 0.44342398001049654    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1824   score: 4.0   memory length: 381355   epsilon: 0.4429151200104933    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1825   score: 4.0   memory length: 381615   epsilon: 0.44240032001049007    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n","episode: 1826   score: 1.0   memory length: 381767   epsilon: 0.44209936001048816    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n","episode: 1827   score: 2.0   memory length: 381950   epsilon: 0.44173702001048587    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1828   score: 7.0   memory length: 382357   epsilon: 0.44093116001048077    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n","episode: 1829   score: 3.0   memory length: 382586   epsilon: 0.4404777400104779    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1830   score: 3.0   memory length: 382817   epsilon: 0.440020360010475    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n","episode: 1831   score: 4.0   memory length: 383111   epsilon: 0.4394382400104713    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n","episode: 1832   score: 3.0   memory length: 383325   epsilon: 0.43901452001046865    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n","episode: 1833   score: 7.0   memory length: 383736   epsilon: 0.4382007400104635    steps: 411    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n","episode: 1834   score: 4.0   memory length: 384034   epsilon: 0.43761070001045976    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n","episode: 1835   score: 4.0   memory length: 384293   epsilon: 0.4370978800104565    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n","episode: 1836   score: 3.0   memory length: 384526   epsilon: 0.4366365400104536    steps: 233    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n","episode: 1837   score: 4.0   memory length: 384822   epsilon: 0.4360504600104499    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n","episode: 1838   score: 3.0   memory length: 385050   epsilon: 0.43559902001044704    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n","episode: 1839   score: 3.0   memory length: 385298   epsilon: 0.43510798001044393    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n","episode: 1840   score: 7.0   memory length: 385693   epsilon: 0.434325880010439    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n","episode: 1841   score: 6.0   memory length: 386061   epsilon: 0.43359724001043437    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n","episode: 1842   score: 2.0   memory length: 386244   epsilon: 0.4332349000104321    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n","episode: 1843   score: 5.0   memory length: 386550   epsilon: 0.43262902001042824    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n","episode: 1844   score: 10.0   memory length: 386938   epsilon: 0.4318607800104234    steps: 388    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n","episode: 1845   score: 5.0   memory length: 387242   epsilon: 0.4312588600104196    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n","episode: 1846   score: 6.0   memory length: 387579   epsilon: 0.43059160001041535    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n","episode: 1847   score: 3.0   memory length: 387809   epsilon: 0.4301362000104125    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n","episode: 1848   score: 6.0   memory length: 388144   epsilon: 0.4294729000104083    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n","episode: 1849   score: 4.0   memory length: 388420   epsilon: 0.4289264200104048    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n","episode: 1850   score: 5.0   memory length: 388768   epsilon: 0.42823738001040046    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n","episode: 1851   score: 3.0   memory length: 388982   epsilon: 0.4278136600103978    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n","episode: 1852   score: 6.0   memory length: 389317   epsilon: 0.4271503600103936    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n","episode: 1853   score: 3.0   memory length: 389546   epsilon: 0.4266969400103907    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n","episode: 1854   score: 3.0   memory length: 389794   epsilon: 0.4262059000103876    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n","episode: 1855   score: 5.0   memory length: 390120   epsilon: 0.4255604200103835    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n","episode: 1856   score: 5.0   memory length: 390462   epsilon: 0.42488326001037924    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n","episode: 1857   score: 5.0   memory length: 390767   epsilon: 0.4242793600103754    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n","episode: 1858   score: 7.0   memory length: 391189   epsilon: 0.42344380001037013    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n","episode: 1859   score: 4.0   memory length: 391448   epsilon: 0.4229309800103669    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n","episode: 1860   score: 3.0   memory length: 391693   epsilon: 0.4224458800103638    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n","episode: 1861   score: 3.0   memory length: 391927   epsilon: 0.4219825600103609    steps: 234    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n","episode: 1862   score: 1.0   memory length: 392078   epsilon: 0.421683580010359    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n","episode: 1863   score: 4.0   memory length: 392395   epsilon: 0.421055920010355    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n","episode: 1864   score: 3.0   memory length: 392640   epsilon: 0.42057082001035195    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n","episode: 1865   score: 4.0   memory length: 392935   epsilon: 0.41998672001034826    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n","episode: 1866   score: 3.0   memory length: 393164   epsilon: 0.4195333000103454    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n","episode: 1867   score: 2.0   memory length: 393363   epsilon: 0.4191392800103429    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n","episode: 1868   score: 9.0   memory length: 393690   epsilon: 0.4184918200103388    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n","episode: 1869   score: 5.0   memory length: 394018   epsilon: 0.4178423800103347    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n","episode: 1870   score: 3.0   memory length: 394265   epsilon: 0.4173533200103316    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n","episode: 1871   score: 8.0   memory length: 394679   epsilon: 0.4165336000103264    steps: 414    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n","episode: 1872   score: 6.0   memory length: 395018   epsilon: 0.41586238001032216    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n","episode: 1873   score: 5.0   memory length: 395345   epsilon: 0.41521492001031807    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n","episode: 1874   score: 2.0   memory length: 395544   epsilon: 0.4148209000103156    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n","episode: 1875   score: 3.0   memory length: 395758   epsilon: 0.4143971800103129    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n","episode: 1876   score: 7.0   memory length: 396148   epsilon: 0.413624980010308    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n","episode: 1877   score: 5.0   memory length: 396477   epsilon: 0.4129735600103039    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n","episode: 1878   score: 3.0   memory length: 396704   epsilon: 0.41252410001030104    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n","episode: 1879   score: 5.0   memory length: 397033   epsilon: 0.4118726800102969    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n","episode: 1880   score: 7.0   memory length: 397438   epsilon: 0.41107078001029185    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n","episode: 1881   score: 4.0   memory length: 397696   epsilon: 0.4105599400102886    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n","episode: 1882   score: 5.0   memory length: 398005   epsilon: 0.40994812001028474    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n","episode: 1883   score: 5.0   memory length: 398334   epsilon: 0.4092967000102806    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n","episode: 1884   score: 2.0   memory length: 398517   epsilon: 0.40893436001027833    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n","episode: 1885   score: 6.0   memory length: 398856   epsilon: 0.4082631400102741    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n","episode: 1886   score: 5.0   memory length: 399185   epsilon: 0.40761172001026996    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n","episode: 1887   score: 4.0   memory length: 399462   epsilon: 0.4070632600102665    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n","episode: 1888   score: 4.0   memory length: 399721   epsilon: 0.40655044001026325    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n","episode: 1889   score: 7.0   memory length: 400105   epsilon: 0.40579012001025844    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 4.21\n","episode: 1890   score: 9.0   memory length: 400608   epsilon: 0.40479418001025214    steps: 503    lr: 6.400000000000001e-06     evaluation reward: 4.28\n","episode: 1891   score: 3.0   memory length: 400839   epsilon: 0.40433680001024924    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.27\n","episode: 1892   score: 4.0   memory length: 401116   epsilon: 0.40378834001024577    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.29\n","episode: 1893   score: 2.0   memory length: 401314   epsilon: 0.4033963000102433    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 4.27\n","episode: 1894   score: 6.0   memory length: 401692   epsilon: 0.40264786001023856    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 4.27\n","episode: 1895   score: 5.0   memory length: 402017   epsilon: 0.4020043600102345    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.29\n","episode: 1896   score: 3.0   memory length: 402244   epsilon: 0.40155490001023164    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.27\n","episode: 1897   score: 12.0   memory length: 402703   epsilon: 0.4006460800102259    steps: 459    lr: 6.400000000000001e-06     evaluation reward: 4.36\n","episode: 1898   score: 6.0   memory length: 403022   epsilon: 0.4000144600102219    steps: 319    lr: 6.400000000000001e-06     evaluation reward: 4.39\n","episode: 1899   score: 4.0   memory length: 403296   epsilon: 0.39947194001021846    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.39\n","episode: 1900   score: 4.0   memory length: 403572   epsilon: 0.398925460010215    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.38\n","episode: 1901   score: 5.0   memory length: 403846   epsilon: 0.3983829400102116    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.4\n","episode: 1902   score: 5.0   memory length: 404191   epsilon: 0.39769984001020725    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 4.41\n","episode: 1903   score: 3.0   memory length: 404441   epsilon: 0.3972048400102041    steps: 250    lr: 6.400000000000001e-06     evaluation reward: 4.4\n","episode: 1904   score: 4.0   memory length: 404701   epsilon: 0.39669004001020086    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.39\n","episode: 1905   score: 3.0   memory length: 404932   epsilon: 0.39623266001019797    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.38\n","episode: 1906   score: 2.0   memory length: 405134   epsilon: 0.39583270001019544    steps: 202    lr: 6.400000000000001e-06     evaluation reward: 4.37\n","episode: 1907   score: 2.0   memory length: 405333   epsilon: 0.39543868001019294    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 4.36\n","episode: 1908   score: 5.0   memory length: 405658   epsilon: 0.3947951800101889    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.38\n","episode: 1909   score: 4.0   memory length: 405920   epsilon: 0.3942764200101856    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 4.39\n","episode: 1910   score: 6.0   memory length: 406274   epsilon: 0.39357550001018116    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 4.42\n","episode: 1911   score: 3.0   memory length: 406486   epsilon: 0.3931557400101785    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.4\n","episode: 1912   score: 8.0   memory length: 406932   epsilon: 0.3922726600101729    steps: 446    lr: 6.400000000000001e-06     evaluation reward: 4.45\n","episode: 1913   score: 4.0   memory length: 407192   epsilon: 0.39175786001016966    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.46\n","episode: 1914   score: 5.0   memory length: 407497   epsilon: 0.39115396001016584    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.48\n","episode: 1915   score: 6.0   memory length: 407830   epsilon: 0.39049462001016166    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 4.49\n","episode: 1916   score: 7.0   memory length: 408195   epsilon: 0.3897719200101571    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 1917   score: 4.0   memory length: 408472   epsilon: 0.3892234600101536    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 1918   score: 3.0   memory length: 408699   epsilon: 0.3887740000101508    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 1919   score: 5.0   memory length: 409026   epsilon: 0.3881265400101467    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 1920   score: 4.0   memory length: 409322   epsilon: 0.387540460010143    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 1921   score: 7.0   memory length: 409706   epsilon: 0.38678014001013816    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 1922   score: 3.0   memory length: 409935   epsilon: 0.3863267200101353    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 1923   score: 3.0   memory length: 410164   epsilon: 0.3858733000101324    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.51\n","episode: 1924   score: 2.0   memory length: 410345   epsilon: 0.38551492001013016    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.49\n","episode: 1925   score: 7.0   memory length: 410730   epsilon: 0.38475262001012533    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 4.52\n","episode: 1926   score: 5.0   memory length: 411004   epsilon: 0.3842101000101219    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 1927   score: 3.0   memory length: 411234   epsilon: 0.383754700010119    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1928   score: 3.0   memory length: 411462   epsilon: 0.38330326001011616    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 1929   score: 3.0   memory length: 411709   epsilon: 0.38281420001011307    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 1930   score: 5.0   memory length: 412036   epsilon: 0.382166740010109    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1931   score: 6.0   memory length: 412372   epsilon: 0.38150146001010476    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1932   score: 4.0   memory length: 412650   epsilon: 0.3809510200101013    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.58\n","episode: 1933   score: 5.0   memory length: 412994   epsilon: 0.380269900010097    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 1934   score: 5.0   memory length: 413280   epsilon: 0.3797036200100934    steps: 286    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1935   score: 3.0   memory length: 413511   epsilon: 0.3792462400100905    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 1936   score: 10.0   memory length: 414010   epsilon: 0.37825822001008425    steps: 499    lr: 6.400000000000001e-06     evaluation reward: 4.63\n","episode: 1937   score: 4.0   memory length: 414286   epsilon: 0.3777117400100808    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.63\n","episode: 1938   score: 2.0   memory length: 414485   epsilon: 0.3773177200100783    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 1939   score: 4.0   memory length: 414728   epsilon: 0.37683658001007525    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 4.63\n","episode: 1940   score: 6.0   memory length: 415086   epsilon: 0.37612774001007077    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 1941   score: 3.0   memory length: 415317   epsilon: 0.37567036001006787    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.59\n","episode: 1942   score: 3.0   memory length: 415549   epsilon: 0.37521100001006497    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1943   score: 2.0   memory length: 415750   epsilon: 0.37481302001006245    steps: 201    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1944   score: 3.0   memory length: 415982   epsilon: 0.37435366001005954    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.5\n","episode: 1945   score: 10.0   memory length: 416468   epsilon: 0.37339138001005345    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1946   score: 3.0   memory length: 416699   epsilon: 0.37293400001005056    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.52\n","episode: 1947   score: 6.0   memory length: 417021   epsilon: 0.3722964400100465    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1948   score: 3.0   memory length: 417232   epsilon: 0.3718786600100439    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 4.52\n","episode: 1949   score: 4.0   memory length: 417508   epsilon: 0.3713321800100404    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.52\n","episode: 1950   score: 3.0   memory length: 417737   epsilon: 0.37087876001003756    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.5\n","episode: 1951   score: 4.0   memory length: 418011   epsilon: 0.3703362400100341    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.51\n","episode: 1952   score: 6.0   memory length: 418385   epsilon: 0.36959572001002944    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 4.51\n","episode: 1953   score: 12.0   memory length: 418858   epsilon: 0.3686591800100235    steps: 473    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1954   score: 3.0   memory length: 419086   epsilon: 0.36820774001002066    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1955   score: 6.0   memory length: 419406   epsilon: 0.36757414001001665    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 4.61\n","episode: 1956   score: 3.0   memory length: 419637   epsilon: 0.36711676001001375    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.59\n","episode: 1957   score: 3.0   memory length: 419864   epsilon: 0.3666673000100109    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1958   score: 5.0   memory length: 420189   epsilon: 0.36602380001000684    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1959   score: 3.0   memory length: 420416   epsilon: 0.365574340010004    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 1960   score: 4.0   memory length: 420712   epsilon: 0.3649882600100003    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1961   score: 5.0   memory length: 421039   epsilon: 0.3643408000099962    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1962   score: 6.0   memory length: 421413   epsilon: 0.3636002800099915    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 1963   score: 6.0   memory length: 421772   epsilon: 0.362889460009987    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.64\n","episode: 1964   score: 3.0   memory length: 421999   epsilon: 0.36244000000998416    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.64\n","episode: 1965   score: 2.0   memory length: 422198   epsilon: 0.36204598000998167    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 1966   score: 5.0   memory length: 422486   epsilon: 0.36147574000997806    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 4.64\n","episode: 1967   score: 5.0   memory length: 422790   epsilon: 0.36087382000997426    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.67\n","episode: 1968   score: 4.0   memory length: 423050   epsilon: 0.360359020009971    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 1969   score: 3.0   memory length: 423262   epsilon: 0.35993926000996834    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1970   score: 7.0   memory length: 423656   epsilon: 0.3591591400099634    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 4.64\n","episode: 1971   score: 4.0   memory length: 423929   epsilon: 0.35861860000996    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1972   score: 4.0   memory length: 424206   epsilon: 0.3580701400099565    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.58\n","episode: 1973   score: 7.0   memory length: 424647   epsilon: 0.357196960009951    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1974   score: 4.0   memory length: 424905   epsilon: 0.35668612000994776    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 1975   score: 2.0   memory length: 425088   epsilon: 0.35632378000994547    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.61\n","episode: 1976   score: 7.0   memory length: 425476   epsilon: 0.3555555400099406    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 4.61\n","episode: 1977   score: 4.0   memory length: 425739   epsilon: 0.3550348000099373    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1978   score: 3.0   memory length: 425986   epsilon: 0.3545457400099342    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1979   score: 5.0   memory length: 426336   epsilon: 0.35385274000992983    steps: 350    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 1980   score: 4.0   memory length: 426579   epsilon: 0.3533716000099268    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1981   score: 5.0   memory length: 426928   epsilon: 0.3526805800099224    steps: 349    lr: 6.400000000000001e-06     evaluation reward: 4.58\n","episode: 1982   score: 4.0   memory length: 427191   epsilon: 0.3521598400099191    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1983   score: 3.0   memory length: 427439   epsilon: 0.351668800009916    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1984   score: 4.0   memory length: 427716   epsilon: 0.35112034000991255    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 1985   score: 4.0   memory length: 427995   epsilon: 0.35056792000990905    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 1986   score: 3.0   memory length: 428207   epsilon: 0.3501481600099064    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 1987   score: 2.0   memory length: 428405   epsilon: 0.3497561200099039    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 4.51\n","episode: 1988   score: 6.0   memory length: 428783   epsilon: 0.3490076800098992    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 1989   score: 6.0   memory length: 429159   epsilon: 0.34826320000989447    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.52\n","episode: 1990   score: 4.0   memory length: 429405   epsilon: 0.3477761200098914    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 4.47\n","episode: 1991   score: 3.0   memory length: 429637   epsilon: 0.3473167600098885    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.47\n","episode: 1992   score: 5.0   memory length: 429929   epsilon: 0.3467386000098848    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 4.48\n","episode: 1993   score: 3.0   memory length: 430143   epsilon: 0.34631488000988214    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 4.49\n","episode: 1994   score: 7.0   memory length: 430569   epsilon: 0.3454714000098768    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 4.5\n","episode: 1995   score: 4.0   memory length: 430827   epsilon: 0.3449605600098736    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.49\n","episode: 1996   score: 4.0   memory length: 431121   epsilon: 0.3443784400098699    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 4.5\n","episode: 1997   score: 4.0   memory length: 431401   epsilon: 0.3438240400098664    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 4.42\n","episode: 1998   score: 7.0   memory length: 431793   epsilon: 0.34304788000986147    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 4.43\n","episode: 1999   score: 7.0   memory length: 432219   epsilon: 0.34220440000985614    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 4.46\n","episode: 2000   score: 3.0   memory length: 432450   epsilon: 0.34174702000985324    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.45\n","episode: 2001   score: 6.0   memory length: 432810   epsilon: 0.34103422000984873    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 4.46\n","episode: 2002   score: 6.0   memory length: 433130   epsilon: 0.3404006200098447    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 4.47\n","episode: 2003   score: 4.0   memory length: 433388   epsilon: 0.3398897800098415    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.48\n","episode: 2004   score: 4.0   memory length: 433649   epsilon: 0.3393730000098382    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.48\n","episode: 2005   score: 4.0   memory length: 433925   epsilon: 0.33882652000983476    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.49\n","episode: 2006   score: 5.0   memory length: 434236   epsilon: 0.33821074000983087    steps: 311    lr: 6.400000000000001e-06     evaluation reward: 4.52\n","episode: 2007   score: 6.0   memory length: 434571   epsilon: 0.33754744000982667    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 2008   score: 9.0   memory length: 435049   epsilon: 0.3366010000098207    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 2009   score: 5.0   memory length: 435374   epsilon: 0.3359575000098166    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.61\n","episode: 2010   score: 3.0   memory length: 435585   epsilon: 0.33553972000981397    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 4.58\n","episode: 2011   score: 5.0   memory length: 435914   epsilon: 0.33488830000980985    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 4.6\n","episode: 2012   score: 6.0   memory length: 436264   epsilon: 0.33419530000980546    steps: 350    lr: 6.400000000000001e-06     evaluation reward: 4.58\n","episode: 2013   score: 9.0   memory length: 436742   epsilon: 0.3332488600097995    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 4.63\n","episode: 2014   score: 3.0   memory length: 436990   epsilon: 0.33275782000979637    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.61\n","episode: 2015   score: 2.0   memory length: 437173   epsilon: 0.3323954800097941    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.57\n","episode: 2016   score: 4.0   memory length: 437449   epsilon: 0.3318490000097906    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 2017   score: 3.0   memory length: 437677   epsilon: 0.33139756000978776    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.53\n","episode: 2018   score: 6.0   memory length: 438025   epsilon: 0.3307085200097834    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 2019   score: 4.0   memory length: 438322   epsilon: 0.3301204600097797    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 2020   score: 4.0   memory length: 438599   epsilon: 0.3295720000097762    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 2021   score: 6.0   memory length: 438923   epsilon: 0.32893048000977215    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.54\n","episode: 2022   score: 5.0   memory length: 439249   epsilon: 0.32828500000976807    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 2023   score: 2.0   memory length: 439434   epsilon: 0.32791870000976575    steps: 185    lr: 6.400000000000001e-06     evaluation reward: 4.55\n","episode: 2024   score: 6.0   memory length: 439790   epsilon: 0.3272138200097613    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 4.59\n","episode: 2025   score: 4.0   memory length: 440089   epsilon: 0.32662180000975755    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.56\n","episode: 2026   score: 11.0   memory length: 440546   epsilon: 0.3257169400097518    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 2027   score: 6.0   memory length: 440942   epsilon: 0.32493286000974686    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 4.65\n","episode: 2028   score: 6.0   memory length: 441315   epsilon: 0.3241943200097422    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.68\n","episode: 2029   score: 4.0   memory length: 441614   epsilon: 0.32360230000973844    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.69\n","episode: 2030   score: 6.0   memory length: 441992   epsilon: 0.3228538600097337    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 4.7\n","episode: 2031   score: 3.0   memory length: 442221   epsilon: 0.32240044000973084    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.67\n","episode: 2032   score: 6.0   memory length: 442557   epsilon: 0.32173516000972663    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.69\n","episode: 2033   score: 3.0   memory length: 442805   epsilon: 0.3212441200097235    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.67\n","episode: 2034   score: 3.0   memory length: 443054   epsilon: 0.3207511000097204    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 4.65\n","episode: 2035   score: 2.0   memory length: 443237   epsilon: 0.3203887600097181    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.64\n","episode: 2036   score: 8.0   memory length: 443715   epsilon: 0.3194423200097121    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 4.62\n","episode: 2037   score: 8.0   memory length: 444189   epsilon: 0.3185038000097062    steps: 474    lr: 6.400000000000001e-06     evaluation reward: 4.66\n","episode: 2038   score: 7.0   memory length: 444592   epsilon: 0.31770586000970114    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 4.71\n","episode: 2039   score: 9.0   memory length: 445049   epsilon: 0.3168010000096954    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2040   score: 3.0   memory length: 445277   epsilon: 0.31634956000969255    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.73\n","episode: 2041   score: 6.0   memory length: 445639   epsilon: 0.315632800009688    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2042   score: 3.0   memory length: 445870   epsilon: 0.3151754200096851    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2043   score: 11.0   memory length: 446309   epsilon: 0.3143062000096796    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 4.85\n","episode: 2044   score: 5.0   memory length: 446619   epsilon: 0.31369240000967574    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.87\n","episode: 2045   score: 4.0   memory length: 446897   epsilon: 0.31314196000967226    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.81\n","episode: 2046   score: 5.0   memory length: 447206   epsilon: 0.3125301400096684    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.83\n","episode: 2047   score: 5.0   memory length: 447576   epsilon: 0.31179754000966375    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2048   score: 3.0   memory length: 447806   epsilon: 0.3113421400096609    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2049   score: 3.0   memory length: 448033   epsilon: 0.31089268000965803    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.81\n","episode: 2050   score: 4.0   memory length: 448328   epsilon: 0.31030858000965433    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2051   score: 4.0   memory length: 448589   epsilon: 0.30979180000965106    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2052   score: 6.0   memory length: 448958   epsilon: 0.30906118000964644    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2053   score: 2.0   memory length: 449141   epsilon: 0.30869884000964415    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.72\n","episode: 2054   score: 2.0   memory length: 449342   epsilon: 0.30830086000964163    steps: 201    lr: 6.400000000000001e-06     evaluation reward: 4.71\n","episode: 2055   score: 8.0   memory length: 449676   epsilon: 0.30763954000963745    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 4.73\n","episode: 2056   score: 3.0   memory length: 449903   epsilon: 0.3071900800096346    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.73\n","episode: 2057   score: 6.0   memory length: 450261   epsilon: 0.3064812400096301    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2058   score: 7.0   memory length: 450645   epsilon: 0.3057209200096253    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 4.78\n","episode: 2059   score: 3.0   memory length: 450876   epsilon: 0.3052635400096224    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.78\n","episode: 2060   score: 5.0   memory length: 451202   epsilon: 0.30461806000961833    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.79\n","episode: 2061   score: 3.0   memory length: 451414   epsilon: 0.3041983000096157    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.77\n","episode: 2062   score: 6.0   memory length: 451753   epsilon: 0.3035270800096114    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.77\n","episode: 2063   score: 6.0   memory length: 452091   epsilon: 0.3028578400096072    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 4.77\n","episode: 2064   score: 7.0   memory length: 452552   epsilon: 0.3019450600096014    steps: 461    lr: 6.400000000000001e-06     evaluation reward: 4.81\n","episode: 2065   score: 7.0   memory length: 452966   epsilon: 0.30112534000959623    steps: 414    lr: 6.400000000000001e-06     evaluation reward: 4.86\n","episode: 2066   score: 3.0   memory length: 453195   epsilon: 0.30067192000959336    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.84\n","episode: 2067   score: 5.0   memory length: 453504   epsilon: 0.3000601000095895    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.84\n","episode: 2068   score: 8.0   memory length: 453946   epsilon: 0.29918494000958396    steps: 442    lr: 6.400000000000001e-06     evaluation reward: 4.88\n","episode: 2069   score: 6.0   memory length: 454264   epsilon: 0.29855530000957997    steps: 318    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2070   score: 5.0   memory length: 454553   epsilon: 0.29798308000957635    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.89\n","episode: 2071   score: 3.0   memory length: 454767   epsilon: 0.29755936000957367    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 4.88\n","episode: 2072   score: 4.0   memory length: 455025   epsilon: 0.29704852000957044    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.88\n","episode: 2073   score: 3.0   memory length: 455237   epsilon: 0.2966287600095678    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.84\n","episode: 2074   score: 7.0   memory length: 455594   epsilon: 0.2959219000095633    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.87\n","episode: 2075   score: 6.0   memory length: 455938   epsilon: 0.295240780009559    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2076   score: 5.0   memory length: 456237   epsilon: 0.29464876000955526    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.89\n","episode: 2077   score: 6.0   memory length: 456610   epsilon: 0.2939102200095506    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2078   score: 6.0   memory length: 456988   epsilon: 0.29316178000954585    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2079   score: 5.0   memory length: 457280   epsilon: 0.2925836200095422    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2080   score: 3.0   memory length: 457526   epsilon: 0.2920965400095391    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2081   score: 5.0   memory length: 457841   epsilon: 0.29147284000953516    steps: 315    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2082   score: 3.0   memory length: 458092   epsilon: 0.290975860009532    steps: 251    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2083   score: 8.0   memory length: 458527   epsilon: 0.29011456000952657    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2084   score: 4.0   memory length: 458786   epsilon: 0.2896017400095233    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2085   score: 7.0   memory length: 459151   epsilon: 0.28887904000951875    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 5.0\n","episode: 2086   score: 2.0   memory length: 459370   epsilon: 0.288445420009516    steps: 219    lr: 6.400000000000001e-06     evaluation reward: 4.99\n","episode: 2087   score: 5.0   memory length: 459698   epsilon: 0.2877959800095119    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 5.02\n","episode: 2088   score: 4.0   memory length: 459993   epsilon: 0.2872118800095082    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 5.0\n","episode: 2089   score: 7.0   memory length: 460420   epsilon: 0.28636642000950285    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2090   score: 9.0   memory length: 460894   epsilon: 0.2854279000094969    steps: 474    lr: 6.400000000000001e-06     evaluation reward: 5.06\n","episode: 2091   score: 7.0   memory length: 461277   epsilon: 0.2846695600094921    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 5.1\n","episode: 2092   score: 4.0   memory length: 461536   epsilon: 0.2841567400094889    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.09\n","episode: 2093   score: 2.0   memory length: 461719   epsilon: 0.2837944000094866    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 5.08\n","episode: 2094   score: 3.0   memory length: 461933   epsilon: 0.2833706800094839    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 5.04\n","episode: 2095   score: 4.0   memory length: 462208   epsilon: 0.28282618000948045    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 5.04\n","episode: 2096   score: 5.0   memory length: 462495   epsilon: 0.28225792000947686    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 5.05\n","episode: 2097   score: 7.0   memory length: 462903   epsilon: 0.28145008000947175    steps: 408    lr: 6.400000000000001e-06     evaluation reward: 5.08\n","episode: 2098   score: 5.0   memory length: 463228   epsilon: 0.2808065800094677    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 5.06\n","episode: 2099   score: 4.0   memory length: 463506   epsilon: 0.2802561400094642    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.03\n","episode: 2100   score: 3.0   memory length: 463751   epsilon: 0.2797710400094611    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.03\n","episode: 2101   score: 5.0   memory length: 464099   epsilon: 0.27908200000945677    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 5.02\n","episode: 2102   score: 2.0   memory length: 464282   epsilon: 0.2787196600094545    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.98\n","episode: 2103   score: 7.0   memory length: 464703   epsilon: 0.2778860800094492    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2104   score: 4.0   memory length: 464966   epsilon: 0.2773653400094459    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2105   score: 4.0   memory length: 465245   epsilon: 0.2768129200094424    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2106   score: 5.0   memory length: 465586   epsilon: 0.27613774000943814    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2107   score: 2.0   memory length: 465785   epsilon: 0.27574372000943564    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2108   score: 5.0   memory length: 466092   epsilon: 0.2751358600094318    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2109   score: 2.0   memory length: 466274   epsilon: 0.2747755000094295    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.9\n","episode: 2110   score: 7.0   memory length: 466680   epsilon: 0.27397162000942443    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2111   score: 6.0   memory length: 467018   epsilon: 0.2733023800094202    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2112   score: 4.0   memory length: 467294   epsilon: 0.27275590000941674    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2113   score: 8.0   memory length: 467745   epsilon: 0.2718629200094111    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2114   score: 3.0   memory length: 467977   epsilon: 0.2714035600094082    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2115   score: 4.0   memory length: 468238   epsilon: 0.2708867800094049    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2116   score: 5.0   memory length: 468544   epsilon: 0.2702809000094011    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2117   score: 3.0   memory length: 468771   epsilon: 0.26983144000939824    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2118   score: 2.0   memory length: 468954   epsilon: 0.26946910000939595    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2119   score: 5.0   memory length: 469249   epsilon: 0.26888500000939225    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2120   score: 8.0   memory length: 469700   epsilon: 0.2679920200093866    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2121   score: 5.0   memory length: 470023   epsilon: 0.26735248000938255    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2122   score: 5.0   memory length: 470350   epsilon: 0.26670502000937846    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2123   score: 7.0   memory length: 470714   epsilon: 0.2659843000093739    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 5.0\n","episode: 2124   score: 3.0   memory length: 470926   epsilon: 0.26556454000937124    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2125   score: 7.0   memory length: 471349   epsilon: 0.26472700000936594    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 5.0\n","episode: 2126   score: 4.0   memory length: 471626   epsilon: 0.2641785400093625    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2127   score: 6.0   memory length: 471947   epsilon: 0.26354296000935845    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2128   score: 8.0   memory length: 472417   epsilon: 0.26261236000935256    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2129   score: 6.0   memory length: 472751   epsilon: 0.2619510400093484    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2130   score: 4.0   memory length: 473007   epsilon: 0.2614441600093452    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2131   score: 4.0   memory length: 473268   epsilon: 0.2609273800093419    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2132   score: 6.0   memory length: 473643   epsilon: 0.2601848800093372    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2133   score: 4.0   memory length: 473939   epsilon: 0.2595988000093335    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2134   score: 4.0   memory length: 474199   epsilon: 0.25908400000933024    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.98\n","episode: 2135   score: 7.0   memory length: 474574   epsilon: 0.25834150000932554    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.03\n","episode: 2136   score: 3.0   memory length: 474804   epsilon: 0.25788610000932266    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.98\n","episode: 2137   score: 7.0   memory length: 475213   epsilon: 0.25707628000931754    steps: 409    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2138   score: 5.0   memory length: 475538   epsilon: 0.25643278000931347    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2139   score: 3.0   memory length: 475767   epsilon: 0.2559793600093106    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.89\n","episode: 2140   score: 6.0   memory length: 476127   epsilon: 0.2552665600093061    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2141   score: 6.0   memory length: 476484   epsilon: 0.2545597000093016    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2142   score: 4.0   memory length: 476742   epsilon: 0.2540488600092984    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2143   score: 11.0   memory length: 477295   epsilon: 0.25295392000929146    steps: 553    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2144   score: 4.0   memory length: 477574   epsilon: 0.25240150000928796    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2145   score: 4.0   memory length: 477850   epsilon: 0.2518550200092845    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2146   score: 4.0   memory length: 478127   epsilon: 0.25130656000928103    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2147   score: 5.0   memory length: 478435   epsilon: 0.2506967200092772    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2148   score: 3.0   memory length: 478662   epsilon: 0.25024726000927433    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2149   score: 6.0   memory length: 479020   epsilon: 0.24953842000926985    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2150   score: 5.0   memory length: 479346   epsilon: 0.24889294000926576    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2151   score: 3.0   memory length: 479578   epsilon: 0.24843358000926286    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2152   score: 3.0   memory length: 479805   epsilon: 0.24798412000926    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2153   score: 7.0   memory length: 480204   epsilon: 0.247194100009255    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2154   score: 5.0   memory length: 480493   epsilon: 0.2466218800092514    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.99\n","episode: 2155   score: 2.0   memory length: 480676   epsilon: 0.2462595400092491    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2156   score: 9.0   memory length: 481200   epsilon: 0.24522202000924254    steps: 524    lr: 6.400000000000001e-06     evaluation reward: 4.99\n","episode: 2157   score: 3.0   memory length: 481432   epsilon: 0.24476266000923963    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2158   score: 5.0   memory length: 481739   epsilon: 0.24415480000923578    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2159   score: 4.0   memory length: 482040   epsilon: 0.243558820009232    steps: 301    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2160   score: 4.0   memory length: 482319   epsilon: 0.24300640000922852    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2161   score: 4.0   memory length: 482595   epsilon: 0.24245992000922506    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2162   score: 4.0   memory length: 482907   epsilon: 0.24184216000922115    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2163   score: 4.0   memory length: 483189   epsilon: 0.24128380000921762    steps: 282    lr: 6.400000000000001e-06     evaluation reward: 4.91\n","episode: 2164   score: 5.0   memory length: 483493   epsilon: 0.2406818800092138    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.89\n","episode: 2165   score: 4.0   memory length: 483736   epsilon: 0.24020074000921077    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 4.86\n","episode: 2166   score: 3.0   memory length: 483947   epsilon: 0.23978296000920812    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 4.86\n","episode: 2167   score: 5.0   memory length: 484251   epsilon: 0.23918104000920432    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.86\n","episode: 2168   score: 4.0   memory length: 484548   epsilon: 0.2385929800092006    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2169   score: 4.0   memory length: 484791   epsilon: 0.23811184000919755    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 4.8\n","episode: 2170   score: 4.0   memory length: 485046   epsilon: 0.23760694000919436    steps: 255    lr: 6.400000000000001e-06     evaluation reward: 4.79\n","episode: 2171   score: 2.0   memory length: 485229   epsilon: 0.23724460000919206    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.78\n","episode: 2172   score: 6.0   memory length: 485584   epsilon: 0.23654170000918762    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.8\n","episode: 2173   score: 4.0   memory length: 485842   epsilon: 0.23603086000918438    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.81\n","episode: 2174   score: 8.0   memory length: 486299   epsilon: 0.23512600000917866    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2175   score: 5.0   memory length: 486606   epsilon: 0.2345181400091748    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.81\n","episode: 2176   score: 2.0   memory length: 486788   epsilon: 0.23415778000917253    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.78\n","episode: 2177   score: 4.0   memory length: 487051   epsilon: 0.23363704000916924    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2178   score: 4.0   memory length: 487329   epsilon: 0.23308660000916576    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.74\n","episode: 2179   score: 6.0   memory length: 487652   epsilon: 0.2324470600091617    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.75\n","episode: 2180   score: 4.0   memory length: 487933   epsilon: 0.2318906800091582    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2181   score: 5.0   memory length: 488280   epsilon: 0.23120362000915384    steps: 347    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2182   score: 6.0   memory length: 488641   epsilon: 0.23048884000914932    steps: 361    lr: 6.400000000000001e-06     evaluation reward: 4.79\n","episode: 2183   score: 2.0   memory length: 488824   epsilon: 0.23012650000914703    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.73\n","episode: 2184   score: 6.0   memory length: 489197   epsilon: 0.22938796000914236    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.75\n","episode: 2185   score: 4.0   memory length: 489473   epsilon: 0.2288414800091389    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.72\n","episode: 2186   score: 4.0   memory length: 489747   epsilon: 0.22829896000913547    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.74\n","episode: 2187   score: 5.0   memory length: 490060   epsilon: 0.22767922000913154    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 4.74\n","episode: 2188   score: 2.0   memory length: 490243   epsilon: 0.22731688000912925    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.72\n","episode: 2189   score: 9.0   memory length: 490700   epsilon: 0.22641202000912353    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 4.74\n","episode: 2190   score: 13.0   memory length: 491189   epsilon: 0.2254438000091174    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 4.78\n","episode: 2191   score: 5.0   memory length: 491518   epsilon: 0.22479238000911328    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 4.76\n","episode: 2192   score: 3.0   memory length: 491730   epsilon: 0.22437262000911062    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.75\n","episode: 2193   score: 6.0   memory length: 492066   epsilon: 0.22370734000910641    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.79\n","episode: 2194   score: 4.0   memory length: 492363   epsilon: 0.2231192800091027    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.8\n","episode: 2195   score: 6.0   memory length: 492720   epsilon: 0.22241242000909822    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.82\n","episode: 2196   score: 7.0   memory length: 493166   epsilon: 0.22152934000909263    steps: 446    lr: 6.400000000000001e-06     evaluation reward: 4.84\n","episode: 2197   score: 3.0   memory length: 493398   epsilon: 0.22106998000908973    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.8\n","episode: 2198   score: 6.0   memory length: 493751   epsilon: 0.2203710400090853    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 4.81\n","episode: 2199   score: 8.0   memory length: 494185   epsilon: 0.21951172000907987    steps: 434    lr: 6.400000000000001e-06     evaluation reward: 4.85\n","episode: 2200   score: 7.0   memory length: 494555   epsilon: 0.21877912000907523    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 4.89\n","episode: 2201   score: 8.0   memory length: 495006   epsilon: 0.21788614000906958    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2202   score: 7.0   memory length: 495426   epsilon: 0.21705454000906432    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2203   score: 6.0   memory length: 495747   epsilon: 0.2164189600090603    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2204   score: 4.0   memory length: 496003   epsilon: 0.2159120800090571    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 4.96\n","episode: 2205   score: 6.0   memory length: 496326   epsilon: 0.21527254000905305    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.98\n","episode: 2206   score: 6.0   memory length: 496716   epsilon: 0.21450034000904816    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 4.99\n","episode: 2207   score: 4.0   memory length: 496996   epsilon: 0.21394594000904466    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2208   score: 3.0   memory length: 497226   epsilon: 0.21349054000904177    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.99\n","episode: 2209   score: 4.0   memory length: 497505   epsilon: 0.21293812000903828    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.01\n","episode: 2210   score: 3.0   memory length: 497719   epsilon: 0.2125144000090356    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 4.97\n","episode: 2211   score: 4.0   memory length: 497994   epsilon: 0.21196990000903215    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.95\n","episode: 2212   score: 3.0   memory length: 498226   epsilon: 0.21151054000902925    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.94\n","episode: 2213   score: 2.0   memory length: 498409   epsilon: 0.21114820000902695    steps: 183    lr: 6.400000000000001e-06     evaluation reward: 4.88\n","episode: 2214   score: 5.0   memory length: 498684   epsilon: 0.2106037000090235    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.9\n","episode: 2215   score: 6.0   memory length: 499004   epsilon: 0.2099701000090195    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2216   score: 5.0   memory length: 499312   epsilon: 0.20936026000901564    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.92\n","episode: 2217   score: 4.0   memory length: 499572   epsilon: 0.20884546000901238    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.93\n","episode: 2218   score: 9.0   memory length: 500023   epsilon: 0.20795248000900673    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 5.0\n","episode: 2219   score: 5.0   memory length: 500352   epsilon: 0.2073010600090026    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 5.0\n","episode: 2220   score: 4.0   memory length: 500628   epsilon: 0.20675458000899916    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 4.96\n","episode: 2221   score: 3.0   memory length: 500840   epsilon: 0.2063348200089965    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 4.94\n","episode: 2222   score: 7.0   memory length: 501242   epsilon: 0.20553886000899146    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 4.96\n","episode: 2223   score: 2.0   memory length: 501424   epsilon: 0.20517850000898918    steps: 182    lr: 2.560000000000001e-06     evaluation reward: 4.91\n","episode: 2224   score: 4.0   memory length: 501681   epsilon: 0.20466964000898596    steps: 257    lr: 2.560000000000001e-06     evaluation reward: 4.92\n","episode: 2225   score: 5.0   memory length: 501970   epsilon: 0.20409742000898234    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 4.9\n","episode: 2226   score: 7.0   memory length: 502357   epsilon: 0.2033311600089775    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 4.93\n","episode: 2227   score: 13.0   memory length: 502986   epsilon: 0.20208574000896962    steps: 629    lr: 2.560000000000001e-06     evaluation reward: 5.0\n","episode: 2228   score: 11.0   memory length: 503582   epsilon: 0.20090566000896215    steps: 596    lr: 2.560000000000001e-06     evaluation reward: 5.03\n","episode: 2229   score: 7.0   memory length: 503987   epsilon: 0.20010376000895708    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 5.04\n","episode: 2230   score: 6.0   memory length: 504361   epsilon: 0.1993632400089524    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 5.06\n","episode: 2231   score: 4.0   memory length: 504638   epsilon: 0.19881478000894892    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 5.06\n","episode: 2232   score: 5.0   memory length: 504985   epsilon: 0.19812772000894457    steps: 347    lr: 2.560000000000001e-06     evaluation reward: 5.05\n","episode: 2233   score: 2.0   memory length: 505168   epsilon: 0.19776538000894228    steps: 183    lr: 2.560000000000001e-06     evaluation reward: 5.03\n","episode: 2234   score: 3.0   memory length: 505416   epsilon: 0.19727434000893918    steps: 248    lr: 2.560000000000001e-06     evaluation reward: 5.02\n","episode: 2235   score: 5.0   memory length: 505726   epsilon: 0.1966605400089353    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.0\n","episode: 2236   score: 7.0   memory length: 506133   epsilon: 0.1958546800089302    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 5.04\n","episode: 2237   score: 9.0   memory length: 506616   epsilon: 0.19489834000892414    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 5.06\n","episode: 2238   score: 6.0   memory length: 506991   epsilon: 0.19415584000891944    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 5.07\n","episode: 2239   score: 8.0   memory length: 507416   epsilon: 0.19331434000891412    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 5.12\n","episode: 2240   score: 4.0   memory length: 507694   epsilon: 0.19276390000891064    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 5.1\n","episode: 2241   score: 4.0   memory length: 507990   epsilon: 0.19217782000890693    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 5.08\n","episode: 2242   score: 9.0   memory length: 508466   epsilon: 0.19123534000890097    steps: 476    lr: 2.560000000000001e-06     evaluation reward: 5.13\n","episode: 2243   score: 5.0   memory length: 508773   epsilon: 0.19062748000889712    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.07\n","episode: 2244   score: 4.0   memory length: 509069   epsilon: 0.1900414000088934    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 5.07\n","episode: 2245   score: 2.0   memory length: 509252   epsilon: 0.18967906000889112    steps: 183    lr: 2.560000000000001e-06     evaluation reward: 5.05\n","episode: 2246   score: 6.0   memory length: 509612   epsilon: 0.1889662600088866    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 5.07\n","episode: 2247   score: 2.0   memory length: 509794   epsilon: 0.18860590000888433    steps: 182    lr: 2.560000000000001e-06     evaluation reward: 5.04\n","episode: 2248   score: 2.0   memory length: 509977   epsilon: 0.18824356000888204    steps: 183    lr: 2.560000000000001e-06     evaluation reward: 5.03\n","episode: 2249   score: 3.0   memory length: 510191   epsilon: 0.18781984000887936    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.0\n","episode: 2250   score: 9.0   memory length: 510677   epsilon: 0.18685756000887327    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 5.04\n","episode: 2251   score: 6.0   memory length: 511013   epsilon: 0.18619228000886906    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 5.07\n","episode: 2252   score: 5.0   memory length: 511323   epsilon: 0.18557848000886518    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.09\n","episode: 2253   score: 4.0   memory length: 511601   epsilon: 0.1850280400088617    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 5.06\n","episode: 2254   score: 10.0   memory length: 512127   epsilon: 0.1839865600088551    steps: 526    lr: 2.560000000000001e-06     evaluation reward: 5.11\n","episode: 2255   score: 5.0   memory length: 512461   epsilon: 0.18332524000885092    steps: 334    lr: 2.560000000000001e-06     evaluation reward: 5.14\n","episode: 2256   score: 6.0   memory length: 512812   epsilon: 0.18263026000884652    steps: 351    lr: 2.560000000000001e-06     evaluation reward: 5.11\n","episode: 2257   score: 4.0   memory length: 513088   epsilon: 0.18208378000884307    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.12\n","episode: 2258   score: 10.0   memory length: 513610   epsilon: 0.18105022000883653    steps: 522    lr: 2.560000000000001e-06     evaluation reward: 5.17\n","episode: 2259   score: 7.0   memory length: 513979   epsilon: 0.1803196000088319    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 5.2\n","episode: 2260   score: 7.0   memory length: 514383   epsilon: 0.17951968000882684    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 5.23\n","episode: 2261   score: 6.0   memory length: 514738   epsilon: 0.1788167800088224    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 5.25\n","episode: 2262   score: 6.0   memory length: 515076   epsilon: 0.17814754000881816    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 5.27\n","episode: 2263   score: 4.0   memory length: 515352   epsilon: 0.1776010600088147    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.27\n","episode: 2264   score: 5.0   memory length: 515681   epsilon: 0.17694964000881058    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 5.27\n","episode: 2265   score: 8.0   memory length: 516066   epsilon: 0.17618734000880576    steps: 385    lr: 2.560000000000001e-06     evaluation reward: 5.31\n","episode: 2266   score: 6.0   memory length: 516437   epsilon: 0.1754527600088011    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 5.34\n","episode: 2267   score: 4.0   memory length: 516711   epsilon: 0.17491024000879768    steps: 274    lr: 2.560000000000001e-06     evaluation reward: 5.33\n","episode: 2268   score: 9.0   memory length: 517139   epsilon: 0.17406280000879232    steps: 428    lr: 2.560000000000001e-06     evaluation reward: 5.38\n","episode: 2269   score: 9.0   memory length: 517582   epsilon: 0.17318566000878677    steps: 443    lr: 2.560000000000001e-06     evaluation reward: 5.43\n","episode: 2270   score: 5.0   memory length: 517909   epsilon: 0.17253820000878267    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 5.44\n","episode: 2271   score: 7.0   memory length: 518294   epsilon: 0.17177590000877785    steps: 385    lr: 2.560000000000001e-06     evaluation reward: 5.49\n","episode: 2272   score: 7.0   memory length: 518718   epsilon: 0.17093638000877254    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 5.5\n","episode: 2273   score: 4.0   memory length: 518961   epsilon: 0.1704552400087695    steps: 243    lr: 2.560000000000001e-06     evaluation reward: 5.5\n","episode: 2274   score: 6.0   memory length: 519315   epsilon: 0.16975432000876506    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 5.48\n","episode: 2275   score: 5.0   memory length: 519623   epsilon: 0.1691444800087612    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 5.48\n","episode: 2276   score: 3.0   memory length: 519853   epsilon: 0.16868908000875832    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 5.49\n","episode: 2277   score: 6.0   memory length: 520200   epsilon: 0.16800202000875397    steps: 347    lr: 2.560000000000001e-06     evaluation reward: 5.51\n","episode: 2278   score: 4.0   memory length: 520458   epsilon: 0.16749118000875074    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 5.51\n","episode: 2279   score: 3.0   memory length: 520670   epsilon: 0.16707142000874808    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 5.48\n","episode: 2280   score: 7.0   memory length: 521034   epsilon: 0.16635070000874352    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 5.51\n","episode: 2281   score: 6.0   memory length: 521392   epsilon: 0.16564186000873904    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 5.52\n","episode: 2282   score: 10.0   memory length: 521773   epsilon: 0.16488748000873427    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 5.56\n","episode: 2283   score: 9.0   memory length: 522243   epsilon: 0.16395688000872838    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 5.63\n","episode: 2284   score: 5.0   memory length: 522568   epsilon: 0.1633133800087243    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 5.62\n","episode: 2285   score: 16.0   memory length: 523181   epsilon: 0.16209964000871663    steps: 613    lr: 2.560000000000001e-06     evaluation reward: 5.74\n","episode: 2286   score: 4.0   memory length: 523440   epsilon: 0.16158682000871338    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 5.74\n","episode: 2287   score: 4.0   memory length: 523716   epsilon: 0.16104034000870993    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.73\n","episode: 2288   score: 6.0   memory length: 524089   epsilon: 0.16030180000870525    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 5.77\n","episode: 2289   score: 4.0   memory length: 524383   epsilon: 0.15971968000870157    steps: 294    lr: 2.560000000000001e-06     evaluation reward: 5.72\n","episode: 2290   score: 4.0   memory length: 524641   epsilon: 0.15920884000869834    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 5.63\n","episode: 2291   score: 6.0   memory length: 524999   epsilon: 0.15850000000869385    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 5.64\n","episode: 2292   score: 6.0   memory length: 525375   epsilon: 0.15775552000868914    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 5.67\n","episode: 2293   score: 4.0   memory length: 525651   epsilon: 0.15720904000868569    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.65\n","episode: 2294   score: 3.0   memory length: 525900   epsilon: 0.15671602000868257    steps: 249    lr: 2.560000000000001e-06     evaluation reward: 5.64\n","episode: 2295   score: 4.0   memory length: 526179   epsilon: 0.15616360000867907    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 5.62\n","episode: 2296   score: 4.0   memory length: 526439   epsilon: 0.15564880000867581    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 5.59\n","episode: 2297   score: 5.0   memory length: 526746   epsilon: 0.15504094000867197    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.61\n","episode: 2298   score: 9.0   memory length: 527255   epsilon: 0.1540331200086656    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 5.64\n","episode: 2299   score: 3.0   memory length: 527471   epsilon: 0.15360544000866289    steps: 216    lr: 2.560000000000001e-06     evaluation reward: 5.59\n","episode: 2300   score: 9.0   memory length: 527955   epsilon: 0.15264712000865682    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 5.61\n","episode: 2301   score: 6.0   memory length: 528333   epsilon: 0.1518986800086521    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 5.59\n","episode: 2302   score: 14.0   memory length: 528863   epsilon: 0.15084928000864545    steps: 530    lr: 2.560000000000001e-06     evaluation reward: 5.66\n","episode: 2303   score: 5.0   memory length: 529188   epsilon: 0.15020578000864138    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 5.65\n","episode: 2304   score: 8.0   memory length: 529628   epsilon: 0.14933458000863586    steps: 440    lr: 2.560000000000001e-06     evaluation reward: 5.69\n","episode: 2305   score: 15.0   memory length: 530193   epsilon: 0.1482158800086288    steps: 565    lr: 2.560000000000001e-06     evaluation reward: 5.78\n","episode: 2306   score: 5.0   memory length: 530500   epsilon: 0.14760802000862494    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.77\n","episode: 2307   score: 4.0   memory length: 530776   epsilon: 0.14706154000862148    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.77\n","episode: 2308   score: 4.0   memory length: 531036   epsilon: 0.14654674000861823    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 5.78\n","episode: 2309   score: 10.0   memory length: 531564   epsilon: 0.1455013000086116    steps: 528    lr: 2.560000000000001e-06     evaluation reward: 5.84\n","episode: 2310   score: 3.0   memory length: 531778   epsilon: 0.14507758000860893    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.84\n","episode: 2311   score: 9.0   memory length: 532231   epsilon: 0.14418064000860326    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 5.89\n","episode: 2312   score: 7.0   memory length: 532632   epsilon: 0.14338666000859823    steps: 401    lr: 2.560000000000001e-06     evaluation reward: 5.93\n","episode: 2313   score: 9.0   memory length: 533051   epsilon: 0.14255704000859298    steps: 419    lr: 2.560000000000001e-06     evaluation reward: 6.0\n","episode: 2314   score: 5.0   memory length: 533377   epsilon: 0.1419115600085889    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.0\n","episode: 2315   score: 9.0   memory length: 533815   epsilon: 0.1410443200085834    steps: 438    lr: 2.560000000000001e-06     evaluation reward: 6.03\n","episode: 2316   score: 8.0   memory length: 534227   epsilon: 0.14022856000857825    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 6.06\n","episode: 2317   score: 5.0   memory length: 534597   epsilon: 0.13949596000857362    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 6.07\n","episode: 2318   score: 10.0   memory length: 535060   epsilon: 0.13857922000856782    steps: 463    lr: 2.560000000000001e-06     evaluation reward: 6.08\n","episode: 2319   score: 3.0   memory length: 535291   epsilon: 0.13812184000856492    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 6.06\n","episode: 2320   score: 6.0   memory length: 535667   epsilon: 0.1373773600085602    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 6.08\n","episode: 2321   score: 6.0   memory length: 536040   epsilon: 0.13663882000855554    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.11\n","episode: 2322   score: 7.0   memory length: 536480   epsilon: 0.13576762000855003    steps: 440    lr: 2.560000000000001e-06     evaluation reward: 6.11\n","episode: 2323   score: 9.0   memory length: 536968   epsilon: 0.13480138000854391    steps: 488    lr: 2.560000000000001e-06     evaluation reward: 6.18\n","episode: 2324   score: 8.0   memory length: 537440   epsilon: 0.133866820008538    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 6.22\n","episode: 2325   score: 11.0   memory length: 537965   epsilon: 0.13282732000853142    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 6.28\n","episode: 2326   score: 9.0   memory length: 538403   epsilon: 0.13196008000852594    steps: 438    lr: 2.560000000000001e-06     evaluation reward: 6.3\n","episode: 2327   score: 3.0   memory length: 538615   epsilon: 0.13154032000852328    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 6.2\n","episode: 2328   score: 6.0   memory length: 538953   epsilon: 0.13087108000851905    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.15\n","episode: 2329   score: 4.0   memory length: 539232   epsilon: 0.13031866000851555    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 6.12\n","episode: 2330   score: 4.0   memory length: 539492   epsilon: 0.1298038600085123    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.1\n","episode: 2331   score: 5.0   memory length: 539802   epsilon: 0.1291900600085084    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 6.11\n","episode: 2332   score: 6.0   memory length: 540143   epsilon: 0.12851488000850414    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 6.12\n","episode: 2333   score: 4.0   memory length: 540421   epsilon: 0.12796444000850066    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 6.14\n","episode: 2334   score: 5.0   memory length: 540726   epsilon: 0.12736054000849684    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 6.16\n","episode: 2335   score: 9.0   memory length: 541105   epsilon: 0.1266101200084921    steps: 379    lr: 2.560000000000001e-06     evaluation reward: 6.2\n","episode: 2336   score: 9.0   memory length: 541575   epsilon: 0.1256795200084862    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 6.22\n","episode: 2337   score: 3.0   memory length: 541805   epsilon: 0.12522412000848332    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 6.16\n","episode: 2338   score: 5.0   memory length: 542130   epsilon: 0.12458062000848219    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 6.15\n","episode: 2339   score: 2.0   memory length: 542313   epsilon: 0.12421828000848244    steps: 183    lr: 2.560000000000001e-06     evaluation reward: 6.09\n","episode: 2340   score: 4.0   memory length: 542589   epsilon: 0.12367180000848281    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 6.09\n","episode: 2341   score: 6.0   memory length: 542945   epsilon: 0.12296692000848329    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.11\n","episode: 2342   score: 3.0   memory length: 543157   epsilon: 0.12254716000848358    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 6.05\n","episode: 2343   score: 8.0   memory length: 543609   epsilon: 0.12165220000848419    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 6.08\n","episode: 2344   score: 6.0   memory length: 543946   epsilon: 0.12098494000848464    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 6.1\n","episode: 2345   score: 8.0   memory length: 544344   epsilon: 0.12019690000848518    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 6.16\n","episode: 2346   score: 11.0   memory length: 544947   epsilon: 0.119002960008486    steps: 603    lr: 2.560000000000001e-06     evaluation reward: 6.21\n","episode: 2347   score: 6.0   memory length: 545327   epsilon: 0.11825056000848651    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 6.25\n","episode: 2348   score: 8.0   memory length: 545796   epsilon: 0.11732194000848714    steps: 469    lr: 2.560000000000001e-06     evaluation reward: 6.31\n","episode: 2349   score: 5.0   memory length: 546087   epsilon: 0.11674576000848753    steps: 291    lr: 2.560000000000001e-06     evaluation reward: 6.33\n","episode: 2350   score: 5.0   memory length: 546413   epsilon: 0.11610028000848797    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.29\n","episode: 2351   score: 7.0   memory length: 546797   epsilon: 0.11533996000848849    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.3\n","episode: 2352   score: 10.0   memory length: 547289   epsilon: 0.11436580000848916    steps: 492    lr: 2.560000000000001e-06     evaluation reward: 6.35\n","episode: 2353   score: 10.0   memory length: 547806   epsilon: 0.11334214000848986    steps: 517    lr: 2.560000000000001e-06     evaluation reward: 6.41\n","episode: 2354   score: 7.0   memory length: 548209   epsilon: 0.1125442000084904    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 6.38\n","episode: 2355   score: 4.0   memory length: 548486   epsilon: 0.11199574000849077    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 6.37\n","episode: 2356   score: 4.0   memory length: 548746   epsilon: 0.11148094000849113    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.35\n","episode: 2357   score: 8.0   memory length: 549176   epsilon: 0.1106295400084917    steps: 430    lr: 2.560000000000001e-06     evaluation reward: 6.39\n","episode: 2358   score: 5.0   memory length: 549482   epsilon: 0.11002366000849212    steps: 306    lr: 2.560000000000001e-06     evaluation reward: 6.34\n","episode: 2359   score: 8.0   memory length: 549895   epsilon: 0.10920592000849268    steps: 413    lr: 2.560000000000001e-06     evaluation reward: 6.35\n","episode: 2360   score: 11.0   memory length: 550310   epsilon: 0.10838422000849324    steps: 415    lr: 2.560000000000001e-06     evaluation reward: 6.39\n","episode: 2361   score: 7.0   memory length: 550735   epsilon: 0.10754272000849381    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 6.4\n","episode: 2362   score: 5.0   memory length: 551058   epsilon: 0.10690318000849425    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 6.39\n","episode: 2363   score: 4.0   memory length: 551334   epsilon: 0.10635670000849462    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 6.39\n","episode: 2364   score: 3.0   memory length: 551564   epsilon: 0.10590130000849493    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 6.37\n","episode: 2365   score: 4.0   memory length: 551824   epsilon: 0.10538650000849528    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.33\n","episode: 2366   score: 5.0   memory length: 552132   epsilon: 0.1047766600084957    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 6.32\n","episode: 2367   score: 4.0   memory length: 552392   epsilon: 0.10426186000849605    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.32\n","episode: 2368   score: 4.0   memory length: 552668   epsilon: 0.10371538000849642    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 6.27\n","episode: 2369   score: 7.0   memory length: 553044   epsilon: 0.10297090000849693    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 6.25\n","episode: 2370   score: 6.0   memory length: 553402   epsilon: 0.10226206000849741    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.26\n","episode: 2371   score: 9.0   memory length: 553912   epsilon: 0.1012522600084981    steps: 510    lr: 2.560000000000001e-06     evaluation reward: 6.28\n","episode: 2372   score: 4.0   memory length: 554157   epsilon: 0.10076716000849843    steps: 245    lr: 2.560000000000001e-06     evaluation reward: 6.25\n","episode: 2373   score: 3.0   memory length: 554387   epsilon: 0.10031176000849874    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 6.24\n","episode: 2374   score: 4.0   memory length: 554650   epsilon: 0.0997910200084991    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.22\n","episode: 2375   score: 3.0   memory length: 554882   epsilon: 0.09933166000849941    steps: 232    lr: 2.560000000000001e-06     evaluation reward: 6.2\n","episode: 2376   score: 8.0   memory length: 555285   epsilon: 0.09853372000849996    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 6.25\n","episode: 2377   score: 4.0   memory length: 555543   epsilon: 0.0980228800085003    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 6.23\n","episode: 2378   score: 4.0   memory length: 555806   epsilon: 0.09750214000850066    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.23\n","episode: 2379   score: 3.0   memory length: 556035   epsilon: 0.09704872000850097    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 6.23\n","episode: 2380   score: 10.0   memory length: 556565   epsilon: 0.09599932000850168    steps: 530    lr: 2.560000000000001e-06     evaluation reward: 6.26\n","episode: 2381   score: 8.0   memory length: 556967   epsilon: 0.09520336000850223    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 6.28\n","episode: 2382   score: 7.0   memory length: 557363   epsilon: 0.09441928000850276    steps: 396    lr: 2.560000000000001e-06     evaluation reward: 6.25\n","episode: 2383   score: 6.0   memory length: 557718   epsilon: 0.09371638000850324    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 6.22\n","episode: 2384   score: 6.0   memory length: 558091   epsilon: 0.09297784000850375    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.23\n","episode: 2385   score: 6.0   memory length: 558449   epsilon: 0.09226900000850423    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.13\n","episode: 2386   score: 6.0   memory length: 558821   epsilon: 0.09153244000850473    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 6.15\n","episode: 2387   score: 7.0   memory length: 559218   epsilon: 0.09074638000850527    steps: 397    lr: 2.560000000000001e-06     evaluation reward: 6.18\n","episode: 2388   score: 6.0   memory length: 559554   epsilon: 0.09008110000850572    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.18\n","episode: 2389   score: 5.0   memory length: 559861   epsilon: 0.08947324000850614    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.19\n","episode: 2390   score: 5.0   memory length: 560189   epsilon: 0.08882380000850658    steps: 328    lr: 2.560000000000001e-06     evaluation reward: 6.2\n","episode: 2391   score: 12.0   memory length: 560702   epsilon: 0.08780806000850727    steps: 513    lr: 2.560000000000001e-06     evaluation reward: 6.26\n","episode: 2392   score: 6.0   memory length: 561060   epsilon: 0.08709922000850776    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.26\n","episode: 2393   score: 3.0   memory length: 561288   epsilon: 0.08664778000850806    steps: 228    lr: 2.560000000000001e-06     evaluation reward: 6.25\n","episode: 2394   score: 10.0   memory length: 561777   epsilon: 0.08567956000850872    steps: 489    lr: 2.560000000000001e-06     evaluation reward: 6.32\n","episode: 2395   score: 7.0   memory length: 562203   epsilon: 0.0848360800085093    steps: 426    lr: 2.560000000000001e-06     evaluation reward: 6.35\n","episode: 2396   score: 7.0   memory length: 562590   epsilon: 0.08406982000850982    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 6.38\n","episode: 2397   score: 7.0   memory length: 563015   epsilon: 0.0832283200085104    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 6.4\n","episode: 2398   score: 5.0   memory length: 563340   epsilon: 0.08258482000851083    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 6.36\n","episode: 2399   score: 8.0   memory length: 563791   epsilon: 0.08169184000851144    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 6.41\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["rewards, episodes = [], []\n","best_eval_reward = 0\n","for e in range(EPISODES):\n","    done = False\n","    score = 0\n","\n","    history = np.zeros([5, 84, 84], dtype=np.uint8)\n","    step = 0\n","    state = env.reset()\n","    next_state = state\n","    life = number_lives\n","\n","    get_init_state(history, state, HISTORY_SIZE)\n","\n","    while not done:\n","        step += 1\n","        frame += 1\n","\n","        # Perform a fire action if ball is no longer on screen to continue onto next life\n","        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","            action = 0\n","        else:\n","            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","        state = next_state\n","        next_state, reward, done, info = env.step(action + 1)\n","        \n","        frame_next_state = get_frame(next_state)\n","        history[4, :, :] = frame_next_state\n","        terminal_state = check_live(life, info['lives'])\n","\n","        life = info['lives']\n","        r = reward\n","\n","        # Store the transition in memory \n","        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","        # Start training after random sample generation\n","        if(frame >= train_frame):\n","            agent.train_policy_net(frame)\n","            # Update the target network only for Double DQN only\n","            if double_dqn and (frame % update_target_network_frequency)== 0:\n","                agent.update_target_net()\n","        score += reward\n","        history[:4, :, :] = history[1:, :, :]\n","            \n","        if done:\n","            evaluation_reward.append(score)\n","            rewards.append(np.mean(evaluation_reward))\n","            episodes.append(e)\n","            pylab.plot(episodes, rewards, 'b')\n","            pylab.xlabel('Episodes')\n","            pylab.ylabel('Rewards') \n","            pylab.title('Episodes vs Reward')\n","            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n","            \n","            # every episode, plot the play time\n","            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n","                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n","                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n","\n","            # if the mean of scores of last 100 episode is bigger than 5 save model\n","            ### Change this save condition to whatever you prefer ###\n","            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n","                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n","                best_eval_reward = np.mean(evaluation_reward)\n"]},{"cell_type":"markdown","metadata":{"id":"96C_0VjE8RQQ"},"source":["# Visualize Agent Performance"]},{"cell_type":"markdown","metadata":{"id":"fYIjMH4k8RQQ"},"source":["BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n","\n","Please save your model before running this portion of the code."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4VuHCao8RQQ"},"outputs":[],"source":["torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOBnUZ1b8RQQ","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1683312529358,"user_tz":300,"elapsed":27,"user":{"displayName":"Yung-Hsin Chao","userId":"03064933817200986783"}},"outputId":"83415380-552a-4da8-8c21-1aa714523c8f"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-d5b196983c59>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMonitor\u001b[0m \u001b[0;31m# If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Monitor' from 'gym.wrappers' (/usr/local/lib/python3.10/dist-packages/gym/wrappers/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from gym.wrappers import Monitor # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n","import glob\n","import io\n","import base64\n","\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","\n","from pyvirtualdisplay import Display\n","\n","# Displaying the game live\n","def show_state(env, step=0, info=\"\"):\n","    plt.figure(3)\n","    plt.clf()\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n","    plt.axis('off')\n","\n","    ipythondisplay.clear_output(wait=True)\n","    ipythondisplay.display(plt.gcf())\n","    \n","# Recording the game and replaying the game afterwards\n","def show_video():\n","    mp4list = glob.glob('video/*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else: \n","        print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","    env = Monitor(env, './video', force=True)\n","    return env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZIg1XVi8RQQ"},"outputs":[],"source":["display = Display(visible=0, size=(300, 200))\n","display.start()\n","\n","# Load agent\n","# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n","agent.epsilon = 0.0 # Set agent to only exploit the best action\n","\n","env = gym.make('BreakoutDeterministic-v4')\n","env = wrap_env(env)\n","\n","done = False\n","score = 0\n","step = 0\n","state = env.reset()\n","next_state = state\n","life = number_lives\n","history = np.zeros([5, 84, 84], dtype=np.uint8)\n","get_init_state(history, state)\n","\n","while not done:\n","    \n","    # Render breakout\n","    env.render()\n","#     show_state(env,step) # uncommenting this provides another way to visualize the game\n","\n","    step += 1\n","    frame += 1\n","\n","    # Perform a fire action if ball is no longer on screen\n","    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","        action = 0\n","    else:\n","        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","    state = next_state\n","    \n","    next_state, reward, done, info = env.step(action + 1)\n","        \n","    frame_next_state = get_frame(next_state)\n","    history[4, :, :] = frame_next_state\n","    terminal_state = check_live(life, info['ale.lives'])\n","        \n","    life = info['ale.lives']\n","    r = np.clip(reward, -1, 1) \n","    r = reward\n","\n","    # Store the transition in memory \n","    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","    # Start training after random sample generation\n","    score += reward\n","    \n","    history[:4, :, :] = history[1:, :, :]\n","env.close()\n","show_video()\n","display.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5H_hCzf8RQR"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}